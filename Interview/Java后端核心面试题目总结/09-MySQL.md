

# MySQL基础

## 一条SQL查询语句是如何执行的？

## 一条SQL更新语句是如何执行的？

## MySQL 查询执行顺序？

MySQL 查询执行的顺序是：

```mysql
(1)     SELECT
(2)     DISTINCT <select_list>
(3)     FROM <left_table>
(4)     <join_type> JOIN <right_table>
(5)     ON <join_condition>
(6)     WHERE <where_condition>
(7)     GROUP BY <group_by_list>
(8)     HAVING <having_condition>
(9)     ORDER BY <order_by_condition>
(10)    LIMIT <limit_number>
```

## delete drop truncate区别

- truncate 和 delete只删除数据，不删除表结构 ；drop删除表结构，并且释放所占的空间。
- **删除数据的速度**，一般来说: **drop> truncate > delete**
- delete属于DML语言，需要事务管理，commit之后才能生效。drop和truncate属于DDL语言，操作立刻生效，不可回滚。
- 使用场合：
  - 当你不再需要该表时， 用 drop;
  - 当你仍要保留该表，但要删除所有记录时， 用 truncate;
  - 当你要删除部分记录时（always with a where clause), 用 delete.

**注意：**对于有主外键关系的表，不能使用truncate而应该使用不带where子句的delete语句，由于truncate不记录在日志中，不能够激活触发器。

# 数据库设计

## 如何设计数据库及表呢？

数据库设计就是根据业务系统的具体需求，结合我们所选用的DBMS（数据库管理系统），为这个业务系统构造出最优的数据存储模型，并建立数据库中的表结构以及表与表之间的关联关系的过程。使之能有效的对应用系统中的数据进行存储，并可以高效的对已存储的数据进行访问。

| 优良的设计                                 | 糟糕的设计                         |
| ------------------------------------------ | ---------------------------------- |
| 减少数据维护异常                           | 存在数据插入、更新、删除异常       |
| 减少数据冗余，节省存储空间，便于进一步扩展 | 存在大量数据冗余，浪费大量存储空间 |
| 高效的访问                                 | 访问数据低效                       |

数据库系统设计及开发大致可以简化为如下几个步骤：

1. **需求分析**：数据是什么，数据具有哪些属性，数据与属性的特点是什么。
2. **概念设计**：建立**ER模型**。
3. **逻辑设计**：按ER图按照一定规则转换为关系模型，关系模式的规范化和优化（应用**设计范式**）。
4. **物理设计**：给数据模型设计一个合理的物理结构，比如数据存取结构（如数据库管理系统的选择）。
5. **数据库实现**：数据定义语言DDL创建数据库，数据入库。
6. **维护和优化**：对数据库进行监测、评估、调整、备份和修改（如建表、索引优化、大表拆分）。

## 什么是设计范式？

关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴德斯科范式/巴斯范式（BCNF）、第四范式（4NF）和第五范式（5NF）。 满足最低要求的范式是第一范式（1NF）。 在第一范式的基础上进一步满足更多要求的称为第二范式（2NF），其余范式以次类推。越高的范式数据库的冗余度就越低。

但并不是说遵循的范式等级越高越好，范式过高虽然具有对数据关系有更好的约束性，但是也会导致表之间的关系更加繁琐，从而导致每次操作的表会变多，数据库性能下降。

通常设计中，**最高也就遵循到 BCNF，普遍还是 3NF**。

**1NF**：数据库中的所有字段都是单一属性，不可再分的，每个列都是原子的。

**2NF**：在 1NF 的基础上，消除了非主属性对码的部分函数依赖。

**3NF**：在 2NF 的基础上，消除非主属性对码的传递函数依赖。

**BCNF**：消除**主属性**对于码的部分函数依赖和传递函数依赖（前面的 2NF、3NF都是**非主属性**对码的部分函数依赖和传递函数依赖）。

>**反范式化**就是为了性能和读取效率，适当地对范式进行违反，**本质上就是用空间来换取时间**，把数据冗余在多个表中，当查询时可以减少或者是避免表之间的关联。

## 什么是函数依赖关系？

* **函数依赖（functional dependency）** ：若在一张表中，在属性（或属性组）X的值确定的情况下，必定能确定属性Y的值，那么就可以说Y函数依赖于X，写作` X → Y`。
  * （学号）->（姓名）/（学号，课名）->（分数）/（系名）->（系主任）。

* **部分函数依赖（partial functional dependency）** ：如果`X→Y`，并且存在X的一个真子集`X0`，使得`X0→Y`，则称`Y`对`X`部分函数依赖。
  * （学号，身份证号）->（姓名），（学号）->（姓名），（身份证号）->（姓名），所以姓名部分函数依赖与（学号，身份证号）。

* **完全函数依赖(Full functional dependency)** ：如果`X→Y`，并且任何X的真子集`X‘`，都不能满足`X’→Y`，则称`Y`对`X`完全函数依赖。**完全函数依赖必须要通过码中的所有属性才可以唯一确定一个值，而部分函数依赖只需要码中的部分属性即可**。
  * （学号，课名）->（分数），但是（学号）->（分数）不成立，（课名）->（分数）不成立，所以分数完全函数依赖与（学号，课名）。

* **传递函数依赖** ： 设X，Y，Z是U的不同的属性子集，如果 Z -> Y，Y -> X，并且 X 不函数依赖于 Y，那么我们就说 Z 传递函数依赖于 X，（X∪Y）∩Z=空集合。传递函数依赖的Y和Z子集往往同属于某一个事物，因此可将其合并放到一个表中。
  * （学号，姓名，系名，系主任）中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖。

## MySQL 存储引擎如何选择？

MySQL 提供了多种的存储引擎：`InnoDB`、`MyISAM`、MRG_MYISAM、MEMORY、CSV、ARCHIVE、BLACKHOLE、PERFORMANCE_SCHEMA、FEDERATED、… ...

具体每种存储引擎的介绍，可以看看 [《数据库存储引擎》](https://github.com/jaywcjlove/mysql-tutorial/blob/master/chapter3/3.5.md) 。

**如何选择合适的存储引擎？**

提供几个选择标准，然后按照标准，选择对应的存储引擎即可，也可以根据 [常用引擎对比](https://github.com/jaywcjlove/mysql-tutorial/blob/master/chapter3/3.5.md#常用引擎对比) 来选择你使用的存储引擎。使用哪种引擎需要根据需求灵活选择，一个数据库中多个表可以使用不同的引擎以满足各种性能和实际需求。使用合适的存储引擎，将会提高整个数据库的性能。

1. 是否需要支持事务。
2. 对索引和缓存的支持。
3. 是否需要使用热备。
4. 崩溃恢复，能否接受崩溃。
5. 存储的限制。
6. 是否需要外键支持。

目前，MySQL 默认的存储引擎是 `InnoDB` ，并且也是最主流的选择。主要原因如下：

- 支持事务。
- 支持行级锁和表级锁，能支持更多的并发量。
- 查询不加锁，完全不影响查询。
- 支持崩溃后恢复。

在 MySQL5.1 以及之前的版本，默认的存储引擎是 `MyISAM` ，但是目前已经不再更新，且它有几个比较关键的缺点：

- 不支持事务。
- 使用表级锁，如果数据量大，一个插入操作锁定表后，其他请求都将阻塞。

**请说明 `InnoDB` 和 `MyISAM` 的区别**

| 对比         | `InnoDB`       | `MyISAM` |
| :----------- | :------------- | :------- |
| 事务         | 支持           | 不支持   |
| 存储限制     | 64TB           | 无       |
| 锁粒度       | 行锁           | 表锁     |
| 崩溃后的恢复 | 支持           | 不支持   |
| 外键         | 支持           | 不支持   |
| 全文检索     | 5.7 版本后支持 | 支持     |

**请说说 `InnoDB` 的 4 大特性？**

- 插入缓冲(insert buffer)
- 二次写(double write)
- 自适应哈希索引(ahi)
- 预读(read ahead)

**为什么 SELECT COUNT(\*) FROM table 在 `InnoDB` 比 `MyISAM` 慢？**

对于 `SELECT COUNT(*) FROM table` 语句，在没有 `WHERE` 条件的情况下，`InnoDB` 比 `MyISAM` 可能会慢很多，尤其在大表的情况下。因为，`InnoDB` 是去实时统计结果，会全表扫描；而 `MyISAM` 内部维持了一个计数器，预存了结果，所以直接返回即可。

**各种不同 MySQL 版本的 Innodb 的改进？**

MySQL5.6 下 `Innodb` 引擎的主要改进：

1. online DDL
2. memcached NoSQL 接口
3. transportable tablespace（ alter table discard/import tablespace）
4. MySQL 正常关闭时，可以 dump 出 buffer pool 的（ space， page_no），重启时 reload，加快预热速度
5. 索引和表的统计信息持久化到 mysql.innodb_table_stats 和 mysql.innodb_index_stats，可提供稳定的执行计划
6. Compressed row format 支持压缩表

MySQL5.7 下 Innodb 引擎的主要改进：

- 1、修改 varchar 字段长度有时可以使用
- 2、Buffer pool 支持在线改变大小
- 3、Buffer pool 支持导出部分比例
- 4、支持新建 innodb tablespace，并可以在其中创建多张表
- 5、磁盘临时表采用 innodb 存储，并且存储在 innodb temp tablespace 里面，以前是 MyISAM 存储
- 6、透明表空间压缩功能

## MySQL 数据类型如何选择？

MySQL 支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型。具体可以看看 [《MySQL 数据类型》](http://www.runoob.com/mysql/mysql-data-types.html) 文档。正确的使用数据类型，对数据库的优化是非常重要的。

**MySQL 中 varchar 与 char 的区别？varchar(50) 中的 50 代表的涵义？**

- 1、varchar 与 char 的区别，char 是一种固定长度的类型，varchar 则是一种可变长度的类型。

- 2、varchar(50) 中 50 的涵义最多存放 50 个字符。varchar(50) 和 varchar(200) 仅存储 ”hello“ 时所占空间一样，

  但后者在排序时会消耗更多内存，因为 `ORDER BY col` 采用 fixed_length 计算 col 长度(memory引擎也一样)。

  > 所以，实际场景下，选择合适的 varchar 长度还是有必要的。

**int(11) 中的 11 代表什么涵义？**

int(11) 中的 11 ，不影响字段存储的范围，只影响展示效果。

**金额(金钱)相关的数据，选择什么数据类型？**

- 方式一，使用 int 或者 bigint 类型。如果需要存储到分的维度，需要 *100 进行放大。
- 方式二，使用 decimal 类型，避免精度丢失。如果使用 Java 语言时，需要使用 BigDecimal 进行对应。

**一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，删除了第 15,16,17 条记录，再把 MySQL 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15？**

- 一般情况下，我们创建的表的类型是InnoDB ，如果新增一条记录（不重启MySQL的情况下），这条记录的ID是18 ；但是如果重启 MySQL 的话，这条记录的 ID 是 15 。因为 InnoDB 表只把自增主键的最大 ID 记录到内存中，所以重启数据库或者对表 OPTIMIZE 操作，都会使最大 ID 丢失。
- 但是，如果我们使用表的类型是 MyISAM ，那么这条记录的 ID 就是 18 。因为 MyISAM 表会把自增主键的最大 ID 记录到数据文件里面，重启 MYSQL 后，自增主键的最大 ID 也不会丢失。

最后，还可以跟面试官装个 x ，生产数据，不建议进行物理删除记录。

**表中有大字段 X(例如：text 类型)，且字段 X 不会经常更新，以读为为主，请问您是选择拆成子表，还是继续放一起？写出您这样选择的理由**

- 拆带来的问题：连接消耗 + 存储拆分空间。

  > 如果能容忍拆分带来的空间问题，拆的话最好和经常要查询的表的主键在物理结构上放置在一起(分区) 顺序 IO ，减少连接消耗，最后这是一个文本列再加上一个全文索引来尽量抵消连接消耗。

- 不拆可能带来的问题：查询性能。

  > 如果能容忍不拆分带来的查询性能损失的话，上面的方案在某个极致条件下肯定会出现问题，那么不拆就是最好的选择。

实际场景下，例如说商品表数据量比较大的情况下，会将商品描述单独存储到一个表中。即，使用拆的方案。

# 索引

## 什么是索引？为什么要使用索引？使用场景？

**索引，就类似书籍的目录一样，可以提高数据查询的效率**。一本500页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。

这里总结了索引的**优点**：

1. 可以大大加快数据的检索速度（大大减少的检索的数据量）,  这也是创建索引的最主要的原因。
2. 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
3. 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表）。
4. 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

索引有什么**缺点**呢？

1. 占用存储空间：索引实际上也是一张表，记录了主键与索引字段，一般以索引文件的形式存储在磁盘上。
2. 降低更新表的速度：表的数据发生了变化，对应的索引也需要一起变更，从而减低的更新速度。否则索引指向的物理数据可能不对，这也是索引失效的原因之一。

**索引的使用场景？**

- 1、对非常小的表，大部分情况下全表扫描效率更高。

- 2、对中大型表，索引非常有效。

- 3、特大型的表，建立和使用索引的代价随着增长，可以使用分区技术来解决。

## 索引的分类？

索引，都是实现在存储引擎层的。主要有六种类型：

- **普通索引**：最基本的索引，没有任何约束。

- **唯一索引**：与普通索引类似，但具有唯一性约束。

- **主键索引**：特殊的唯一索引，不允许有空值。

- **复合索引/联合索引**：将多个列组合在一起创建索引，可以覆盖多个列。

- **外键索引**：只有`InnoDB`类型的表才可以使用外键索引，保证数据的一致性、完整性和实现级联操作。

- **全文索引**：MySQL 自带的全文索引只能用于 `InnoDB`、`MyISAM` ，并且只能对英文进行全文检索，一般使用全文索引引擎。

  > 常用的全文索引引擎的解决方案有 Elasticsearch、Solr 等等。最为常用的是 Elasticsearch 。

具体的使用，可以看看 [《服务端指南 数据存储篇 | MySQL（03） 如何设计索引》](http://blog.720ui.com/2017/mysql_core_03_how_use_index/) 。

## 如何创建及使用索引？

**MySQL 索引的“创建”原则？**

1. 最适合索引的列是出现在 `WHERE` 子句中的列，或连接子句中的列，而不是出现在 `SELECT` 关键字后的列。
2. 索引列的基数越大，索引效果越好。
3. 根据情况创建复合索引，复合索引可以提高查询效率。
4. 避免创建过多的索引，索引会额外占用磁盘空间，降低写操作效率。
5. 主键尽可能选择较短的数据类型，可以有效减少索引的磁盘占用提高查询效率。
6. 对字符串进行索引，应该定制一个前缀长度，可以节省大量的索引空间。

**MySQL 索引的“使用”注意事项？**

- 1、应尽量避免在 `WHERE` 子句中使用 `!=` 或 `<>` 操作符，否则将引擎放弃使用索引而进行全表扫描。优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。

  > 注意，`column IS NULL` 也是不可以使用索引的。

- 2、应尽量避免在 `WHERE` 子句中使用 `OR` 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：`SELECT id FROM t WHERE num = 10 OR num = 20` 。

- 3、应尽量避免在 `WHERE` 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。

- 4、应尽量避免在 `WHERE` 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。

- 5、不要在 `WHERE` 子句中的 `=` 左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。

- 6、复合索引遵循前缀原则。

- 7、如果 MySQL 评估使用索引比全表扫描更慢，会放弃使用索引。如果此时想要索引，可以在语句中添加强制索引。

- 8、列类型是字符串类型，查询时一定要给值加引号，否则索引失效。

- 9、`LIKE` 查询，`%` 不能在前，因为无法使用索引。如果需要模糊匹配，可以使用全文索引。

**以下三条 SQL 如何建索引，只建一条怎么建？**

```
WHERE a = 1 AND b = 1
WHERE b = 1
WHERE b = 1 ORDER BY time DESC
```

- 以顺序 b , a, time 建立复合索引，`CREATE INDEX table1_b_a_time ON index_test01(b, a, time)`。
- 对于第一条 SQL ，因为最新 MySQL 版本会优化 `WHERE` 子句后面的列顺序，以匹配复合索引顺序。

**想知道一个查询用到了哪个索引，如何查看?**

`EXPLAIN` 显示了 MYSQL 如何使用索引来处理 SELECT 语句以及连接表,可以帮助选择更好的索引和写出更优化的查询语句。

使用方法，在 `SELECT` 语句前加上 `EXPLAIN` 就可以了。

## 常见的索引模型有哪些？

**哈希表**

* 哈希表是一种以键-值（key-value）存储数据的结构。问题是，**哈希索引做区间查询的速度挺慢的**。所以，**哈希表这种结构适用于只有等值查询的场景**，适用于`Memcached`及其他一些NoSQL引擎。

**有序数组**

* **有序数组在等值查询和范围查询场景中的性能就都非常优秀**。如果仅仅看查询效率，有序数组很完美。但是，在需要更新数据的时，每在中间插入一个记录就必须挪动后面所有的记录，成本太高。所以，**有序数组索引只适用于静态存储引擎**，比如要保存的是2008年某个城市的所有人口信息（这类数据后续不会再被修改）。

**二叉搜索树**

* 二叉搜索树是经典的数据结构。二叉搜索树的特点是：每个父节点都有两个子节点（子节点可能为空），每个左子节点都比父节点小，每个右子节点比父节点大。
* 二叉搜索树搜索效率挺高，但是实际上大多数的数据库存储却并不使用，原因在于数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。所以我们要减少I/O次数，对于树来说，IO次数就是树的高度。
* 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，**“N叉”树中的“N”取决于数据块的大小**。
  * 以`InnoDB`的一个整数字段索引为例，这个N差不多是**1200**。这棵树高是4的时候，就可以存1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

## InnoDB 索引原理？

关于索引原理，可以参考以下几篇文章：

- [《MySQL索引背后的数据结构及算法原理》](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

- [《MySQL 索引原理》](https://blog.csdn.net/u013235478/article/details/50625677)

- [《深入理解 MySQL 索引原理和实现 —— 为什么索引可以加速查询？》](https://blog.csdn.net/tongdanping/article/details/79878302)

### InnoDB 的索引模型 B+Tree

在了解B+Tree之前，我们需先了解一下磁盘及B-Tree相关知识。

**磁盘基础知识**

系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。

`InnoDB`存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。`InnoDB`存储引擎中默认每个页的大小为 16 KB，可通过参数 `innodb_page_size` 将页的大小设置为 4K、8K、16K ，在 MySQL 中可通过命令查看页的大：`show variables like 'innodb_page_size';`

而系统一个磁盘块的存储空间往往没有这么大，因此 `InnoDB` 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小`16KB` 。`InnoDB` 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘 I/O 次数，提高查询效率。

**那什么是 B-Tree 索引？**

B-Tree 是为磁盘等外存储设备设计的一种平衡查找树。B-Tree 结构的数据可以**让系统高效的找到数据所在的磁盘块**。为了描述B-Tree，首先定义一条记录为一个二元组 [key, data] ，key 为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。

一棵 m 阶的 B-Tree 有如下特性：

1. 每个节点最多有 m 个孩子。
   - 除了根节点和叶子节点外，其它每个节点至少有 Ceil(m/2) 个孩子。
   - 若根节点不是叶子节点，则至少有 2 个孩子。
2. 所有叶子节点都在同一层，且不包含其它关键字信息。
3. 每个非叶子节点包含 n 个关键字信息（P0,P1,…Pn, k1,…kn）
   - 关键字的个数 n 满足：ceil(m/2)-1 <= n <= m-1
   - ki(i=1,…n) 为关键字，且关键字升序排序。
   - Pi(i=0,…n) 为指向子树根节点的指针。P(i-1) 指向的子树的所有节点关键字均小于 ki ，但都大于 k(i-1) 。

B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个 3 阶的 B-Tree：

<div align="center">  
<img src="http://static.iocoder.cn/84ea509fa091a10add4e7614e6cb37db" width="800px"/>
</div>

- 每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的 key 和三个指向子树根节点的 point ，point 存储的是子节点所在磁盘块的地址。两个 key 划分成的三个范围域，对应三个 point 指向的子树的数据的范围域。
- 以根节点为例，key 为 17 和 35 ，P1 指针指向的子树的数据范围为小于 17 ，P2 指针指向的子树的数据范围为 [17~35] ，P3 指针指向的子树的数据范围为大于 35 。

模拟查找 key 为 29 的过程：

1. 根据根节点找到磁盘块 1 ，读入内存。【磁盘I/O操作第1次】
2. 比较 key 29 在区间（17,35），找到磁盘块 1 的指针 P2 。
3. 根据 P2 指针找到磁盘块 3 ，读入内存。【磁盘I/O操作第2次】
4. 比较 key 29 在区间（26,30），找到磁盘块3的指针P2。
5. 根据 P2 指针找到磁盘块 8 ，读入内存。【磁盘I/O操作第3次】
6. 在磁盘块 8 中的 key 列表中找到 eky 29 。

分析上面过程，发现需要 3 次磁盘 I/O 操作，和 3 次内存查找操作。由于内存中的 key 是一个有序表结构，可以利用二分法查找提高效率。而 3 次磁盘 I/O 操作是影响整个 B-Tree 查找效率的决定因素。B-Tree 相对于 AVLTree 缩减了节点个数，使每次磁盘 I/O 取到内存的数据都发挥了作用，从而提高了查询效率。

**哪什么是 B+Tree 索引？**

B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构。在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为**索引组织表**。InnoDB使用了**B+树**索引模型，数据都是存储在B+树中的。每一个索引在InnoDB里面对应一棵B+树。**B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。**

从上面中的 B-Tree 结构图中可以看到，每个节点中不仅包含数据的 key 值，还有 data 值。而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小，当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。在 B+Tree 中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储 key 值信息，这样可以大大加大每个节点存储的 key 值数量，降低 B+Tree 的高度。

B+Tree 相对于 B-Tree 有几点不同：

- 非叶子节点只存储键值信息。
- 所有叶子节点之间都有一个链指针。
- 数据记录都存放在叶子节点中。

将上一节中的 B-Tree 优化，由于 B+Tree 的非叶子节点只存储键值信息，假设每个磁盘块能存储 4 个键值及指针信息，则变成 B+Tree 后其结构如下图所示：

<div align="center">  
<img src="http://static.iocoder.cn/259d196856a231aff5e3cf1505848af4" width="800px"/>
</div>

- 通常在 B+Tree 上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对 B+Tree 进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。

可能上面例子中只有 22 条数据记录，看不出 B+Tree 的优点，下面做一个推算：

* `InnoDB` 存储引擎中页大小为16KB，一般表的主键类型为 INT（占用4个字节） 或 BIGINT（占用8个字节），指针大小在`InnoDB`为6个字节，那么一个N = 16*1023/（8+6）= 1170 （约等1200）。如果高度为4层，1170^3=17亿。

- 实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree 的高度一般都在 2~4 层。MySQL 的 `InnoDB` 存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要 1~3 次磁盘 I/O 操作。

**B+Tree 有哪些索引类型？**

在 B+Tree 中，根据叶子节点的内容，索引类型分为**主键索引**和**非主键索引**。

* 主键索引的叶子节点存的是**整行数据**。在InnoDB里，主键索引也被称为**聚簇索引**（clustered index）。

* 非主键索引的叶子节点内容是**主键的值**。在InnoDB里，非主键索引也被称为**二级索引/辅助索引**（secondary index）。

假设，我们有一个主键列为ID的表，表中有字段k，并且在k上有索引。

```mysql
mysql> create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');
```

表中R1~R5行的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)，两棵树的示例示意图如下。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20201126220850358.png" width="500px"/>
<div align="center">图1 索引组织结构</divd>
</div>

二级索引与聚集索引的区别在于**二级索引的叶子节点并不包含行记录的全部数据，而是存储相应行数据的聚簇索引键，即主键**。

**基于主键索引和普通索引的查询有什么区别？**

- 如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
- 如果语句是select * from T where k=5，即辅助索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次找到具体行记录数据。这个过程称为**回表**。（回到主键索引树搜索的过程，称为回表）

另外，`InnoDB` 通过主键聚簇数据，如果没有定义主键，会选择一个唯一的非空索引代替，如果没有这样的索引，会隐式定义个主键作为聚簇索引。

### 为什么MySQL用B+树做索引而不用B-树或红黑树?

**为什么不用B-Tree?**

* 从上面的分析可以看出，**B+树只有叶节点存放数据，其余节点用来索引；而B-树是每个索引节点都会有Data域。**
* `InnoDB` 在把磁盘数据读磁盘时会以页为基本单位，大小是固定的16KB，节点中存放了data，这无疑就增加了磁盘IO次数。

**为什么不用红黑树？**

* 红黑树的树的深度往往过大，会造成磁盘IO读写过于频繁，进而导致效率低下。B+树的每层可以有1170个分叉，可以大大降低树的高度。
* 要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。

### 使用聚簇索引的注意点有哪些？

聚簇索引表最大限度地提高了 I/O 密集型应用的性能，但它也有以下几个限制：

- 1、插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于 InnoDB 表，我们一般都会定义一个自增的 ID 列为主键。

  > 关于这一点，可能面试官会换一个问法。例如，为什么主键需要是自增 ID ，又或者为什么主键需要带有时间性关联。

- 2、更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB 表，我们一般定义主键为不可更新。

  > MySQL 默认情况下，主键是允许更新的。对于 MongoDB ， 主键是不允许更新的。

- 3、二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

  > 当然，有一种情况可以无需二次查找，基于非主键索引查询，但是查询字段只有主键 ID ，那么在二级索引中就可以查找到。

- 4、主键 ID 建议使用整型。因为，每个主键索引的 B+Tree 节点的键值可以存储更多主键 ID ，每个非主键索引的 B+Tree 节点的数据可以存储更多主键 ID 。

### 什么是最左前缀匹配原则？

在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。

B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录，比如有索引`(a, b, c, d)`，查询条件`a = 1 and b = 2 and c > 3 and d = 4`，则会在每个节点依次命中a、b、c，无法命中d。(很简单：索引命中只能是**相等**的情况，不能是范围匹配)

- 当构建组合索引(a,b,c,d)时，实际上创建了(a), (a, b), (a, b, c), (a, b,c ,d)四个索引，每个索引先保证前面的key有序，再保证后面的key有序。实际上当查询条件`a = 1 and b = 2 and c > 3 `时，可以用索引(a, b, c)，因为在a，b相同的情况下，c是有序的。但是当查询条件`a = 1 and b = 2 and c > 3 and d = 4`时，就不能用上述建的索引中的任意一个。所以a，b，c命中，d无法命中，如果查询条件a = 1 and b = 2 and c = 3 and d > 4，那么d也命中，就用(a,b,c,d)索引。

> 索引只能用于查找key是否**存在（相等）**，遇到范围查询`(>、<、between、like`左匹配)等就**不能进一步匹配**了，后续退化为线性查找。

这里就引申出一个问题：在建立联合索引的时候，如何安排索引内的字段顺序？

* 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。
* 其次，考虑的原则就是空间。

**=、in自动优化顺序**

**不需要考虑=、in等的顺序**，MySQL会自动优化这些条件的顺序，以匹配尽可能多的索引列。

例子：如有索引`(a, b, c, d)`，查询条件`c > 3 and b = 2 and a = 1 and d < 4`与`a = 1 and c > 3 and b = 2 and d < 4`等顺序都是可以的，MySQL会自动优化为`a = 1 and b = 2 and c > 3 and d < 4`，依次命中a、b、c。

### 什么是覆盖索引？与联合索引区别？

还是一上面图1为例，如果执行查询SQL语句是`select * from T where k between 3 and 5`，执行流程如下：

* 在k索引树上找到k=3的记录，取得 ID = 300；
* 再到ID索引树查到ID=300对应的R3；
* 在k索引树取下一个值k=5，取得ID=500；
* 再回到ID索引树查到ID=500对应的R4；
* 在k索引树取下一个值k=6，不满足条件，循环结束。

在这个过程中，**回到主键索引树搜索的过程，我们称之为回表**。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。

在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？

如果执行的语句是`select ID from T where k between 3 and 5`，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

需要注意的是，在引擎内部使用覆盖索引在索引k上其实读了三个记录，R3~R5（对应的索引k上的记录项），但是对于MySQL的Server层来说，它就是找引擎拿到了两条记录，因此MySQL认为扫描行数是2。

**覆盖索引与联合索引区别？**

* 覆盖索引：如果查询条件使用的是普通索引（或是联合索引的最左前缀字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果。
* 联合索引：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。

### 什么是索引下推？

MySQL 5.6 引入的**索引下推优化（index condition pushdown)**， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，**减少回表次数，大大提升了查询的效率**。

如果一张市民表联合索引（name, age），主键为name，现在有一句SQL：

```mysql
select * from user where name like '张%' and age=10 and ismale=1;
```

如果没有索引下推的话，执行流程如下：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20201126225305587.png" width="500px"/>
</div>

 索引下推执行流程：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20201126225346324.png" width="500px"/>
</div>

> 每一个虚线箭头表示回表一次。

第一个图中，在(name,age)索引里面去掉了age的值，这个过程`InnoDB`并不会去看age的值，只是按顺序把“name第一个字是’张’”的记录一条条取出来回表。因此，需要回表4次。

第二图中，`InnoDB`在(name,age)索引内部就判断了age是否等于10，对于不等于10的记录，直接判断并跳过。在这个例子中，只需要对ID4、ID5这两条记录回表取数据判断，就只需要回表2次。

## MyISAM 如何实现索引？

MyISAM 索引的实现，和 InnoDB 索引的实现是一样使用 B+Tree ，**差别在于 MyISAM 索引文件和数据文件是分离的，索引文件仅保存数据记录的地址**。

（1）主键索引：

MyISAM引 擎使用B+Tree作为索引结构，**叶节点的data域存放的是数据记录的地址**。下图是MyISAM主键索引的原理图：

<div align="center">  
<img src="http://static.iocoder.cn/d49d260fc1eb8f992df0401b70d70e3d" width="500px"/>
</div>

- 这里设表一共有三列，假设我们以 Col1 为主键，上图是一个 MyISAM 表的主索引（Primary key）示意。可以看出 MyISAM 的索引文件仅仅保存数据记录的地址。

（2）辅助索引：

**在 MyISAM 中，主索引和辅助索引在结构上没有任何区别，只是主索引要求 key 是唯一的，而辅助索引的 key 可以重复。**如果我们在 Col2 上建立一个辅助索引，则此索引的结构如下图所示：

<div align="center">  
<img src="http://static.iocoder.cn/2fb922405a35479fa99eb2de4708638c" width="500px"/>
</div>

- 同样也是一颗 B+Tree ，data 域保存数据记录的地址。因此，**MyISAM 中索引检索的算法为首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址，读取相应数据记录。**

MyISAM 的索引方式也叫做“**非聚集**”的，之所以这么称呼是为了与InnoDB 的聚集索引区分。

**MyISAM 索引与 InnoDB 索引的区别？**

- InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引。

- InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效。

- MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。

- InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。


## MySQL 索引失效？

**索引失效的常见场景**

* **OR**导致索引失效：查询条件包含or，可能导致索引失效，如果要想使用`or`又不想让索引失效，那就得需要为`or`条件中的每个列都建立索引。
* **类型不一致**导致的索引失效：如何字段类型是字符串，where时一定用引号括起来，否则索引失效。
* **模糊查询**导致索引失效：使用模糊查询（like）的时候以`%`开头也会导致索引失效。（优化：使用覆盖索引/或把%放后面）
* **函数**导致索引失效：在索引列上使用MySQL的内置函数，索引失效。
* **运算符**导致索引失效：索引字段上使用（！= 或者 < >，not in）时，可能会导致索引失效。
* **not in、not exists**导致索引失效。
* 索引字段上使用**is null、 is not null**，可能导致索引失效。
* 左连接查询或者右连接查询查询关联的字段**编码格式**不一样，可能导致索引失效：比如一个表的编码是utf8mb4，而另外一个表字段编码为utf8。

* **联合索引如果不遵循最左前缀原则**，那么索引也将失效，例如**查询时的条件列不是联合索引中的第一个列，或者遇到范围查询（`>、<、!=、between、like`左匹配）**。

# 事务隔离

## 什么是事务？事务的关键特性？

简单来说，**事务**就是用户定义的一系列数据库操作，这些操作可以视为一个完成的逻辑处理工作单元（unit），**要么全部执行，要么全部不执行，是不可分割的工作单元**。

MySQL是一个支持多引擎的系统，但并不是所有的引擎都支持事务，**事务能否生效取决于数据库引擎是否支持事务**。常用的MySQL 数据库默认使用`Innodb`引擎是支持事务的， `MyISAM`不支持事务。

提到事务，肯定会想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）。

* **原子性(atomicity)**

  “原子”的本意是“不可再分”，事务的原子性表现为一个事务中涉及到的多个操作在逻辑上缺一不可。事务的原子性要求事务中的所有操作要么都执行，要么都不执行。

* 一致性(consistency)

  “一致”指的是数据的一致，具体是指所有数据都处于满足业务规则的一致性状态。一致性原则要求：一个事务中不管涉及到多少个操作，都必须保证事务执行之前数据是正确的，事务执行之后数据仍然是正确的。如果一个事务在执行的过程中，其中某一个或某几个操作失败了，则必须将其他所有操作撤销，将数据恢复到事务执行之前的状态，这就是回滚。

* 隔离性(isolation)

  在应用程序实际运行过程中，事务往往是并发执行的，所以很有可能有许多事务同时处理相同的数据，因此每个事务都应该与其他事务隔离开来，防止数据损坏。隔离性原则要求多个事务在并发执行过程中不会互相干扰。

* 持久性(durability)

  持久性原则要求事务执行完成后，对数据的修改永久的保存下来，不会因各种系统错误或其他意外情况而受到影响。通常情况下，事务对数据的修改应该被写入到持久化存储器中。

举一个例子：在执行SQL语句的时候，某些业务要求（如一个转账操作），一系列操作必须全部执行，而不能只执行一部分。

```shell
假如我们从id=1的A账户给id=2的B账户转账100元

-- 第一步：将id=1的A账户余额(500)减去100
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
-- 第二步：将id=2的B账户余额(500)加上100
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
```

从A账户到B账户转账从6个详细操作：
（1）从A账户中把余额读出来（500）。
（2）对A账户做减法操作（500-100）。
（3）把结果写回A账户中（400）。
（4）从B账户中把余额读出来（500）。
（5）对B账户做加法操作（500+100）。
（6）把结果写回B账户中（600）。

事务的ACID特性就体现在：

* 原子性：保证1-6所有过程要么都执行，要么都不执行。一旦在执行某一步骤的过程中发生问题，就需要执行回滚操作。假如执行到第五步的时候，B账户突然不可用（比如被注销），那么之前的所有操作都应该回滚到执行事务之前的状态。

* 一致性：在转账之前，A和B的账户中共有500+500=1000元钱。在转账之后，A和B的账户中共有400+600=1000元。也就是说，数据的状态在执行该事务操作之后从一个状态改变到了另外一个状态。同时一致性还能保证账户余额不会变成负数等。

* 隔离性：在A向B转账的整个过程中，只要事务还没有提交（commit），查询A账户和B账户的时候，两个账户里面的钱的数量都不会有变化。如果在A给B转账的同时，有另外一个事务执行了C给B转账的操作，那么当两个事务都结束的时候，B账户里面的钱应该是A转给B的钱加上C转给B的钱再加上自己原有的钱。

* 持久性：一旦转账成功（事务提交），两个账户的里面的钱就会真的发生变化（会把数据写入数据库做持久化保存）。

## 什么是脏读、幻读、不可重复读？

当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）等并发问题。

假如现在有两个事务——A和B在并发执行修改一个Student表中age值：  

* **脏读**（dirty read) ：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据。
  （1）A将某条记录的age值从20修改为30。 
  （2）B读取了A更新后的值：30。 
  （3）A回滚，age值恢复到了20。 
  （4）B读取到的30就是一个无效的值。  
* **不可重复读**（non-repeatable read）:事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。
  （1）A读取了age值为20。
  （2）B将age值修改为30。
  （3）A再次读取age值为30，和第一次读取不一致。
* **幻读**（phantom read）:与不可重复读类似，不可重复读侧重于修改，幻读侧重于新增或删除。
  （1）A读取了Student表中的一部分数据。
  （2）B向Student表中插入了新的行。
  （3）A读取了Student表时，多出了一些行或少了一些行。

## MySQL的四种事务隔离级别呢？

为了解决上述这些问题，就有了“隔离性”的概念，它要求每个事务都应该与其他事务隔离开来，多个事务在并发执行过程中不会互相干扰。

一个事务与其他事务隔离的程度称为隔离级别。在谈隔离级别之前，首先要知道，**隔离级别越高，数据一致性就越好，但效率越弱**。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL标准的事务隔离级别包括：**读未提交（READ_UNCOMMITTED）、读提交（READ_COMMITTED）、可重复读（REPEATABLE_READ）和串行化（SERIALIZABLE）**。

| 隔离级别         | 含义                                                         | 举例                                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| READ_UNCOMMITTED | 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 | 允许A读取B未提交的修改。                                     |
| READ_COMMITTED   | 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 | 要求A只能读取B已提交的修改。                                 |
| REPEATABLE_READ  | 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 | 确保A可以多次从一个字段中读取到相同的值，即A执行期间禁止其它事务对这个字段进行更新。 |
| SERIALIZABLE     | 最高的隔离级别，完全服从ACID的隔离级别，确保阻止脏读、不可重复读以及幻读。 | 确保A可以多次从一个表中读取到相同的行，在A执行期间，禁止其它事务对这个表进行添加、更新、删除操作。可以避免任何并发问题，但性能十分低下。 |

各个隔离级别所能解决的并发问题（x——不能解决，√——能解决）：

| 隔离级别     | 脏读 | 不可重复读 | 幻读        |
| ------------ | ---- | ---------- | ----------- |
| RU           | ×    | ×          | ×           |
| RC           | √    | ×          | ×           |
| RR           | √    | √          | ×（可解决） |
| SERIALIZABLE | √    | √          | √           |

> 其实 RR 也是可以避免幻读的，通过对 select 操作手动加 行X锁（SELECT … FOR UPDATE 这也正是 SERIALIZABLE 隔离级别下会隐式为你做的事情），同时还需要知道，即便当前记录不存在，比如 id = 1 是不存在的，当前事务也会获得一把记录锁（因为`InnoDB`的行锁锁定的是索引，故记录实体存在与否没关系，存在就加行X锁，不存在就加 next-key lock间隙X锁），其他事务则无法插入此索引的记录，故杜绝了幻读。
>
> 必读 [《MySQL 幻读的详解、实例及解决办法》](https://segmentfault.com/a/1190000016566788) 案例性更强，易懂。
>

通俗的理解：

* 读未提交，一个事务还未提交时，它的变更就能被别的事务所看到。
* 读提交，指的是一个事务提交之后，才能被其他事务所看到。
* 可重复读，指的是一个事务执行过程所看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
* 串行化，指的是对于同一行记录，“写”会加写锁，“读”会加读锁。当出现读写锁冲突的时候，后访问事务必须等前一个事务执行完成，才能继续执行。

各种数据库产品对事务隔离级别的支持程度：

| 隔离级别         | Oracle  | MySQL   |
| ---------------- | ------- | ------- |
| READ_UNCOMMITTED | ×       | √       |
| READ_COMMITTED   | √(默认) | √       |
| REPEATABLE_READ  | ×       | √(默认) |
| SERIALIZABLE     | √       | √       |

## 事务的实现原理（MVCC）是什么？

多版本并发控制（MVCC），是一种用来**解决读-写冲突**的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读。

推荐可以看看如下资料：

- 沈询 [《在线分布式数据库原理与实践》](https://www.imooc.com/learn/272)

  > 一共 1 小时 53 分钟，有趣，牛逼，强烈推荐！！！

- 钟延辉

  - [《分布式数据库 MVCC 技术探秘 (1)》](https://mp.weixin.qq.com/s/sOxLZlXRYR-zZKStE7qAwg)
  - [《分布式数据库 MVCC 技术探秘(2): 混合逻辑时钟》](https://mp.weixin.qq.com/s/8lX3Gyq4J5vLHETtG01EdA)

## 事务启动方式有哪些？

MySQL的事务启动方式有以下几种：

1. **显式启动事务语句**， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。

```mysql
START TRANSACTION;
-- 事务代码
commit;
```

2. **`set autocommit=0`**，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。

有些客户端连接框架会默认连接成功后先执行一个`set autocommit=0`的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。因此，**建议开发中总是使用`set autocommit=1`，之后通过显式语句的方式来启动事务。**

# 锁机制

## 全局锁、表级锁与行锁

根据**加锁的范围**，MySQL里面的锁大致可以分成**全局锁、表级锁和行锁**三类。

**全局锁**：全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 **Flush tables with read lock (FTWRL)**。全局锁会让其他线程的DDL、DML都阻塞，只有DQL正常运行。**全局锁的典型使用场景是，做全库逻辑备份。**

* 既然要全库只读，为什么不使用`set global readonly=true`的方式呢？
* （1）在有些系统中，`readonly`的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。（2）在异常处理机制上有差异。执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为`readonly`之后，如果客户端发生异常，则数据库就会一直保持`readonly`状态，这样会导致整个库长时间处于不可写状态，风险较高。

**表级锁**：MySQL里面表级别的锁有两种：**一种是表锁，一种是元数据锁**（meta data lock，MDL)。

* **表锁的语法是 lock tables … read/write。**与FTWRL类似，可以用`unlock tables`主动释放锁，也可以在客户端断开的时候自动释放。需要注意，`lock tables`语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
  * 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于`InnoDB`这种支持行锁的引擎，一般不使用`lock tables`命令来控制并发，毕竟锁住整个表的影响面还是太大。
* 另一类表级的锁是**MDL（metadata lock)**。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。
  * 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
  * 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

**行锁**：**行锁就是针对数据表中行记录的锁**。`InnoDB`是支持行锁的，`MyISAM`不支持行锁。

* 在`InnoDB`事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。所以，**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放**。

 **MySQL 中 `InnoDB` 引擎的行锁是通过加在什么上完成(或称实现)的？为什么是这样子的？？**

`InnoDB` 是基于索引来完成行锁。例如：`SELECT * FROM tab_with_index WHERE id = 1 FOR UPDATE` 。

- `FOR UPDATE` 可以根据条件来完成**行锁**锁定，并且 id 是有索引键的列，如果 id 不是索引键那么 `InnoDB` 将完成**表锁**，并发将无从谈起。

## 乐观锁和悲观锁

**悲观锁**

* 它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。
* 在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。

**乐观锁**

* 相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。
* 而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。

## 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为**死锁**。

当出现死锁以后，有两种策略：

- 一种策略是，**直接进入等待，直到超时**。这个超时时间可以通过参数`innodb_lock_wait_timeout`（默认值为50s）来设置。
- 另一种策略是，**发起死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数`innodb_deadlock_detect`设置为`on`，表示开启这个逻辑。

**正常情况下我们还是要采用第二种策略，即：主动死锁检测**，而且`innodb_deadlock_detect`的默认值本身就是on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的（**整体死锁检测的时间复杂度为O(n^2^)**）。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。

如何解决死锁检测消耗资源大的问题呢？

- 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉（风险大）。
- 另一个思路是**控制并发度**。如利用中间件；一行改多行... ...

## MySQL锁机制

https://www.infoq.cn/article/zau0ewzsdtx9zofr6c8w

> todo

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210709220533750.png" width="500px"/>
</div>

## MySQL锁优化

> todo

# 日志

## redo log（重做日志）

## binlog（归档日志）

🦅 **各种日志格式的涵义**

binlog 有三种格式类型，分别如下：

1）Statement

每一条会修改数据的 SQL 都会记录在 binlog 中。

- 优点：不需要记录每一行的变化，减少了 binlog 日志量，节约了 IO，提高性能。(相比 row 能节约多少性能与日志量，这个取决于应用的 SQL 情况，正常同一条记录修改或者插入 row 格式所产生的日志量还小于 Statement 产生的日志量，但是考虑到如果带条件的 update 操作，以及整表删除，alter 表等操作，ROW 格式会产生大量日志，因此在考虑是否使用 ROW 格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的 IO 性能问题。)

- 缺点：由于记录的只是执行语句，为了这些语句能在 slave 上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在 slave 得到和在 master 端执行时候相同 的结果。另外 MySQL 的复制，像一些特定函数功能，slave 可与 master 上要保持一致会有很多相关问题(如 `sleep()` 函数，`last_insert_id()`，以及 user-defined functions(udf) 会出现问题)。

- 使用以下函数的语句也无法被复制：

  - `LOAD_FILE()`

  - `UUID()`

  - `USER()`

  - `FOUND_ROWS()`

  - `SYSDATE()` (除非启动时启用了 `--sysdate-is-now` 选项)

    > 同时在 INSERT …SELECT 会产生比 RBR 更多的行级锁 。

2）Row

不记录 SQL 语句上下文相关信息，仅保存哪条记录被修改。

- 优点：binlog 中可以不记录执行的 SQL 语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以 rowlevel 的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或 function ，以及 trigger 的调用和触发无法被正确复制的问题。
- 缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容,比如一条 Update 语句，修改多条记录，则 binlog 中每一条修改都会有记录，这样造成 binlog 日志量会很大，特别是当执行 alter table 之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。

3）Mixedlevel

是以上两种 level 的混合使用。

- 一般的语句修改使用 Statement 格式保存 binlog 。
- 如一些函数，statement 无法完成主从复制的操作，则采用 Row 格式保存 binlog 。

MySQL 会根据执行的每一条具体的 SQL 语句来区分对待记录的日志形式，也就是在 Statement 和 Row 之间选择 一种。

新版本的 MySQL 中对 row level 模式也被做了优化，并不是所有的修改都会以 row level 来记录。

- 像遇到表结构变更的时候就会以 Statement 模式来记录。
- 至于 Update 或者 Delete 等修改数据的语句，还是会记录所有行的变更，即使用 Row 模式。

🦅 **适用场景？**

在一条 SQL 操作了多行数据时， Statement 更节省空间，Row 更占用空间。但是， Row 模式更可靠。

因为，互联网公司，使用 MySQL 的功能相对少，基本不使用存储过程、触发器、函数的功能，选择默认的语句模式，Statement Level（默认）即可。

🦅 **结合第一个问题，每一种日志格式在复制中的优劣？**

- Statement 可能占用空间会相对小一些，传送到 slave 的时间可能也短，但是没有 Row 模式的可靠。
- Row 模式在操作多行数据时更占用空间，但是可靠。

所以，这是在占用空间和可靠之间的选择。

**如何在线正确清理 MySQL binlog？**

MySQL 中的 binlog 日志记录了数据中的数据变动，便于对数据的基于时间点和基于位置的恢复。但日志文件的大小会越来越大，占用大量的磁盘空间，因此需要定时清理一部分日志信息。

```
# 首先查看主从库正在使用的binlog文件名称
show master(slave) status

# 删除之前一定要备份
purge master logs before'2017-09-01 00:00:00'; # 删除指定时间前的日志
purge master logs to'mysql-bin.000001'; # 删除指定的日志文件

# 自动删除：通过设置binlog的过期时间让系统自动删除日志
show variables like 'expire_logs_days'; # 查看过期时间
set global expire_logs_days = 30; # 设置过期时间
```

## undo log（回滚日志）

## 事务是如何通过日志来实现呢？

基本流程如下：

- 因为事务在修改页时，要先记 undo ，在记 undo 之前要记 undo 的 redo， 然后修改数据页，再记数据页修改的 redo。 redo（里面包括 undo 的修改）一定要比数据页先持久化到磁盘。
- 当事务需要回滚时，因为有 undo，可以把数据页回滚到前镜像的状态。
- 崩溃恢复时，如果 redo log 中事务没有对应的 commit 记录，那么需要用 undo 把该事务的修改回滚到事务开始之前。如果有 commit 记录，就用 redo 前滚到该事务完成时并提交掉。

## 两阶段提交是什么？

## 慢查询日志是什么？

# 数据库优化

[《PHP 面试之 MySQL 查询优化》](https://www.jianshu.com/p/ab958a4823d1)

## 你如何做MySQL性能优化呢？

数据表的优化（符合3范式）

1. 1范式：1NF是对属性的原子性约束，要求属性具有原子性，不可再分解；(只要是关系型数据库都满足1NF)
2. 2范式：2NF是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性；
3. 3范式：3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。没有冗余的数据库设计可以做到
4. 但是，没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，就必须降低范式标准，适当保留冗余数据。具体做法是：在概念数据模型设计时遵守第三范式，降低范式标准的工作放到物理数据模型设计时考虑。降低范式就是增加字段，允许冗余。

sql语句优化  索引

使用order by null禁用排序。group by 默认情况下会排序（file sorting），非常费时。

使用join代替子查询（子查询会默认创建临时表）

分表：

1. 垂直分割：将字段分开
2. 水平分割：将记录分开

读写分离

## 遇见一些个sql慢如何排查问题？如何优化？

explain  sql语句之后，看哪些字段？

嵌套查询，子查询优化有没有做过？

多连表查询如何优化。关联查询优化





## MySQL 数据库 CPU 飙升到 500% 的话，怎么处理？

当 CPU 飙升到 500% 时，先用操作系统命令 top 命令观察是不是 mysqld 占用导致的，如果不是，找出占用高的进程，并进行相关处理。

> 如果此时是 IO 压力比较大，可以使用 iostat 命令，定位是哪个进程占用了磁盘 IO 。

如果是 mysqld 造成的，使用 `show processlist` 命令，看看里面跑的 Session 情况，是不是有消耗资源的 SQL 在运行。找出消耗高的 SQL ，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。一般来说，肯定要 kill 掉这些线程(同时观察 CPU 使用率是否下降)，等进行相应的调整(比如说加索引、改 SQL 、改内存参数)之后，再重新跑这些 SQL。

> 也可以查看 MySQL 慢查询日志，看是否有慢 SQL 。

也有可能是每个 SQL 消耗资源并不多，但是突然之间，有大量的 Session 连进来导致 CPU 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。

🦅 **在 MySQL 服务器运行缓慢的情况下输入什么命令能缓解服务器压力？**

> 这个回答，和上面的回答思路是差不多的，优秀在更有层次感。

1）检查系统的状态

通过操作系统的一些工具检查系统的状态，比如 CPU、内存、交换、磁盘的利用率，根据经验或与系统正常时的状态相比对，有时系统表面上看起来看空闲，这也可能不是一个正常的状态，因为 CPU 可能正等待IO的完成。除此之外，还应观注那些占用系统资源(CPU、内存)的进程。

- 使用 sar 来检查操作系统是否存在 IO 问题。
- 使用 vmstat 监控内存 CPU 资源。
- 磁盘 IO 问题，处理方式：做 raid10 提高性能 。
- 网络问题，telnet 一下 MySQL 对外开放的端口。如果不通的话，看看防火墙是否正确设置了。另外，看看 MySQ L是不是开启了 skip-networking 的选项，如果开启请关闭。

2）检查 MySQL 参数

- max_connect_errors
- connect_timeout
- skip-name-resolve
- slave-net-timeout=seconds
- master-connect-retry

3）检查 MySQL 相关状态值

- 关注连接数
- 关注下系统锁情况
- 关注慢查询（slow query）日志

# 其他问题

## MySQL 主从复制的流程是怎么样的？

MySQL 的主从复制是基于如下 3 个线程的交互（多线程复制里面应该是 4 类线程）：

- 1、Master 上面的 binlog dump 线程，该线程负责将 master 的 binlog event 传到 slave 。
- 2、Slave 上面的 IO 线程，该线程负责接收 Master 传过来的 binlog，并写入 relay log 。
- 3、Slave 上面的 SQL 线程，该线程负责读取 relay log 并执行。
- 4、如果是多线程复制，无论是 5.6 库级别的假多线程还是 MariaDB 或者 5.7 的真正的多线程复制， SQL 线程只做 coordinator ，只负责把 relay log 中的 binlog 读出来然后交给 worker 线程， woker 线程负责具体 binlog event 的执行。

🦅 **MySQL 如何保证复制过程中数据一致性？**

> 艿艿：这个问题比较难，理解不了也没问题。我自己也没完全理解，主要是网络找到这个答案，后续有精力在研究。

- 1、在 MySQL5.5 以及之前， slave 的 SQL 线程执行的 relay log 的位置只能保存在文件（ relay-log.info）里面，并且该文件默认每执行 10000 次事务做一次同步到磁盘， 这意味着 slave 意外 crash 重启时， SQL 线程执行到的位置和数据库的数据是不一致的，将导致复制报错，如果不重搭复制，则有可能会导致数据不一致。
  - MySQL 5.6 引入参数 relay_log_info_repository，将该参数设置为 TABLE 时， MySQL 将 SQL 线程执行到的位置存到 mysql.slave_relay_log_info 表，这样更新该表的位置和 SQL 线程执行的用户事务绑定成一个事务，这样 slave 意外宕机后，slave 通过 innodb 的崩溃恢复可以把 SQL 线程执行到的位置和用户事务恢复到一致性的状态。
- 2、MySQL 5.6 引入 GTID 复制，每个 GTID 对应的事务在每个实例上面最多执行一次， 这极大地提高了复制的数据一致性。
- 3、MySQL 5.5 引入半同步复制， 用户安装半同步复制插件并且开启参数后，设置超时时间，可保证在超时时间内如果 binlog 不传到 slave 上面，那么用户提交事务时不会返回，直到超时后切成异步复制，但是如果切成异步之前用户线程提交时在 master 上面等待的时候，事务已经提交，该事务对 master 上面的其他 session 是可见的，如果这时 master 宕机，那么到 slave 上面该事务又不可见了，该问题直到 5.7 才解决。
- 4、MySQL 5.7 引入无损半同步复制，引入参 rpl_semi_sync_master_wait_point，该参数默认为 after_sync，指的是在切成半同步之前，事务不提交，而是接收到 slave 的 ACK 确认之后才提交该事务，从此，复制真正可以做到无损的了。
- 5、可以再说一下 5.7 的无损复制情况下， master 意外宕机，重启后发现有 binlog 没传到 slave 上面，这部分 binlog 怎么办？？？分 2 种情况讨论， 1 宕机时已经切成异步了， 2 是宕机时还没切成异步？？？ 这个怎么判断宕机时有没有切成异步呢？？？ 分别怎么处理？？？

🦅 **MySQL 如何解决主从复制的延时性？**

5.5 是单线程复制，5.6 是多库复制（对于单库或者单表的并发操作是没用的），5.7 是真正意义的多线程复制，它的原理是基于 group commit， 只要 master 上面的事务是 group commit 的，那 slave 上面也可以通过多个 worker线程去并发执行。 和 MairaDB10.0.0.5 引入多线程复制的原理基本一样。

🦅 **工作遇到的复制 bug 的解决方法？**

5.6 的多库复制有时候自己会停止，我们写了一个脚本重新 start slave 。

🦅 **你是否做过主从一致性校验，如果有，怎么做的，如果没有，你打算怎么做？**

主从一致性校验有多种工具 例如 checksum、mysqldiff、pt-table-checksum 等。

## 聊聊 MySQL 备份方式？备份策略是怎么样的？

具体的，胖友可以看看 [《MySQL 高级备份策略》](http://www.qinglin.net/1015.html) 。主要有几个知识点：

- 数据的备份类型

  - 【常用】完全备份

    > 这是大多数人常用的方式，它可以备份整个数据库，包含用户表、系统表、索引、视图和存储过程等所有数据库对象。但它需要花费更多的时间和空间，所以，一般推荐一周做一次完全备份。

  - 增量备份

    > 它是只备份数据库一部分的另一种方法，它不使用事务日志，相反，它使用整个数据库的一种新映象。它比最初的完全备份小，因为它只包含自上次完全备份以来所改变的数据库。它的优点是存储和恢复速度快。推荐每天做一次差异备份。

  - 【常用】事务日志备份

    > 事务日志是一个单独的文件，它记录数据库的改变，备份的时候只需要复制自上次备份以来对数据库所做的改变，所以只需要很少的时间。为了使数据库具有鲁棒性，推荐每小时甚至更频繁的备份事务日志。

  - 文件备份

    > 数据库可以由硬盘上的许多文件构成。如果这个数据库非常大，并且一个晚上也不能将它备份完，那么可以使用文件备份每晚备份数据库的一部分。由于一般情况下数据库不会大到必须使用多个文件存储，所以这种备份不是很常用。

- 备份数据的类型

  - 热备份
  - 温备份
  - 冷备份

- 备份工具

  - cp
  - mysqldump
  - xtrabackup
  - lvm2 快照

🦅 **MySQL 几种备份方式？**

MySQL 一般有 3 种备份方式。

1）逻辑备份

使用 MySQL 自带的 mysqldump 工具进行备份。备份成sql文件形式。

- 优点：最大好处是能够与正在运行的 MySQL 自动协同工作，在运行期间可以确保备份是当时的点，它会自动将对应操作的表锁定，不允许其他用户修改(只能访问)。可能会阻止修改操作。SQL 文件通用方便移植。
- 缺点：备份的速度比较慢。如果是数据量很多的时候，就很耗时间。如果数据库服务器处在提供给用户服务状态，在这段长时间操作过程中，意味着要锁定表(一般是读锁定，只能读不能写入数据)，那么服务就会影响的。

2）物理备份

> 艿艿：因为现在主流是 InnoDB ，所以基本不再考虑这种方式。

直接拷贝只适用于 MyISAM 类型的表。这种类型的表是与机器独立的。但实际情况是，你设计数据库的时候不可能全部使用 MyISAM 类型表。你也不可能因为 MyISAM 类型表与机器独立，方便移植，于是就选择这种表，这并不是选择它的理由。

- 缺点：你不能去操作正在运行的 MySQL 服务器(在拷贝的过程中有用户通过应用程序访问更新数据，这样就无法备份当时的数据)，可能无法移植到其他机器上去。

3）双机热备份。

当数据量太大的时候备份是一个很大的问题，MySQL 数据库提供了一种主从备份的机制，也就是双机热备。

- 优点：适合数据量大的时候。现在明白了，大的互联网公司对于 MySQL 数据备份，都是采用热机备份。搭建多台数据库服务器，进行主从复制。

🦅 **数据库不能停机，请问如何备份? 如何进行全备份和增量备份?**

可以使用逻辑备份和双机热备份。

- 完全备份：完整备份一般一段时间进行一次，且在网站访问量最小的时候，这样常借助批处理文件定时备份。主要是写一个批处理文件在里面写上处理程序的绝对路径然后把要处理的东西写在后面，即完全备份数据库。
- 增量备份：对 ddl 和 dml 语句进行二进制备份。且 5.0 无法增量备份，5.1 后可以。如果要实现增量备份需要在 `my.ini` 文件中配置备份路径即可，重启 MySQL 服务器，增量备份就启动了。

🦅 **你的备份工具的选择？备份计划是怎么样的？**

视库的大小来定，一般来说 100G 内的库，可以考虑使用 mysqldump 来做，因为 mysqldump 更加轻巧灵活，备份时间选在业务低峰期，可以每天进行都进行全量备份(mysqldump 备份出来的文件比较小，压缩之后更小)。

100G 以上的库，可以考虑用 xtrabackup 来做，备份速度明显要比 mysqldump 要快。一般是选择一周一个全备，其余每天进行增量备份，备份时间为业务低峰期。

> 艿艿：一般情况下，选择每周备份 + 每天增量备份比较靠谱。

🦅 **备份恢复时间是多长？**

物理备份恢复快，逻辑备份恢复慢。

这里跟机器，尤其是硬盘的速率有关系，以下列举几个仅供参考：

- 20G 的 2 分钟（mysqldump）
- 80G 的 30分钟（mysqldump)
- 111G 的 30分钟（mysqldump)
- 288G 的 3 小时（xtrabackup)
- 3T 的 4 小时（xtrabackup)

逻辑导入时间一般是备份时间的 5 倍以上。

🦅 **备份恢复失败如何处理？**

首先在恢复之前就应该做足准备工作，避免恢复的时候出错。比如说备份之后的有效性检查、权限检查、空间检查等。如果万一报错，再根据报错的提示来进行相应的调整。

🦅 **mysqldump 和 xtrabackup 实现原理？**

1）mysqldump

mysqldump 是最简单的逻辑备份方式。

- 在备份 MyISAM 表的时候，如果要得到一致的数据，就需要锁表，简单而粗暴。
- 在备份 InnoDB 表的时候，加上 `–master-data=1 –single-transaction` 选项，在事务开始时刻，记录下 binlog pos 点，然后利用 MVCC 来获取一致的数据，由于是一个长事务，在写入和更新量很大的数据库上，将产生非常多的 undo ，显著影响性能，所以要慎用。
- 优点：简单，可针对单表备份，在全量导出表结构的时候尤其有用。
- 缺点：简单粗暴，单线程，备份慢而且恢复慢，跨 IDC 有可能遇到时区问题

2）xtrabackup

xtrabackup 实际上是物理备份+逻辑备份的组合。

- 在备份 InnoDB 表的时候，它拷贝 ibd 文件，并一刻不停的监视 redo log 的变化，append 到自己的事务日志文件。在拷贝 ibd 文件过程中，ibd文件本身可能被写”花”，这都不是问题，因为在拷贝完成后的第一个 prepare 阶段，xtrabackup 采用类似于 Innodb 崩溃恢复的方法，把数据文件恢复到与日志文件一致的状态，并把未提交的事务回滚。
- 如果同时需要备份 MyISAM 表以及 InnoDB 表结构等文件，那么就需要用 `flush tables with lock` 来获得全局锁，开始拷贝这些不再变化的文件，同时获得 binlog 位置，拷贝结束后释放锁，也停止对 redo log 的监视。

🦅 **如何从 mysqldump 产生的全库备份中只恢复某一个库、某一张表？**

具体可见 [《MySQL 全库备份中恢复某个库和某张表以及 mysqldump 参数 –ignore-table 介绍》](http://blog.51cto.com/wujianwei/1959473) 文章。

## 聊聊 MySQL 集群?

> 艿艿：这块艿艿懂的少，主要找了一些网络上的资料。

- [《五大常见的 MySQL 高可用方案》](https://zhuanlan.zhihu.com/p/25960208)
- [《高性能、高可用、可扩展的 MySQL 集群如何组建？》](https://www.zhihu.com/question/21307639)

🦅 **对于简历中写有熟悉 MySQL 高可用方案？**

我一般先问他现在管理的数据库架构是什么，如果他只说出了主从，而没有说任何 HA 的方案，那么我就可以判断出他没有实际的 HA 经验。

不过这时候也不能就是断定他不懂 MySQL 高可用，也许是没有实际机会去使用，那么我就要问 [MMM](http://www.cnblogs.com/gomysql/p/3671896.html) 以及 [MHA](http://svip.iocoder.cn/MySQL/Interview/MySQL高可用架构之MHA) 以及 [MM + keepalived](http://blog.51cto.com/sumongodb/1953244) 等的原理、实现方式以及它们之间的优势和不足了，一般这种情况下，能说出这个的基本没有。

- MMM 那东西好像不靠谱，据说不稳定，但是有人在用的，和 mysql-router 比较像，都是指定可写的机器和只读机器。
- MHA 的话一句话说不完，可以搜索下相关博客。

🦅 **使用过其他分支版本的数据库吗？Percona、Mariadb 等。对Percona 的 pxc 集群了解吗？**

除了 Oracle 旗下的 MySQL 外，我还使用过 Percona Server 。

Percona 是在原生 MySQL 的基础上，进行了优化和改进，所以 Percona 的性能比 MySQL 更好。

- 目前，我知道 Percona 提供免费的线程池功能，而社区版的 MySQL 没有线程池的功能（当然，企业版的mysql是有线程池的，但是需要收费）
- 另外 Percona 还支持 NUMA 等功能。

我熟悉 pxc ，我曾经在测试环境搭建过 pxc ，但是没有在生产上使用，因为目前使用 pxc 的企业不是很多，目前我知道搜狐在用 pxc 。

- pxc 是摒弃 MySQL 主从的概念，即对于 pxc 来说，每个节点都可以读写，并且写一份数据，其他节点会同时拥有，这是一种同步的复制方案（区别于 MySQL 主从的异步复制）。



