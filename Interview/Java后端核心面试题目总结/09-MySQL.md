# MySQL基础

## 一条SQL语句是如何执行的？

当一条查询MySQL语句执行时，主要经历如下流程：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210611090819527.png" width="500px"/>
</div>

* 连接器：管理连接，权限校验。
* 查询缓存：在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果命中缓存直接返回结果；如过没有命中缓存，进行下一步。
* 分析器：通过词法分析，提取sql语句的关键元素；通过语法分析，验证sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。
* 优化器：执行计划生成，索引选择。

* 执行器：调用数据库引擎接口，返回引擎的执行结果。

当一条更新MySQL语句执行时，大致流程与查询语句MySQL执行流程一致。但需要注意的是，只要有对一个表更新了，这个表上之前的所有的查询缓存都会被清空。对于更新压力大的数据库来说，查询缓存的命中率会非常低。所以我们不建议使用查询缓存。

## MySQL 查询执行顺序？

MySQL 查询执行的顺序是：

```mysql
(1)     SELECT
(2)     DISTINCT <select_list>
(3)     FROM <left_table>
(4)     <join_type> JOIN <right_table>
(5)     ON <join_condition>
(6)     WHERE <where_condition>
(7)     GROUP BY <group_by_list>
(8)     HAVING <having_condition>
(9)     ORDER BY <order_by_condition>
(10)    LIMIT <limit_number>
```

## delete drop truncate区别

- truncate 和 delete只删除数据，不删除表结构 ；drop删除表结构，并且释放所占的空间。
- **删除数据的速度**，一般来说: **drop> truncate > delete**
- delete属于DML语言，需要事务管理，commit之后才能生效。drop和truncate属于DDL语言，操作立刻生效，不可回滚。
- 使用场合：
  - 当你不再需要该表时， 用 drop;
  - 当你仍要保留该表，但要删除所有记录时， 用 truncate;
  - 当你要删除部分记录时（always with a where clause), 用 delete.

**注意：**对于有主外键关系的表，不能使用truncate而应该使用不带where子句的delete语句，由于truncate不记录在日志中，不能够激活触发器。

## 自增主键一定连续吗？用完了怎么办？

# 索引

## 什么是索引？为什么要使用索引？使用场景？

**索引，就类似书籍的目录一样，可以提高数据查询的效率**。一本500页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。

这里总结了索引的**优点**：

1. 可以大大加快数据的检索速度（大大减少的检索的数据量）,  这也是创建索引的最主要的原因。
2. 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
3. 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表）。
4. 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

索引有什么**缺点**呢？

1. 占用存储空间：索引实际上也是一张表，记录了主键与索引字段，一般以索引文件的形式存储在磁盘上。
2. 降低更新表的速度：表的数据发生了变化，对应的索引也需要一起变更，从而减低的更新速度。否则索引指向的物理数据可能不对，这也是索引失效的原因之一。

**索引的使用场景？**

- 1、对非常小的表，大部分情况下全表扫描效率更高。

- 2、对中大型表，索引非常有效。

- 3、特大型的表，建立和使用索引的代价随着增长，可以使用分区技术来解决。

## 索引的分类？

索引，都是实现在存储引擎层的。主要有六种类型：

- **普通索引**：最基本的索引，没有任何约束。

- **唯一索引**：与普通索引类似，但具有唯一性约束。

- **主键索引**：特殊的唯一索引，不允许有空值。

- **复合索引/联合索引**：将多个列组合在一起创建索引，可以覆盖多个列。

- **外键索引**：只有`InnoDB`类型的表才可以使用外键索引，保证数据的一致性、完整性和实现级联操作。

- **全文索引**：MySQL 自带的全文索引只能用于 `InnoDB`、`MyISAM` ，并且只能对英文进行全文检索，一般使用全文索引引擎。

  > 常用的全文索引引擎的解决方案有 Elasticsearch、Solr 等等。最为常用的是 Elasticsearch 。

具体的使用，可以看看 [《服务端指南 数据存储篇 | MySQL（03） 如何设计索引》](http://blog.720ui.com/2017/mysql_core_03_how_use_index/) 。

## 如何创建及使用索引？

**MySQL 索引的“创建”原则？**

1. 最适合索引的列是出现在 `WHERE` 子句中的列，或连接子句中的列，而不是出现在 `SELECT` 关键字后的列。
2. 索引列的基数越大，索引效果越好。
3. 根据情况创建复合索引，复合索引可以提高查询效率。
4. 避免创建过多的索引，索引会额外占用磁盘空间，降低写操作效率。
5. 主键尽可能选择较短的数据类型，可以有效减少索引的磁盘占用提高查询效率。
6. 对字符串进行索引，应该定制一个前缀长度，可以节省大量的索引空间。

**MySQL 索引的“使用”注意事项？**

- 1、应尽量避免在 `WHERE` 子句中使用 `!=` 或 `<>` 操作符，否则将引擎放弃使用索引而进行全表扫描。优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。

  > 注意，`column IS NULL` 也是不可以使用索引的。

- 2、应尽量避免在 `WHERE` 子句中使用 `OR` 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：`SELECT id FROM t WHERE num = 10 OR num = 20` 。

- 3、应尽量避免在 `WHERE` 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。

- 4、应尽量避免在 `WHERE` 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。

- 5、不要在 `WHERE` 子句中的 `=` 左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。

- 6、复合索引遵循前缀原则。

- 7、如果 MySQL 评估使用索引比全表扫描更慢，会放弃使用索引。如果此时想要索引，可以在语句中添加强制索引。

- 8、列类型是字符串类型，查询时一定要给值加引号，否则索引失效。

- 9、`LIKE` 查询，`%` 不能在前，因为无法使用索引。如果需要模糊匹配，可以使用全文索引。

**以下三条 SQL 如何建索引，只建一条怎么建？**

```
WHERE a = 1 AND b = 1
WHERE b = 1
WHERE b = 1 ORDER BY time DESC
```

- 以顺序 b , a, time 建立复合索引，`CREATE INDEX table1_b_a_time ON index_test01(b, a, time)`。
- 对于第一条 SQL ，因为最新 MySQL 版本会优化 `WHERE` 子句后面的列顺序，以匹配复合索引顺序。

**想知道一个查询用到了哪个索引，如何查看?**

`EXPLAIN` 显示了 MYSQL 如何使用索引来处理 SELECT 语句以及连接表,可以帮助选择更好的索引和写出更优化的查询语句。

使用方法，在 `SELECT` 语句前加上 `EXPLAIN` 就可以了。

## 常见的索引模型有哪些？

**哈希表**

* 哈希表是一种以键-值（key-value）存储数据的结构。问题是，**哈希索引做区间查询的速度挺慢的**。所以，**哈希表这种结构适用于只有等值查询的场景**，适用于`Memcached`及其他一些NoSQL引擎。

**有序数组**

* **有序数组在等值查询和范围查询场景中的性能就都非常优秀**。如果仅仅看查询效率，有序数组很完美。但是，在需要更新数据的时，每在中间插入一个记录就必须挪动后面所有的记录，成本太高。所以，**有序数组索引只适用于静态存储引擎**，比如要保存的是2008年某个城市的所有人口信息（这类数据后续不会再被修改）。

**二叉搜索树**

* 二叉搜索树是经典的数据结构。二叉搜索树的特点是：每个父节点都有两个子节点（子节点可能为空），每个左子节点都比父节点小，每个右子节点比父节点大。
* 二叉搜索树搜索效率挺高，但是实际上大多数的数据库存储却并不使用，原因在于数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。所以我们要减少I/O次数，对于树来说，IO次数就是树的高度。
* 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，**“N叉”树中的“N”取决于数据块的大小**。
  * 以`InnoDB`的一个整数字段索引为例，这个N差不多是**1200**。这棵树高是4的时候，就可以存1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

## InnoDB 索引原理？

关于索引原理，可以参考以下几篇文章：

- [《MySQL索引背后的数据结构及算法原理》](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

- [《MySQL 索引原理》](https://blog.csdn.net/u013235478/article/details/50625677)

- [《深入理解 MySQL 索引原理和实现 —— 为什么索引可以加速查询？》](https://blog.csdn.net/tongdanping/article/details/79878302)

### InnoDB 的索引模型 B+Tree

在了解B+Tree之前，我们需先了解一下磁盘及B-Tree相关知识。

**磁盘基础知识**

系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。

`InnoDB`存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。`InnoDB`存储引擎中默认每个页的大小为 16 KB，可通过参数 `innodb_page_size` 将页的大小设置为 4K、8K、16K ，在 MySQL 中可通过命令查看页的大：`show variables like 'innodb_page_size';`

而系统一个磁盘块的存储空间往往没有这么大，因此 `InnoDB` 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小`16KB` 。`InnoDB` 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘 I/O 次数，提高查询效率。

**那什么是 B-Tree 索引？**

B-Tree 是为磁盘等外存储设备设计的一种平衡查找树。B-Tree 结构的数据可以**让系统高效的找到数据所在的磁盘块**。为了描述B-Tree，首先定义一条记录为一个二元组 [key, data] ，key 为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。

一棵 m 阶的 B-Tree 有如下特性：

1. 每个节点最多有 m 个孩子。
   - 除了根节点和叶子节点外，其它每个节点至少有 Ceil(m/2) 个孩子。
   - 若根节点不是叶子节点，则至少有 2 个孩子。
2. 所有叶子节点都在同一层，且不包含其它关键字信息。
3. 每个非叶子节点包含 n 个关键字信息（P0,P1,…Pn, k1,…kn）
   - 关键字的个数 n 满足：ceil(m/2)-1 <= n <= m-1
   - ki(i=1,…n) 为关键字，且关键字升序排序。
   - Pi(i=0,…n) 为指向子树根节点的指针。P(i-1) 指向的子树的所有节点关键字均小于 ki ，但都大于 k(i-1) 。

B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个 3 阶的 B-Tree：

<div align="center">  
<img src="http://static.iocoder.cn/84ea509fa091a10add4e7614e6cb37db" width="800px"/>
</div>

- 每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的 key 和三个指向子树根节点的 point ，point 存储的是子节点所在磁盘块的地址。两个 key 划分成的三个范围域，对应三个 point 指向的子树的数据的范围域。
- 以根节点为例，key 为 17 和 35 ，P1 指针指向的子树的数据范围为小于 17 ，P2 指针指向的子树的数据范围为 [17~35] ，P3 指针指向的子树的数据范围为大于 35 。

模拟查找 key 为 29 的过程：

1. 根据根节点找到磁盘块 1 ，读入内存。【磁盘I/O操作第1次】
2. 比较 key 29 在区间（17,35），找到磁盘块 1 的指针 P2 。
3. 根据 P2 指针找到磁盘块 3 ，读入内存。【磁盘I/O操作第2次】
4. 比较 key 29 在区间（26,30），找到磁盘块3的指针P2。
5. 根据 P2 指针找到磁盘块 8 ，读入内存。【磁盘I/O操作第3次】
6. 在磁盘块 8 中的 key 列表中找到 eky 29 。

分析上面过程，发现需要 3 次磁盘 I/O 操作，和 3 次内存查找操作。由于内存中的 key 是一个有序表结构，可以利用二分法查找提高效率。而 3 次磁盘 I/O 操作是影响整个 B-Tree 查找效率的决定因素。B-Tree 相对于 AVLTree 缩减了节点个数，使每次磁盘 I/O 取到内存的数据都发挥了作用，从而提高了查询效率。

**哪什么是 B+Tree 索引？**

B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构。在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为**索引组织表**。InnoDB使用了**B+树**索引模型，数据都是存储在B+树中的。每一个索引在InnoDB里面对应一棵B+树。**B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。**

从上面中的 B-Tree 结构图中可以看到，每个节点中不仅包含数据的 key 值，还有 data 值。而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小，当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。在 B+Tree 中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储 key 值信息，这样可以大大加大每个节点存储的 key 值数量，降低 B+Tree 的高度。

B+Tree 相对于 B-Tree 有几点不同：

- 非叶子节点只存储键值信息。
- 所有叶子节点之间都有一个链指针。
- 数据记录都存放在叶子节点中。

将上一节中的 B-Tree 优化，由于 B+Tree 的非叶子节点只存储键值信息，假设每个磁盘块能存储 4 个键值及指针信息，则变成 B+Tree 后其结构如下图所示：

<div align="center">  
<img src="http://static.iocoder.cn/259d196856a231aff5e3cf1505848af4" width="800px"/>
</div>

- 通常在 B+Tree 上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对 B+Tree 进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。

可能上面例子中只有 22 条数据记录，看不出 B+Tree 的优点，下面做一个推算：

* `InnoDB` 存储引擎中页大小为16KB，一般表的主键类型为 INT（占用4个字节） 或 BIGINT（占用8个字节），指针大小在`InnoDB`为6个字节，那么一个N = 16*1023/（8+6）= 1170 （约等1200）。如果高度为4层，1170^3=17亿。

- 实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree 的高度一般都在 2~4 层。MySQL 的 `InnoDB` 存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要 1~3 次磁盘 I/O 操作。

**B+Tree 有哪些索引类型？**

在 B+Tree 中，根据叶子节点的内容，索引类型分为**主键索引**和**非主键索引**。

* 主键索引的叶子节点存的是**整行数据**。在InnoDB里，主键索引也被称为**聚簇索引**（clustered index）。

* 非主键索引的叶子节点内容是**主键的值**。在InnoDB里，非主键索引也被称为**二级索引/辅助索引**（secondary index）。

假设，我们有一个主键列为ID的表，表中有字段k，并且在k上有索引。

```mysql
mysql> create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');
```

表中R1~R5行的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)，两棵树的示例示意图如下。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20201126220850358.png" width="500px"/>
<div align="center">图1 索引组织结构</divd>
</div>

二级索引与聚集索引的区别在于**二级索引的叶子节点并不包含行记录的全部数据，而是存储相应行数据的聚簇索引键，即主键**。

**基于主键索引和普通索引的查询有什么区别？**

- 如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
- 如果语句是select * from T where k=5，即辅助索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次找到具体行记录数据。这个过程称为**回表**。（回到主键索引树搜索的过程，称为回表）

另外，`InnoDB` 通过主键聚簇数据，如果没有定义主键，会选择一个唯一的非空索引代替，如果没有这样的索引，会隐式定义个主键作为聚簇索引。

### 为什么MySQL用B+树做索引而不用B-树或红黑树?

**为什么不用B-Tree?**

* 从上面的分析可以看出，**B+树只有叶节点存放数据，其余节点用来索引；而B-树是每个索引节点都会有Data域。**
* `InnoDB` 在把磁盘数据读磁盘时会以页为基本单位，大小是固定的16KB，节点中存放了data，这无疑就增加了磁盘IO次数。

**为什么不用红黑树？**

* 红黑树的树的深度往往过大，会造成磁盘IO读写过于频繁，进而导致效率低下。B+树的每层可以有1170个分叉，可以大大降低树的高度。
* 要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。

### 使用聚簇索引的注意点有哪些？

聚簇索引表最大限度地提高了 I/O 密集型应用的性能，但它也有以下几个限制：

- 1、插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于 InnoDB 表，我们一般都会定义一个自增的 ID 列为主键。

  > 关于这一点，可能面试官会换一个问法。例如，为什么主键需要是自增 ID ，又或者为什么主键需要带有时间性关联。

- 2、更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB 表，我们一般定义主键为不可更新。

  > MySQL 默认情况下，主键是允许更新的。对于 MongoDB ， 主键是不允许更新的。

- 3、二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

  > 当然，有一种情况可以无需二次查找，基于非主键索引查询，但是查询字段只有主键 ID ，那么在二级索引中就可以查找到。

- 4、主键 ID 建议使用整型。因为，每个主键索引的 B+Tree 节点的键值可以存储更多主键 ID ，每个非主键索引的 B+Tree 节点的数据可以存储更多主键 ID 。

### 什么是最左前缀匹配原则？

在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。

B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录，比如有索引`(a, b, c, d)`，查询条件`a = 1 and b = 2 and c > 3 and d = 4`，则会在每个节点依次命中a、b、c，无法命中d。(很简单：索引命中只能是**相等**的情况，不能是范围匹配)

- 当构建组合索引(a,b,c,d)时，实际上创建了(a), (a, b), (a, b, c), (a, b,c ,d)四个索引，每个索引先保证前面的key有序，再保证后面的key有序。实际上当查询条件`a = 1 and b = 2 and c > 3 `时，可以用索引(a, b, c)，因为在a，b相同的情况下，c是有序的。但是当查询条件`a = 1 and b = 2 and c > 3 and d = 4`时，就不能用上述建的索引中的任意一个。所以a，b，c命中，d无法命中，如果查询条件a = 1 and b = 2 and c = 3 and d > 4，那么d也命中，就用(a,b,c,d)索引。

> 索引只能用于查找key是否**存在（相等）**，遇到范围查询`(>、<、between、like`左匹配)等就**不能进一步匹配**了，后续退化为线性查找。

这里就引申出一个问题：在建立联合索引的时候，如何安排索引内的字段顺序？

* 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。
* 其次，考虑的原则就是空间。

**=、in自动优化顺序**

**不需要考虑=、in等的顺序**，MySQL会自动优化这些条件的顺序，以匹配尽可能多的索引列。

例子：如有索引`(a, b, c, d)`，查询条件`c > 3 and b = 2 and a = 1 and d < 4`与`a = 1 and c > 3 and b = 2 and d < 4`等顺序都是可以的，MySQL会自动优化为`a = 1 and b = 2 and c > 3 and d < 4`，依次命中a、b、c。

### 什么是覆盖索引？与联合索引区别？

还是一上面图1为例，如果执行查询SQL语句是`select * from T where k between 3 and 5`，执行流程如下：

* 在k索引树上找到k=3的记录，取得 ID = 300；
* 再到ID索引树查到ID=300对应的R3；
* 在k索引树取下一个值k=5，取得ID=500；
* 再回到ID索引树查到ID=500对应的R4；
* 在k索引树取下一个值k=6，不满足条件，循环结束。

在这个过程中，**回到主键索引树搜索的过程，我们称之为回表**。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。

在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？

如果执行的语句是`select ID from T where k between 3 and 5`，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

需要注意的是，在引擎内部使用覆盖索引在索引k上其实读了三个记录，R3~R5（对应的索引k上的记录项），但是对于MySQL的Server层来说，它就是找引擎拿到了两条记录，因此MySQL认为扫描行数是2。

**覆盖索引与联合索引区别？**

* 覆盖索引：如果查询条件使用的是普通索引（或是联合索引的最左前缀字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果。
* 联合索引：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。

### 什么是索引下推？

MySQL 5.6 引入的**索引下推优化（index condition pushdown)**， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，**减少回表次数，大大提升了查询的效率**。

如果一张市民表联合索引（name, age），主键为name，现在有一句SQL：

```mysql
select * from user where name like '张%' and age=10 and ismale=1;
```

如果没有索引下推的话，执行流程如下：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20201126225305587.png" width="500px"/>
</div>

 索引下推执行流程：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20201126225346324.png" width="500px"/>
</div>

> 每一个虚线箭头表示回表一次。

第一个图中，在(name,age)索引里面去掉了age的值，这个过程`InnoDB`并不会去看age的值，只是按顺序把“name第一个字是’张’”的记录一条条取出来回表。因此，需要回表4次。

第二图中，`InnoDB`在(name,age)索引内部就判断了age是否等于10，对于不等于10的记录，直接判断并跳过。在这个例子中，只需要对ID4、ID5这两条记录回表取数据判断，就只需要回表2次。

## MyISAM 如何实现索引？

MyISAM 索引的实现，和 InnoDB 索引的实现是一样使用 B+Tree ，**差别在于 MyISAM 索引文件和数据文件是分离的，索引文件仅保存数据记录的地址**。

（1）主键索引：

MyISAM引 擎使用B+Tree作为索引结构，**叶节点的data域存放的是数据记录的地址**。下图是MyISAM主键索引的原理图：

<div align="center">  
<img src="http://static.iocoder.cn/d49d260fc1eb8f992df0401b70d70e3d" width="500px"/>
</div>

- 这里设表一共有三列，假设我们以 Col1 为主键，上图是一个 MyISAM 表的主索引（Primary key）示意。可以看出 MyISAM 的索引文件仅仅保存数据记录的地址。

（2）辅助索引：

**在 MyISAM 中，主索引和辅助索引在结构上没有任何区别，只是主索引要求 key 是唯一的，而辅助索引的 key 可以重复。**如果我们在 Col2 上建立一个辅助索引，则此索引的结构如下图所示：

<div align="center">  
<img src="http://static.iocoder.cn/2fb922405a35479fa99eb2de4708638c" width="500px"/>
</div>

- 同样也是一颗 B+Tree ，data 域保存数据记录的地址。因此，**MyISAM 中索引检索的算法为首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址，读取相应数据记录。**

MyISAM 的索引方式也叫做“**非聚集**”的，之所以这么称呼是为了与InnoDB 的聚集索引区分。

**MyISAM 索引与 InnoDB 索引的区别？**

- InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引。

- InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效。

- MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。

- InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。


## MySQL 索引失效？

**索引失效的常见场景**

* **OR**导致索引失效：查询条件包含or，可能导致索引失效，如果要想使用`or`又不想让索引失效，那就得需要为`or`条件中的每个列都建立索引。
* **类型不一致**导致的索引失效：如何字段类型是字符串，where时一定用引号括起来，否则索引失效。
* **模糊查询**导致索引失效：使用模糊查询（like）的时候以`%`开头也会导致索引失效。（优化：使用覆盖索引/或把%放后面）
* **函数**导致索引失效：在索引列上使用MySQL的内置函数，索引失效。
* **运算符**导致索引失效：索引字段上使用（！= 或者 < >，not in）时，可能会导致索引失效。
* **not in、not exists**导致索引失效。
* 索引字段上使用**is null、 is not null**，可能导致索引失效。
* 左连接查询或者右连接查询查询关联的字段**编码格式**不一样，可能导致索引失效：比如一个表的编码是utf8mb4，而另外一个表字段编码为utf8。

* **联合索引如果不遵循最左前缀原则**，那么索引也将失效，例如**查询时的条件列不是联合索引中的第一个列，或者遇到范围查询（`>、<、!=、between、like`左匹配）**。

# 事务隔离

## 什么是事务？事务的关键特性？

简单来说，**事务**就是用户定义的一系列数据库操作，这些操作可以视为一个完成的逻辑处理工作单元（unit），**要么全部执行，要么全部不执行，是不可分割的工作单元**。

MySQL是一个支持多引擎的系统，但并不是所有的引擎都支持事务，**事务能否生效取决于数据库引擎是否支持事务**。常用的MySQL 数据库默认使用`Innodb`引擎是支持事务的， `MyISAM`不支持事务。

提到事务，肯定会想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）。

* **原子性(atomicity)**

  “原子”的本意是“不可再分”，事务的原子性表现为一个事务中涉及到的多个操作在逻辑上缺一不可。事务的原子性要求事务中的所有操作要么都执行，要么都不执行。

* 一致性(consistency)

  “一致”指的是数据的一致，具体是指所有数据都处于满足业务规则的一致性状态。一致性原则要求：一个事务中不管涉及到多少个操作，都必须保证事务执行之前数据是正确的，事务执行之后数据仍然是正确的。如果一个事务在执行的过程中，其中某一个或某几个操作失败了，则必须将其他所有操作撤销，将数据恢复到事务执行之前的状态，这就是回滚。

* 隔离性(isolation)

  在应用程序实际运行过程中，事务往往是并发执行的，所以很有可能有许多事务同时处理相同的数据，因此每个事务都应该与其他事务隔离开来，防止数据损坏。隔离性原则要求多个事务在并发执行过程中不会互相干扰。

* 持久性(durability)

  持久性原则要求事务执行完成后，对数据的修改永久的保存下来，不会因各种系统错误或其他意外情况而受到影响。通常情况下，事务对数据的修改应该被写入到持久化存储器中。

举一个例子：在执行SQL语句的时候，某些业务要求（如一个转账操作），一系列操作必须全部执行，而不能只执行一部分。

```shell
假如我们从id=1的A账户给id=2的B账户转账100元

-- 第一步：将id=1的A账户余额(500)减去100
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
-- 第二步：将id=2的B账户余额(500)加上100
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
```

从A账户到B账户转账从6个详细操作：
（1）从A账户中把余额读出来（500）。
（2）对A账户做减法操作（500-100）。
（3）把结果写回A账户中（400）。
（4）从B账户中把余额读出来（500）。
（5）对B账户做加法操作（500+100）。
（6）把结果写回B账户中（600）。

事务的ACID特性就体现在：

* 原子性：保证1-6所有过程要么都执行，要么都不执行。一旦在执行某一步骤的过程中发生问题，就需要执行回滚操作。假如执行到第五步的时候，B账户突然不可用（比如被注销），那么之前的所有操作都应该回滚到执行事务之前的状态。

* 一致性：在转账之前，A和B的账户中共有500+500=1000元钱。在转账之后，A和B的账户中共有400+600=1000元。也就是说，数据的状态在执行该事务操作之后从一个状态改变到了另外一个状态。同时一致性还能保证账户余额不会变成负数等。

* 隔离性：在A向B转账的整个过程中，只要事务还没有提交（commit），查询A账户和B账户的时候，两个账户里面的钱的数量都不会有变化。如果在A给B转账的同时，有另外一个事务执行了C给B转账的操作，那么当两个事务都结束的时候，B账户里面的钱应该是A转给B的钱加上C转给B的钱再加上自己原有的钱。

* 持久性：一旦转账成功（事务提交），两个账户的里面的钱就会真的发生变化（会把数据写入数据库做持久化保存）。

## 什么是脏读、幻读、不可重复读？

当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）等并发问题。

假如现在有两个事务——A和B在并发执行修改一个Student表中age值：  

* **脏读**（dirty read) ：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据。
  （1）A将某条记录的age值从20修改为30。 
  （2）B读取了A更新后的值：30。 
  （3）A回滚，age值恢复到了20。 
  （4）B读取到的30就是一个无效的值。  
* **不可重复读**（non-repeatable read）:事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。
  （1）A读取了age值为20。
  （2）B将age值修改为30。
  （3）A再次读取age值为30，和第一次读取不一致。
* **幻读**（phantom read）:与不可重复读类似，不可重复读侧重于修改，幻读侧重于新增或删除。
  （1）A读取了Student表中的一部分数据。
  （2）B向Student表中插入了新的行。
  （3）A读取了Student表时，多出了一些行或少了一些行。

## MySQL的四种事务隔离级别呢？

为了解决上述这些问题，就有了“隔离性”的概念，它要求每个事务都应该与其他事务隔离开来，多个事务在并发执行过程中不会互相干扰。

一个事务与其他事务隔离的程度称为隔离级别。在谈隔离级别之前，首先要知道，**隔离级别越高，数据一致性就越好，但效率越弱**。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL标准的事务隔离级别包括：**读未提交（READ_UNCOMMITTED）、读提交（READ_COMMITTED）、可重复读（REPEATABLE_READ）和串行化（SERIALIZABLE）**。

| 隔离级别         | 含义                                                         | 举例                                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| READ_UNCOMMITTED | 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 | 允许A读取B未提交的修改。                                     |
| READ_COMMITTED   | 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 | 要求A只能读取B已提交的修改。                                 |
| REPEATABLE_READ  | 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 | 确保A可以多次从一个字段中读取到相同的值，即A执行期间禁止其它事务对这个字段进行更新。 |
| SERIALIZABLE     | 最高的隔离级别，完全服从ACID的隔离级别，确保阻止脏读、不可重复读以及幻读。 | 确保A可以多次从一个表中读取到相同的行，在A执行期间，禁止其它事务对这个表进行添加、更新、删除操作。可以避免任何并发问题，但性能十分低下。 |

各个隔离级别所能解决的并发问题（x——不能解决，√——能解决）：

| 隔离级别     | 脏读 | 不可重复读 | 幻读        |
| ------------ | ---- | ---------- | ----------- |
| RU           | ×    | ×          | ×           |
| RC           | √    | ×          | ×           |
| RR           | √    | √          | ×（可解决） |
| SERIALIZABLE | √    | √          | √           |

> 其实 RR 也是可以避免幻读的，通过对 select 操作手动加 行X锁（SELECT … FOR UPDATE 这也正是 SERIALIZABLE 隔离级别下会隐式为你做的事情），同时还需要知道，即便当前记录不存在，比如 id = 1 是不存在的，当前事务也会获得一把记录锁（因为`InnoDB`的行锁锁定的是索引，故记录实体存在与否没关系，存在就加行X锁，不存在就加 next-key lock间隙X锁），其他事务则无法插入此索引的记录，故杜绝了幻读。
>
> 必读 [《MySQL 幻读的详解、实例及解决办法》](https://segmentfault.com/a/1190000016566788) 案例性更强，易懂。

通俗的理解：

* 读未提交，一个事务还未提交时，它的变更就能被别的事务所看到。
* 读提交，指的是一个事务提交之后，才能被其他事务所看到。
* 可重复读，指的是一个事务执行过程所看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
* 串行化，指的是对于同一行记录，“写”会加写锁，“读”会加读锁。当出现读写锁冲突的时候，后访问事务必须等前一个事务执行完成，才能继续执行。

各种数据库产品对事务隔离级别的支持程度：

| 隔离级别         | Oracle  | MySQL   |
| ---------------- | ------- | ------- |
| READ_UNCOMMITTED | ×       | √       |
| READ_COMMITTED   | √(默认) | √       |
| REPEATABLE_READ  | ×       | √(默认) |
| SERIALIZABLE     | √       | √       |

## 事务启动方式有哪些？

MySQL的事务启动方式有以下几种：

1. **显式启动事务语句**， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。

```mysql
START TRANSACTION;
-- 事务代码
commit;
```

2. **`set autocommit=0`**，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。

有些客户端连接框架会默认连接成功后先执行一个`set autocommit=0`的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。因此，**建议开发中总是使用`set autocommit=1`，之后通过显式语句的方式来启动事务。**

## MVCC是什么？

MVCC全称`Multi-Version Concurrency Control`，即**多版本并发控制**。它通过维护数据的历史版本，从而解决并发访问情况下的**读一致性**问题。MVCC的实现，是通过保存数据在某个时间点的**快照**来实现的。

可以这么理解，MVCC可以解决并发读写的一致性问题（ 可以做到读操作不阻塞写操作，同时写操作也不会阻塞读操作），可以解决`脏读`、`幻读`、`不可重复读`等事务隔离问题，但不能解决`写-写 更新丢失`问题。

因此在实际运用中会有以下提高并发性能的`组合拳`：

- `MVCC + 悲观锁`：MVCC解决读写冲突，悲观锁解决写写冲突。
- `MVCC + 乐观锁`：MVCC解决读写冲突，乐观锁解决写写冲突。

**快照读VS当前读**

在理解MVCC实现原理之前，需要先明白快照读与当前读的区别。

* 当前读：读取的数据库记录，都是当前最新的版本，会对当前读取的数据进行加锁，防止其他事务修改数据。是悲观锁的一种操作。
  * select lock in share mode (共享锁)
  * select for update (排他锁)、update (排他锁)、insert (排他锁)、delete (排他锁)
  * 串行化事务隔离级别
* 快照读：`MVCCC`是“维持一个数据的多个版本，使读写操作没有冲突”的一个抽象概念。这个概念需要具体功能去实现，这个具体实现就是快照读。
  - 不加锁的select操作（注：事务级别不是串行化）

## MVCC实现原理呢？

MVCC主要是通过`版本链`，`undo log` 与`Read View `一起来实现的。

### 版本链

在`InnoDB`中，每行记录实际上还包含了三个隐藏字段：**严格递增**的**事务id**（`trx_id`）和**回滚指针**（`roll_pointer`）和自增id（`row_id`）。

1. `trx_id`：事务id。每次修改某行记录时，事务会将唯一的事务id赋值给`trx_id`隐藏列。
2. `roll_pointer`：回滚指针。每次修改某行记录时，都会把`undo`日志地址赋值给`roll_pointer`隐藏列。
3. `row_id`：隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以row_id产生一个聚簇索引。

也就是说，`row_id`是数据库默认为该行记录生成的`唯一隐式主键`，`trx_id`是当前操作该记录的`事务ID`，而`roll_pointer`是一个`回滚指针`，用于配合`undo日志`，指向上一个`旧版本`。

举个例子，假设`hero`表中只有一行记录，当时插入的事务id为80。此时，该条记录的示例图如下： 

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210712141057894.png" width="600px"/>
</div> 

假设之后两个事务`id`分别为`100`、`200`的事务对这条记录进行`UPDATE`操作，操作流程如下： 

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210712141112258.png" width="600px"/>
</div> 

由于每次变动都会先把`undo log`记录下来，并用`roll_pointer`指向`undo log`地址。因此可以认为，**对该条记录的修改日志串联起来就形成了一个`版本链`，版本链的头节点就是当前记录最新的值**。如下： 

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210712141305740.png" width="700px"/>
</div> 

### undo log（回滚日志）

undo log（回滚日志）主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到`undo log`里。当事务进行`回滚时`可以通过undo log 里的日志进行数据还原。

**undo log 的用途**

- 保证事务进行`rollback`时的`原子性和一致性`，当事务进行`回滚`的时候可以用undo log的数据进行恢复。
- 用于MVCC`快照读`的数据，在MVCC多版本控制中，通过读取`undo log`的`历史版本数据`可以实现`不同事务版本号`都拥有自己`独立的快照数据版本`。

**undo log主要分为两种：**

- `insert undo log`

  代表事务在insert新记录时产生的undo log , 只在事务回滚时需要，并且在事务提交后可以被立即丢弃。

- `update undo log`（主要）

  事务在进行update或delete时产生的undo log ; 不仅在事务回滚时需要，在快照读时也需要；

  所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除

### Read View（一致性视图）

Read View（一致性视图）主要是用来做**可见性**判断的，即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。

`ReadView`中主要包含以下4个属性：

- `trx_ids`: 当前系统活跃(`未提交`)事务版本号集合。
- `low_limit_id`: 创建当前read view 时“当前系统最大事务版本号+1”。
- `up_limit_id`: 创建当前read view 时“系统正处于活跃事务最小版本号”。
- `creator_trx_id`: 创建当前read view的事务版本号。

有了`ReadView`之后，我们可以基于以下步骤判断某个版本的记录是否对当前事务可见。形象的图解：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210611221715889.png" width="500px"/>
</div>

* `trx_id` < `up_limit_id` || `db_trx_id` == `creator_trx_id`（可见）

  如果数据事务ID小于read view中的`最小活跃事务ID`，则可以肯定该数据是在`当前事务启之前`就已经`存在`了的，可见。

  或者数据的`事务ID`等于`creator_trx_id` ，那么说明这个数据就是当前事务`自己生成的`，自己生成的数据自己当然能看见，所以这种情况下此数据也是可见。

* `trx_id` >= `low_limit_id`（不可见）

  如果数据事务ID大于read view 中的当前系统的`最大事务ID`，则说明该数据是在当前read view 创建`之后才产生`的，所以数据不可见。如果小于则进入下一个判断。

* `trx_id`是否在活跃事务（`trx_ids`）中

  - `不存在`：则说明read view产生的时候事务已经commit了，这种情况数据则可见。
  - `已存在`：则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是不可见的。

在`MySQL`中，`READ COMMITTED`和`REPEATABLE READ`隔离级别的一个非常大的区别就是它们生成`ReadView`的时机不同

而，主要区别是：

* **在可重复读隔离级别下，只需要在事务开始的时候创建`Read View`，之后事务里的其他查询都会公用这一个`ReadView`**，这样就能保证后续读取的结果完全一致；
* **读提交隔离级别下，每一个语句执行前都会重新算出一个新的`Read View`**，这样就能保证每次都能读到其它事务已提交的数据。

# 锁机制

事务并发访问同一数据资源的情况主要就分为`读-读`、`写-写`和`读-写`三种。

1. `读-读` 即并发事务同时访问同一行数据记录。由于两个事务都进行只读操作，不会对记录造成任何影响，因此并发读完全允许。
2. `写-写` 即并发事务同时修改同一行数据记录。这种情况下可能导致`脏写`问题，这是任何情况下都不允许发生的，因此只能通过`加锁`实现，也就是当一个事务需要对某行记录进行修改时，首先会先给这条记录加锁，如果加锁成功则继续执行，否则就排队等待，事务执行完成或回滚会自动释放锁。
3. `读-写` 即一个事务进行读取操作，另一个进行写入操作。这种情况下可能会产生`脏读`、`不可重复读`、`幻读`。最好的方案是**读操作利用多版本并发控制（`MVCC`），写操作进行加锁**。

## 锁的粒度

根据**加锁的范围**，MySQL里面的锁大致可以分成**全局锁、表级锁和行锁**三类。

**1、全局锁：全局锁就是对整个数据库实例加锁**。MySQL提供了一个加全局读锁的方法，命令是 **Flush tables with read lock (FTWRL)**。全局锁会让其他线程的DDL、DML都阻塞，只有DQL正常运行。**全局锁的典型使用场景是，做全库逻辑备份。**

**2、表级锁：作用在整张数据表上**。MySQL里面表级别的锁有两种：**一种是表锁，一种是元数据锁**（meta data lock，MDL)。

* **表锁的语法是 lock tables … read/write。**与FTWRL类似，可以用`unlock tables`主动释放锁，也可以在客户端断开的时候自动释放。需要注意，`lock tables`语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
* 另一类表级的锁是**MDL（metadata lock)**。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

**3、行锁**：**行锁就是针对数据表中行记录的锁**。`InnoDB`是支持行锁的，`MyISAM`不支持行锁。

* 在`InnoDB`事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。所以，**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放**。

------

 **MySQL 中 `InnoDB` 引擎的行锁是通过加在什么上完成(或称实现)的？为什么是这样子的？？**

`InnoDB` 是基于索引来完成行锁。例如：`SELECT * FROM tab_with_index WHERE id = 1 FOR UPDATE` 。

- `FOR UPDATE` 可以根据条件来完成**行锁**锁定，并且 id 是有索引键的列，如果 id 不是索引键那么 `InnoDB` 将完成**表锁**，并发将无从谈起。

## 锁的分类

为了实现`读-读`之间不受影响，并且`写-写`、`读-写`之间能够相互阻塞，`Mysql`使用了`读写锁`的思路进行实现，具体来说就是分为了`共享锁`和`排它锁`：

1. `共享锁(Shared Locks)`：简称`S锁`，在事务要读取一条记录时，需要先获取该记录的`S锁`。`S锁`可以在同一时刻被多个事务同时持有。我们可以用`select ...... lock in share mode;`的方式手工加上一把`S锁`。
2. `排他锁(Exclusive Locks)`：简称`X锁`，在事务要改动一条记录时，需要先获取该记录的`X锁`。`X锁`在同一时刻最多只能被一个事务持有。`X锁`的加锁方式有两种，第一种是自动加锁，在对数据进行增删改的时候，都会默认加上一个`X锁`。还有一种是手工加锁，我们用一个`FOR UPDATE`给一行数据加上一个`X锁`。

还需要注意的一点是，如果一个事务已经持有了某行记录的`S锁`，另一个事务是无法为这行记录加上`X锁`的，反之亦然。

除了`共享锁(Shared Locks)`和`排他锁(Exclusive Locks)`，`Mysql`还有`意向锁(Intention Locks)`。

* 意向锁是由数据库自己维护的，一般来说，当我们给一行数据加上共享锁之前，数据库会自动在这张表上面加一个`意向共享锁(IS锁)`；当我们给一行数据加上排他锁之前，数据库会自动在这张表上面加一个`意向排他锁(IX锁)`。
* **`意向锁`可以认为是`S锁`和`X锁`在数据表上的标识，通过意向锁可以快速判断表中是否有记录被上锁，从而避免通过遍历的方式来查看表中有没有记录被上锁，提升加锁效率**。例如，我们要加表级别的`X锁`，这时候数据表里面如果存在行级别的`X锁`或者`S锁`的，加锁就会失败，此时直接根据`意向锁`就能知道这张表是否有行级别的`X锁`或者`S锁`。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210712150855641.png" width="400px"/>
</div>

## InnoDB中的表级锁

`InnoDB`中的表级锁主要包括表级别的`意向共享锁(IS锁)`和`意向排他锁(IX锁)`以及`自增锁(AUTO-INC锁)`。其中`IS锁`和`IX锁`在前面已经介绍过了，这里不再赘述，我们接下来重点了解一下`AUTO-INC锁`。

大家都知道，如果我们给某列字段加了`AUTO_INCREMENT`自增属性，插入的时候不需要为该字段指定值，系统会自动保证递增。系统实现这种自动给`AUTO_INCREMENT`修饰的列递增赋值的原理主要是两个：

1. `AUTO-INC锁`：在执行插入语句的时先加上表级别的`AUTO-INC锁`，插入执行完成后立即释放锁。**如果我们的插入语句在执行前无法确定具体要插入多少条记录，比如`INSERT ... SELECT`这种插入语句，一般采用`AUTO-INC锁`的方式**。
2. `轻量级锁`：在插入语句生成`AUTO_INCREMENT`值时先才获取这个`轻量级锁`，然后在`AUTO_INCREMENT`值生成之后就释放`轻量级锁`。**如果我们的插入语句在执行前就可以确定具体要插入多少条记录，那么一般采用轻量级锁的方式对AUTO_INCREMENT修饰的列进行赋值**。这种方式可以避免锁定表，可以提升插入性能。

> mysql默认根据实际场景自动选择加锁方式，当然也可以通过`innodb_autoinc_lock_mode`强制指定只使用其中一种。

## InnoDB中的行级锁

前面说过，通过`MVCC`可以解决`脏读`、`不可重复读`、`幻读`这些读一致性问题，但实际上这只是解决了普通`select`语句的数据读取问题。事务利用`MVCC`进行的读取操作称之为`快照读`，所有普通的`SELECT`语句在`READ COMMITTED`、`REPEATABLE READ`隔离级别下都算是`快照读`。除了`快照读`之外，还有一种是`锁定读`，即在读取的时候给记录加锁，在`锁定读`的情况下依然要解决`脏读`、`不可重复读`、`幻读`的问题。由于都是在记录上加锁，这些锁都属于`行级锁`。

**`InnoDB`的行锁，是通过锁住索引来实现的，如果加锁查询的时候没有使用过索引，会将整个聚簇索引都锁住，相当于锁表了**。根据锁定范围的不同，行锁可以使用`记录锁(Record Locks)`、`间隙锁(Gap Locks)`和`临键锁(Next-Key Locks)`的方式实现。假设现在有一张表`t`，主键是`id`。我们插入了4行数据，主键值分别是 1、4、7、10。接下来我们就以聚簇索引为例，具体介绍三种形式的行锁。

**记录锁(Record Locks)** 所谓记录，就是指聚簇索引中真实存放的数据，比如上面的1、4、7、10都是记录。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210712151223928.png" width="600px"/>
</div> 

* 显然，记录锁就是直接锁定某行记录。当我们使用唯一性的索引(包括唯一索引和聚簇索引)进行等值查询且精准匹配到一条记录时，此时就会直接将这条记录锁定。例如`select * from t where id =4 for update;`就会将`id=4`的记录锁定。

**间隙锁(Gap Locks)** 间隙指的是两个记录之间逻辑上尚未填入数据的部分，比如上述的(1,4)、(4,7)等。 

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210712151251685.png" width="600px"/>
</div> 

同理，间隙锁就是锁定某些间隙区间的。当我们使用用等值查询或者范围查询，并且没有命中任何一个`record`，此时就会将对应的间隙区间锁定。例如`select * from t where id =3 for update;`或者`select * from t where id > 1 and id < 4 for update;`就会将(1,4)区间锁定。

**临键锁(Next-Key Locks)** 临键指的是间隙加上它右边的记录组成的左开右闭区间。比如上述的(1,4]、(4,7]等。 

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210712151304539.png" width="600px"/>
</div> 

- 临键锁就是记录锁(Record Locks)和间隙锁(Gap Locks)的结合，即除了锁住记录本身，还要再锁住索引之间的间隙。当我们使用范围查询，并且命中了部分`record`记录，此时锁住的就是临键区间。注意，临键锁锁住的区间会包含最后一个record的右边的临键区间。例如`select * from t where id > 5 and id <= 7 for update;`会锁住(4,7]、(7,+∞)。mysql默认行锁类型就是`临键锁(Next-Key Locks)`。当使用唯一性索引，等值查询匹配到一条记录的时候，临键锁(Next-Key Locks)会退化成记录锁；没有匹配到任何记录的时候，退化成间隙锁。

`间隙锁(Gap Locks)`和`临键锁(Next-Key Locks)`都是用来解决幻读问题的，在`已提交读（READ COMMITTED）`隔离级别下，`间隙锁(Gap Locks)`和`临键锁(Next-Key Locks)`都会失效！

## 乐观锁和悲观锁

**悲观锁**

* 它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。
* 在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。
* 上面所讲的排他锁、共享锁也都是悲观锁。

**乐观锁**

* 相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。
* 而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现，例如上面所讲的MVCC就是一种乐观锁实现。

## 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为**死锁**。

当出现死锁以后，有两种策略：

- 一种策略是，**直接进入等待，直到超时**。这个超时时间可以通过参数`innodb_lock_wait_timeout`（默认值为50s）来设置。
- 另一种策略是，**发起死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数`innodb_deadlock_detect`设置为`on`，表示开启这个逻辑。

**正常情况下我们还是要采用第二种策略，即：主动死锁检测**，而且`innodb_deadlock_detect`的默认值本身就是on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的（**整体死锁检测的时间复杂度为O(n^2^)**）。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。

如何解决死锁检测消耗资源大的问题呢？

- 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉（风险大）。
- 另一个思路是**控制并发度**。如利用中间件；一行改多行... ...

# 日志

## redo log（重做日志）

为什么会有redo log?

* （1）保证`InnoDB` 的持久性；（2）redo log 要进行磁盘操作是与Buffer Pool `磁盘随机写入`比， redo log 的磁盘操作有几个优势：`1.引入redo log buffer，按组写入，不是一条条写。2.磁盘为顺序写入。`这样， redo log 日志的磁盘操作比起 Buffer Pool 的磁盘操作性能要好很多。

------

`redo log`是`InnoDB`存储引擎层的日志，又被称为重写日志，用来记录事务操作的变化，记录的是数据修改之后的值，不管事务提交是否成功，都会被记录下来。

而这种**先写日志，后写磁盘**的技术就是MySQL里面经常提及到的**WAL**(**Write Ahead Logging**)技术。

具体的来说，就是当有一条记录需要更新的时候，`InnoDB`引擎会把记录优先更新到`redo log`里面，并更新内存，这样更新操作就完成了。同时，`InnoDB`引擎会在空闲的时间将`redo log`中的记录存储到磁盘上。

由于`redo log`记录的是数据页的变更，而这种记录是没有必要永久保存的，因此`redo log`实现上采用来大小固定，循环写入的方式，当记录写到末尾时，又会从头开始写，如下图所示。 

<div align="center">  
<img src="https://img-blog.csdnimg.cn/2021061110060971.png" width="450px"/>
</div>

 如图所示，`write pos`是当前记录的位置，一边写一边后移，写到4号文件末尾就回到1号文件开头。`check point`是当前要把记录写入到数据文件的位置，也是后移并且循环的。

有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**。

## binlog（归档日志）

`binlog`是MySQL数据库Server层的，是所有存储引擎共享的日志模块，它用于记录数据库执行的写入性操作，也就是在事务`commit`阶段进行记录，以二进制的形式保存于磁盘中。

`binlog`是逻辑日志，并且由MySQL数据库的Server层执行，也就是说使用所有的存储引擎数据库都会记录`binlog`日志。

`binlog`是以追加的方式进行写入的，可以通过 `max_binlog_size` 参数设置`binlog`文件大小，当文件大小达到某个值时，会生成新的文件来保存日志。

**binlog刷盘机制**

对于`InnoDB`引擎而言，在每次事务`commit`提交时才会记录`binlog`日志，此时记录仍然在内存中，那么什么时候存储到磁盘中呢？`mysql`通过 `sync_binlog` 参数控制`binlog`刷盘时机，取值范围：`0～N`：

*  0：不去强求，由系统自行判断何时写入磁盘；
*  1：每次事务`commit`的时候都要将`binlog`写入磁盘； 
* N：每N个事务`commit`，才会将`binlog`写入磁盘；

`sync_binlog` 参数建议设置为1，这样每次事务commit时就会把`binlog`写入磁盘中，这样也可以保证mysql异常重启之后`binlog`日志不会丢失。

**binlog使用场景**

在实际场景中， `binlog` 的主要场景有两点，一点是主从复制，另一点是数据恢复。

* 主从复制：在master端开启 `binlog` ，然后将 `binlog` 发送给各个slaver端，slaver端读取 `binlog` 日志，从而使得主从数据库中数据一致 。
* 数据恢复：通过 `binlog` 获取想要恢复的时间段数据。

**如何在线正确清理 MySQL binlog？**

MySQL 中的 `binlog` 日志记录了数据中的数据变动，便于对数据的基于时间点和基于位置的恢复。但日志文件的大小会越来越大，占用大量的磁盘空间，因此需要定时清理一部分日志信息。

```mysql
# 首先查看主从库正在使用的binlog文件名称
show master(slave) status

# 删除之前一定要备份
purge master logs before'2017-09-01 00:00:00'; # 删除指定时间前的日志
purge master logs to'mysql-bin.000001'; # 删除指定的日志文件

# 自动删除：通过设置binlog的过期时间让系统自动删除日志
show variables like 'expire_logs_days'; # 查看过期时间
set global expire_logs_days = 30; # 设置过期时间
```

## redo log与binlog、undo log区别

|          | binlog                                                       | redo log                                                     | undo log           |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------ |
| 存储位置 | Server层实现，所有引擎皆可使用                               | 引擎层实现，`InnoDB `引擎独有                                |                    |
| 文件大小 | `max_binlog_size `：每个日志文件大小                         | 大小固定<br/>`innodb_log_files_in_group`：日志文件数量<br/>`innodb_log_file_size`：每个日志文件大小 |                    |
| 日志名称 | 归档日志                                                     | 重写日志                                                     | 回滚日志           |
| 记录方式 | 追加写，文件写到一定大小后<br/>切换到下一个（不会覆盖）(体现归档的功能) | "循环写"，当写到结尾时<br/>会回到开头循环写日志（覆盖）      |                    |
| 适用场景 | 主从复制和数据恢复                                           | 提升性能和崩溃恢复(crash-safe)                               | MVCC多版本并发控制 |

`binlog `日志只用于归档，只依靠 `binlog `是没有`
crash-safe `能力的。但只有 `redo log `也不行，因为 `redo log `是 `InnoDB `特有的，且日志上的记录落盘后会被覆盖掉。因此需要 `binlog `和 `redo log`二者同时记录，通过"两阶段提交"，维持数据逻辑一致性，也能保证当数据库发生宕机重启时，数据不会丢失。

相关参数设置建议：

* `innodb_flush_log_at_trx_commit`：设置为1，表示每次事务的redo log都直接持久化到磁盘（注意是这里指的是redo log日志本身落盘），异常重启之后数据不丢失。

* `sync_binlog`： 设置为1，表示每次事务的`binlog`都直接持久化到磁盘（注意是这里指的是`binlog`日志本身落盘），保证MySQL重启后`binlog`记录是完整的。

## MySQL中两阶段提交是什么？

这里我给出这个update语句的执行流程图，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210611101237224.png" width="450px"/>
</div>

粗略地观察一下上图，MySQL想要准备事务的时候会先写redo log、`binlog`分成两个阶段。

* 两阶段提交的第一阶段 （prepare阶段）：写redo log 并将其标记为prepare状态；
* 紧接着写`binlog`；
* 两阶段提交的第二阶段（commit阶段）：写`redo log`并将其标记为commit状态。

**redo log和`binlog`都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致**。采用两阶段提交来恢复数据时，redo log 用于恢复主机故障时的未更新的物理数据，`binlog`用于备份操作。每个阶段的log操作都是记录在磁盘中的，在恢复数据时，redo log状态为commit则说明`binlog`也成功，直接恢复数据；如果redo log 时prepare，则需要查询对应的`binlog`事务是否成功，决定回滚还是执行。 

## slow query log是什么？

slow query log（慢查询日志）是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。**long_query_time的默认值为10**，意思是运行10S以上的语句。

默认情况下，MySQL数据库并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。

**慢查询日志相关参数** 

 MySQL 慢查询的相关参数解释：

* slow_query_log  ：是否开启慢查询日志，1表示开启，0表示关闭。
* log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log。
* slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log。
* long_query_time ：慢查询阈值，当查询时间多于设定的阈值时，记录日志。
* log_queries_not_using_indexes：未使用索引的查询也被记录到慢查询日志中（可选项）。
* log_output：日志存储方式。log_output='FILE'表示将日志存入文件，默认值是'FILE'。log_output='TABLE'表示将日志存入数据库，这样日志信息就会被写入到`mysql.slow_log`表中。MySQL数据库支持同时两种日志存储方式，配置的时候以逗号隔开即可，如：log_output='FILE,TABLE'。日志记录到系统的专用日志表中，要比记录到文件耗费更多的系统资源，因此对于需要启用慢查询日志，又需要能够获得更高的系统性能，那么建议优先记录到文件。

**日志分析工具mysqldumpslow**

在生产环境中，如果要手工分析日志，查找、分析SQL，显然是个体力活，MySQL提供了日志分析工具`mysqldumpslow`，查看`mysqldumpslow --help`查看命令：

```shell
-s 表示按何种方式排序。
c  访问次数。
l   锁定时间。
r   返回记录。
t   查询时间。
al  平均锁定时间。
ar  平均返回记录数。
at  平均查询时间。
-t  返回前面多少条数据。
-g  后面搭配一个正则匹配模式，大小写不敏感。
```

## 事务是如何通过日志来实现呢？

基本流程如下：

- 因为事务在修改页时，要先记 undo ，在记 undo 之前要记 undo 的 redo， 然后修改数据页，再记数据页修改的 redo。 redo（里面包括 undo 的修改）一定要比数据页先持久化到磁盘。
- 当事务需要回滚时，因为有 undo，可以把数据页回滚到前镜像的状态。
- 崩溃恢复时，如果 redo log 中事务没有对应的 commit 记录，那么需要用 undo 把该事务的修改回滚到事务开始之前。如果有 commit 记录，就用 redo 前滚到该事务完成时并提交掉。

# 数据库设计

## 如何设计数据库呢？

数据库系统设计及开发大致可以简化为如下几个步骤：

1. **需求分析**：数据是什么，数据具有哪些属性，数据与属性的特点是什么。
2. **概念设计**：建立**ER模型**。
3. **逻辑设计**：按ER图按照一定规则转换为关系模型，关系模式的规范化和优化（应用**设计范式**）。
4. **物理设计**：给数据模型设计一个合理的物理结构，比如数据存取结构（如数据库管理系统的选择）。
5. **数据库实现**：数据定义语言DDL创建数据库，数据入库。
6. **维护和优化**：对数据库进行监测、评估、调整、备份和修改（如建表、索引优化、大表拆分）。

## 什么是设计范式？

关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴德斯科范式/巴斯范式（BCNF）、第四范式（4NF）和第五范式（5NF）。 满足最低要求的范式是第一范式（1NF）。 在第一范式的基础上进一步满足更多要求的称为第二范式（2NF），其余范式以次类推。越高的范式数据库的冗余度就越低。

但并不是说遵循的范式等级越高越好，范式过高虽然具有对数据关系有更好的约束性，但是也会导致表之间的关系更加繁琐，从而导致每次操作的表会变多，数据库性能下降。

通常设计中，**最高也就遵循到 BCNF，普遍还是 3NF**。

**1NF**：数据库中的所有字段都是单一属性，不可再分的，每个列都是原子的。

**2NF**：在 1NF 的基础上，消除了非主属性对码的部分函数依赖。

**3NF**：在 2NF 的基础上，消除非主属性对码的传递函数依赖。

**BCNF**：消除**主属性**对于码的部分函数依赖和传递函数依赖（前面的 2NF、3NF都是**非主属性**对码的部分函数依赖和传递函数依赖）。

>**反范式化**就是为了性能和读取效率，适当地对范式进行违反，**本质上就是用空间来换取时间**，把数据冗余在多个表中，当查询时可以减少或者是避免表之间的关联。

## 什么是函数依赖关系？

* **函数依赖（functional dependency）** ：若在一张表中，在属性（或属性组）X的值确定的情况下，必定能确定属性Y的值，那么就可以说Y函数依赖于X，写作` X → Y`。
  * （学号）->（姓名）/（学号，课名）->（分数）/（系名）->（系主任）。

* **部分函数依赖（partial functional dependency）** ：如果`X→Y`，并且存在X的一个真子集`X0`，使得`X0→Y`，则称`Y`对`X`部分函数依赖。
  * （学号，身份证号）->（姓名），（学号）->（姓名），（身份证号）->（姓名），所以姓名部分函数依赖与（学号，身份证号）。

* **完全函数依赖(Full functional dependency)** ：如果`X→Y`，并且任何X的真子集`X‘`，都不能满足`X’→Y`，则称`Y`对`X`完全函数依赖。**完全函数依赖必须要通过码中的所有属性才可以唯一确定一个值，而部分函数依赖只需要码中的部分属性即可**。
  * （学号，课名）->（分数），但是（学号）->（分数）不成立，（课名）->（分数）不成立，所以分数完全函数依赖与（学号，课名）。

* **传递函数依赖** ： 设X，Y，Z是U的不同的属性子集，如果 Z -> Y，Y -> X，并且 X 不函数依赖于 Y，那么我们就说 Z 传递函数依赖于 X，（X∪Y）∩Z=空集合。传递函数依赖的Y和Z子集往往同属于某一个事物，因此可将其合并放到一个表中。
  * （学号，姓名，系名，系主任）中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖。

## MySQL 存储引擎如何选择？

MySQL 提供了多种的存储引擎：`InnoDB`、`MyISAM`、MRG_MYISAM、MEMORY、CSV、ARCHIVE、BLACKHOLE、PERFORMANCE_SCHEMA、FEDERATED、… ...

具体每种存储引擎的介绍，可以看看 [《数据库存储引擎》](https://github.com/jaywcjlove/mysql-tutorial/blob/master/chapter3/3.5.md) 。

**如何选择合适的存储引擎？**

提供几个选择标准，然后按照标准，选择对应的存储引擎即可，也可以根据 [常用引擎对比](https://github.com/jaywcjlove/mysql-tutorial/blob/master/chapter3/3.5.md#常用引擎对比) 来选择你使用的存储引擎。使用哪种引擎需要根据需求灵活选择，一个数据库中多个表可以使用不同的引擎以满足各种性能和实际需求。使用合适的存储引擎，将会提高整个数据库的性能。

1. 是否需要支持事务。
2. 对索引和缓存的支持。
3. 是否需要使用热备。
4. 崩溃恢复，能否接受崩溃。
5. 存储的限制。
6. 是否需要外键支持。

目前，MySQL 默认的存储引擎是 `InnoDB` ，并且也是最主流的选择。主要原因如下：

- 支持事务。
- 支持行级锁和表级锁，能支持更多的并发量。
- 查询不加锁，完全不影响查询。
- 支持崩溃后恢复。

在 MySQL5.1 以及之前的版本，默认的存储引擎是 `MyISAM` ，但是目前已经不再更新，且它有几个比较关键的缺点：

- 不支持事务。
- 使用表级锁，如果数据量大，一个插入操作锁定表后，其他请求都将阻塞。

**请说明 `InnoDB` 和 `MyISAM` 的区别**

| 对比         | `InnoDB`       | `MyISAM` |
| :----------- | :------------- | :------- |
| 事务         | 支持           | 不支持   |
| 存储限制     | 64TB           | 无       |
| 锁粒度       | 行锁           | 表锁     |
| 崩溃后的恢复 | 支持           | 不支持   |
| 外键         | 支持           | 不支持   |
| 全文检索     | 5.7 版本后支持 | 支持     |

**请说说 `InnoDB` 的 4 大特性？**

- 插入缓冲(insert buffer)
- 二次写(double write)
- 自适应哈希索引(ahi)
- 预读(read ahead)

**为什么 SELECT COUNT(\*) FROM table 在 `InnoDB` 比 `MyISAM` 慢？**

对于 `SELECT COUNT(*) FROM table` 语句，在没有 `WHERE` 条件的情况下，`InnoDB` 比 `MyISAM` 可能会慢很多，尤其在大表的情况下。因为，`InnoDB` 是去实时统计结果，会全表扫描；而 `MyISAM` 内部维持了一个计数器，预存了结果，所以直接返回即可。

**各种不同 MySQL 版本的 Innodb 的改进？**

MySQL5.6 下 `Innodb` 引擎的主要改进：

1. online DDL
2. memcached NoSQL 接口
3. transportable tablespace（ alter table discard/import tablespace）
4. MySQL 正常关闭时，可以 dump 出 buffer pool 的（ space， page_no），重启时 reload，加快预热速度
5. 索引和表的统计信息持久化到 mysql.innodb_table_stats 和 mysql.innodb_index_stats，可提供稳定的执行计划
6. Compressed row format 支持压缩表

MySQL5.7 下 Innodb 引擎的主要改进：

- 1、修改 varchar 字段长度有时可以使用
- 2、Buffer pool 支持在线改变大小
- 3、Buffer pool 支持导出部分比例
- 4、支持新建 innodb tablespace，并可以在其中创建多张表
- 5、磁盘临时表采用 innodb 存储，并且存储在 innodb temp tablespace 里面，以前是 MyISAM 存储
- 6、透明表空间压缩功能

## MySQL 数据类型如何选择？

MySQL 支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型。具体可以看看 [《MySQL 数据类型》](http://www.runoob.com/mysql/mysql-data-types.html) 文档。正确的使用数据类型，对数据库的优化是非常重要的。

**MySQL 中 varchar 与 char 的区别？varchar(50) 中的 50 代表的涵义？**

- 1、varchar 与 char 的区别，char 是一种固定长度的类型，varchar 则是一种可变长度的类型。

- 2、varchar(50) 中 50 的涵义最多存放 50 个字符。varchar(50) 和 varchar(200) 仅存储 ”hello“ 时所占空间一样，

  但后者在排序时会消耗更多内存，因为 `ORDER BY col` 采用 fixed_length 计算 col 长度(memory引擎也一样)。

  > 所以，实际场景下，选择合适的 varchar 长度还是有必要的。

**int(11) 中的 11 代表什么涵义？**

int(11) 中的 11 ，不影响字段存储的范围，只影响展示效果。

**金额(金钱)相关的数据，选择什么数据类型？**

- 方式一，使用 int 或者 bigint 类型。如果需要存储到分的维度，需要 *100 进行放大。
- 方式二，使用 decimal 类型，避免精度丢失。如果使用 Java 语言时，需要使用 BigDecimal 进行对应。

**一张表，里面有 ID 自增主键，当 insert 了 17 条记录之后，删除了第 15,16,17 条记录，再把 MySQL 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15？**

- 一般情况下，我们创建的表的类型是InnoDB ，如果新增一条记录（不重启MySQL的情况下），这条记录的ID是18 ；但是如果重启 MySQL 的话，这条记录的 ID 是 15 。因为 InnoDB 表只把自增主键的最大 ID 记录到内存中，所以重启数据库或者对表 OPTIMIZE 操作，都会使最大 ID 丢失。
- 但是，如果我们使用表的类型是 MyISAM ，那么这条记录的 ID 就是 18 。因为 MyISAM 表会把自增主键的最大 ID 记录到数据文件里面，重启 MYSQL 后，自增主键的最大 ID 也不会丢失。

最后，还可以跟面试官装个 x ，生产数据，不建议进行物理删除记录。

**表中有大字段 X(例如：text 类型)，且字段 X 不会经常更新，以读为为主，请问您是选择拆成子表，还是继续放一起？写出您这样选择的理由**

- 拆带来的问题：连接消耗 + 存储拆分空间。

  > 如果能容忍拆分带来的空间问题，拆的话最好和经常要查询的表的主键在物理结构上放置在一起(分区) 顺序 IO ，减少连接消耗，最后这是一个文本列再加上一个全文索引来尽量抵消连接消耗。

- 不拆可能带来的问题：查询性能。

  > 如果能容忍不拆分带来的查询性能损失的话，上面的方案在某个极致条件下肯定会出现问题，那么不拆就是最好的选择。

实际场景下，例如说商品表数据量比较大的情况下，会将商品描述单独存储到一个表中。即，使用拆的方案。

# 数据库优化

## 你如何做MySQL性能优化呢？

MySQL性能优化主要囊括如下几个方面：

* MySQL配置优化 
* MySQL表结构优化 
* 索引优化 
* SQL语句优化 
* 架构优化 
* 服务器配置优化

> 可参考[https://juejin.cn/post/6844904085330591758](https://juejin.cn/post/6844904085330591758)一文。>

## 遇见一些个SQL慢查询问题？该如何优化？

在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：

* 索引没有设计好；
  * 紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。
  * 比较理想的是能够在备库先执行。
* SQL 语句没写好。对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。隐式类型转换、隐式字符编码转换也一样，因为要求在索引字段上做函数操作而可能导致了全索引扫描。
  * 可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。
* MySQL 选错了索引，优化器存在选错索引的可能性
  * 对于由于索引统计信息不准确导致的问题，你可以用 analyze table 来解决。
  * 对于其他优化器误判的情况，可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。

> 慢查询案例可参考：[MySQL索引原理及慢查询优化](https://tech.meituan.com/2014/06/30/mysql-index.html)一文。

## 为什么不建议使用join，如果使用如何优化？



## count(*)这么慢，该怎么办？

MySQL使用count(*)时：

* `MyISAM` 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；但是`MyISAM`不支持事务。

* **`show table status 命令`**显示的行数有误差，也不能直接使用。

* `InnoDB` 引擎就麻烦了，它执行 count(*) 的时候，会遍历全表，虽然结果准确，但会导致性能问题（由于 InnoDB 要支持事务，从而导致 `InnoDB` 表不能把 `count(*)` 直接存起来，然后查询的时候直接返回形成的）。

**count(*)、count(主键 id) 和 count(1)、count(字段）区别**

count()是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。

* **count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数**。

一个一个来看：

* **count(主键 id)**：`InnoDB` 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。
* **count(1)** ：`InnoDB` 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。
* **count(字段)**：如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。
* **count(*)**：并不会把全部字段取出来，而是专门做了优化，不取值。`count(*)` 肯定不是 null，按行累加。

所以结论是：**按照效率排序的话，count(字段)<count(主键id)<count(1)/count(*)，所以建议尽量使用`count(*)`**。

那么，我们如何解决count(*)导致的性能问题呢？

* 用缓存系统`Redis`来保存表的总行数。问题：丢失更新问题、会导致数据不精确。
* 改进：把这个计数直接放到数据库里单独的一张计数表 C 中。

## explain  SQL语句之后，看哪些字段？

使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询与或是表结构的性能瓶颈。

使用很简单，只要查询语句前面加上EXPLAIN即可：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210712180231354.png" width="1000px"/>
</div>

这些字段有：

* id：标识整个查询中SELELCT语句的顺序，在嵌套查询中id越大的语句越先执行，该值可能为NULL。

* select_type

  * **simple：** 简单的select查询，没有union或者子查询；
  * **primary：** 最外层的select查询；
  * **union：** `union`中的第二个或随后的select查询，不依赖于外部查询的结果集；
  * **dependent union**：`union`中的第二个或随后的select查询，依赖于外部查询的结果集；
  * **subquery：** 子查询中的第一个select查询，不依赖与外部查询的结果集；
  * **dependent subquery：** 子查询中的第一个select查询，依赖于外部查询的结果集；
  * **derived：** 用于from子句中有子查询的情况，MySQL会递归执行这些子查询，此结果集放在临时表中。

* table：用来表示输出行所引用的表名。

* partitions：

* **type**：表示访问类型，下面依次解释各种类型，类型顺序从**最好到最差**排列。

  * **system：** 表仅有一行，是const类型的一个特例；
  * **const：** 确定只有一行匹配的时候，MySQL优化器会在查询前读取它并且只读取一次，速度非常快;
  * **eq_ref：** 对于每个来自于前面的表的行组合，从该表中读取一行，常用在一个索引是unique key或者primary key
  * **ref**：对于来自前面的表的行组合，所有有匹配索引值的行都从这张表中读取,如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY（换句话说，如果联接不能基于关键字选择单个行的话），则使用ref；
  * **index_merge：** 该访问类型使用了索引合并优化方法，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素；
  * **range：** 只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL；
  * **index：** 在进行统计时非常常见，此联接类型实际上会扫描索引树；
  * **all：** 对于每个来自于先前的表的行组合，进行完整的表扫描，通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出。
  

* possible_keys：可以使用这个索引去辅助查找记录，当查询涉及到的字段，都会被列出，但不一定被查询使用.若为空则表示没有可以使用的索引，此时可以通过检查where语句看是否可以引用某些列或者新建索引来提高性能。

* **key**：显示的是当前表实际使用的索引，如果没有选择索引，则此列为null，要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。
* `key_len`：列显示MySQL决定使用的键长度。如果KEY键是NULL，则长度为NULL。**在不损失精确性的情况下，长度越短越好**。
* ref：用来显示使用哪个列或常数与key一起从表中选择相应的行。它显示的列的名字（或const），此列多数时候为null。
* rows：显示的是MySQL解析器认为执行此SQL时必须扫描的行数。此数值为一个预估值，不是具体值，通常比实际值小。
* filtered：此参数为**mysql 5.7 新加参数**，指的是返回结果的行数所占需要读到的行（rows的值）的比例 对于使用join时，前一个表的结果集大小直接影响了循环的行数。
* **Extra**：表示不在其他列并且也很重要的额外信息。
  * **using index：** 该值表示这个SQL语句使用了覆盖索引（覆盖索引是指可以直接在索引列中得到想要的结果，而不用去回表），此时效率最高；
  * **using where：** 表示存储引擎搜到记录后进行了后过滤(POST-FILTER)，如果查询未能使用索引，using where的作用只是提醒我们MySQL要用where条件过滤结果集；
  * **using temporary** 表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询；
  * **using filesort：** 是指MySQL无法利用索引直接完成排序（排序的字段不是索引字段），此时会用到缓冲空间来进行排序；
  * **using join buffer：** 强调在获取连接条件时没有用到索引，并且需要连接缓冲区来存储中间结果。（性能可以通过添加索引或者修改连接字段改进）；
  * **impossible where：** 表示where条件导致没有返回的行；
  * **using index condition：** 是MySQL 5.6 之后新加的特性，结合MySQL的ICP（Index Condition Pushdown）特性使用。主要是优化了可以在索引（仅限二级索引）上进行 like 查找。

> 可参考[MySQL EXPLAIN结果集分析 - 附带大量案例](https://juejin.cn/post/6844903938081161229)一文。

## 嵌套查询、子查询优化有没有做过？



## MySQL 数据库 CPU 飙升到 500% 的话，怎么处理？

当 CPU 飙升到 500% 时，先用操作系统命令 top 命令观察是不是 `mysqld` 占用导致的，如果不是，找出占用高的进程，并进行相关处理。

> 如果此时是 IO 压力比较大，可以使用 `iostat` 命令，定位是哪个进程占用了磁盘 IO 。

如果是 `mysqld` 造成的，使用 `show processlist` 命令，看看里面跑的 Session 情况，是不是有消耗资源的 SQL 在运行。找出消耗高的 SQL ，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。一般来说，肯定要 kill 掉这些线程(同时观察 CPU 使用率是否下降)，等进行相应的调整(比如说加索引、改 SQL 、改内存参数)之后，再重新跑这些 SQL。

> 也可以查看 MySQL 慢查询日志，看是否有慢 SQL 。

也有可能是每个 SQL 消耗资源并不多，但是突然之间，有大量的 Session 连进来导致 CPU 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。

**在 MySQL 服务器运行缓慢的情况下输入什么命令能缓解服务器压力？**

（1）检查系统的状态

通过操作系统的一些工具检查系统的状态，比如 CPU、内存、交换、磁盘的利用率，根据经验或与系统正常时的状态相比对，有时系统表面上看起来看空闲，这也可能不是一个正常的状态，因为 CPU 可能正等待IO的完成。除此之外，还应观注那些占用系统资源(CPU、内存)的进程。

- 使用 sar 来检查操作系统是否存在 IO 问题。
- 使用 vmstat 监控内存 CPU 资源。
- 磁盘 IO 问题，处理方式：做 raid10 提高性能 。
- 网络问题，telnet 一下 MySQL 对外开放的端口。如果不通的话，看看防火墙是否正确设置了。另外，看看 MySQ L是不是开启了 skip-networking 的选项，如果开启请关闭。

（2）检查 MySQL 参数

- max_connect_errors
- connect_timeout
- skip-name-resolve
- slave-net-timeout=seconds
- master-connect-retry

（3）检查 MySQL 相关状态值

- 关注连接数
- 关注下系统锁情况
- 关注慢查询（slow query）日志

# 其他问题

## MySQL 主从复制的流程是怎么样的？

MySQL 的主从复制是基于如下 3 个线程的交互（多线程复制里面应该是 4 类线程）：

- 1、Master 上面的 binlog dump 线程，该线程负责将 master 的 binlog event 传到 slave 。
- 2、Slave 上面的 IO 线程，该线程负责接收 Master 传过来的 binlog，并写入 relay log 。
- 3、Slave 上面的 SQL 线程，该线程负责读取 relay log 并执行。
- 4、如果是多线程复制，无论是 5.6 库级别的假多线程还是 MariaDB 或者 5.7 的真正的多线程复制， SQL 线程只做 coordinator ，只负责把 relay log 中的 binlog 读出来然后交给 worker 线程， woker 线程负责具体 binlog event 的执行。

🦅 **MySQL 如何保证复制过程中数据一致性？**

* 1、在 MySQL5.5 以及之前， slave 的 SQL 线程执行的 relay log 的位置只能保存在文件（ relay-log.info）里面，并且该文件默认每执行 10000 次事务做一次同步到磁盘， 这意味着 slave 意外 crash 重启时， SQL 线程执行到的位置和数据库的数据是不一致的，将导致复制报错，如果不重搭复制，则有可能会导致数据不一致。
  * MySQL 5.6 引入参数 relay_log_info_repository，将该参数设置为 TABLE 时， MySQL 将 SQL 线程执行到的位置存到 mysql.slave_relay_log_info 表，这样更新该表的位置和 SQL 线程执行的用户事务绑定成一个事务，这样 slave 意外宕机后，slave 通过 innodb 的崩溃恢复可以把 SQL 线程执行到的位置和用户事务恢复到一致性的状态。
* 2、MySQL 5.6 引入 GTID 复制，每个 GTID 对应的事务在每个实例上面最多执行一次， 这极大地提高了复制的数据一致性。
* 3、MySQL 5.5 引入半同步复制， 用户安装半同步复制插件并且开启参数后，设置超时时间，可保证在超时时间内如果 binlog 不传到 slave 上面，那么用户提交事务时不会返回，直到超时后切成异步复制，但是如果切成异步之前用户线程提交时在 master 上面等待的时候，事务已经提交，该事务对 master 上面的其他 session 是可见的，如果这时 master 宕机，那么到 slave 上面该事务又不可见了，该问题直到 5.7 才解决。
* 4、MySQL 5.7 引入无损半同步复制，引入参 rpl_semi_sync_master_wait_point，该参数默认为 after_sync，指的是在切成半同步之前，事务不提交，而是接收到 slave 的 ACK 确认之后才提交该事务，从此，复制真正可以做到无损的了。
* 5、可以再说一下 5.7 的无损复制情况下， master 意外宕机，重启后发现有 binlog 没传到 slave 上面，这部分 binlog 怎么办？？？分 2 种情况讨论， 1 宕机时已经切成异步了， 2 是宕机时还没切成异步？？？ 这个怎么判断宕机时有没有切成异步呢？？？ 分别怎么处理？？？

**MySQL 如何解决主从复制的延时性？**

5.5 是单线程复制，5.6 是多库复制（对于单库或者单表的并发操作是没用的），5.7 是真正意义的多线程复制，它的原理是基于 group commit， 只要 master 上面的事务是 group commit 的，那 slave 上面也可以通过多个 worker线程去并发执行。 和 MairaDB10.0.0.5 引入多线程复制的原理基本一样。

**工作遇到的复制 bug 的解决方法？**

5.6 的多库复制有时候自己会停止，我们写了一个脚本重新 start slave 。

**你是否做过主从一致性校验，如果有，怎么做的，如果没有，你打算怎么做？**

主从一致性校验有多种工具 例如 checksum、mysqldiff、pt-table-checksum 等。

## 聊聊 MySQL 备份方式？备份策略是怎么样的？

具体的，胖友可以看看 [《MySQL 高级备份策略》](http://www.qinglin.net/1015.html) 。主要有几个知识点：

- 数据的备份类型

  - 【常用】完全备份

    > 这是大多数人常用的方式，它可以备份整个数据库，包含用户表、系统表、索引、视图和存储过程等所有数据库对象。但它需要花费更多的时间和空间，所以，一般推荐一周做一次完全备份。

  - 增量备份

    > 它是只备份数据库一部分的另一种方法，它不使用事务日志，相反，它使用整个数据库的一种新映象。它比最初的完全备份小，因为它只包含自上次完全备份以来所改变的数据库。它的优点是存储和恢复速度快。推荐每天做一次差异备份。

  - 【常用】事务日志备份

    > 事务日志是一个单独的文件，它记录数据库的改变，备份的时候只需要复制自上次备份以来对数据库所做的改变，所以只需要很少的时间。为了使数据库具有鲁棒性，推荐每小时甚至更频繁的备份事务日志。

  - 文件备份

    > 数据库可以由硬盘上的许多文件构成。如果这个数据库非常大，并且一个晚上也不能将它备份完，那么可以使用文件备份每晚备份数据库的一部分。由于一般情况下数据库不会大到必须使用多个文件存储，所以这种备份不是很常用。

- 备份数据的类型

  - 热备份
  - 温备份
  - 冷备份

- 备份工具

  - cp
  - mysqldump
  - xtrabackup
  - lvm2 快照

🦅 **MySQL 几种备份方式？**

MySQL 一般有 3 种备份方式。

1）逻辑备份

使用 MySQL 自带的 mysqldump 工具进行备份。备份成sql文件形式。

- 优点：最大好处是能够与正在运行的 MySQL 自动协同工作，在运行期间可以确保备份是当时的点，它会自动将对应操作的表锁定，不允许其他用户修改(只能访问)。可能会阻止修改操作。SQL 文件通用方便移植。
- 缺点：备份的速度比较慢。如果是数据量很多的时候，就很耗时间。如果数据库服务器处在提供给用户服务状态，在这段长时间操作过程中，意味着要锁定表(一般是读锁定，只能读不能写入数据)，那么服务就会影响的。

2）物理备份

> 艿艿：因为现在主流是 InnoDB ，所以基本不再考虑这种方式。

直接拷贝只适用于 MyISAM 类型的表。这种类型的表是与机器独立的。但实际情况是，你设计数据库的时候不可能全部使用 MyISAM 类型表。你也不可能因为 MyISAM 类型表与机器独立，方便移植，于是就选择这种表，这并不是选择它的理由。

- 缺点：你不能去操作正在运行的 MySQL 服务器(在拷贝的过程中有用户通过应用程序访问更新数据，这样就无法备份当时的数据)，可能无法移植到其他机器上去。

3）双机热备份。

当数据量太大的时候备份是一个很大的问题，MySQL 数据库提供了一种主从备份的机制，也就是双机热备。

- 优点：适合数据量大的时候。现在明白了，大的互联网公司对于 MySQL 数据备份，都是采用热机备份。搭建多台数据库服务器，进行主从复制。

🦅 **数据库不能停机，请问如何备份? 如何进行全备份和增量备份?**

可以使用逻辑备份和双机热备份。

- 完全备份：完整备份一般一段时间进行一次，且在网站访问量最小的时候，这样常借助批处理文件定时备份。主要是写一个批处理文件在里面写上处理程序的绝对路径然后把要处理的东西写在后面，即完全备份数据库。
- 增量备份：对 ddl 和 dml 语句进行二进制备份。且 5.0 无法增量备份，5.1 后可以。如果要实现增量备份需要在 `my.ini` 文件中配置备份路径即可，重启 MySQL 服务器，增量备份就启动了。

🦅 **你的备份工具的选择？备份计划是怎么样的？**

视库的大小来定，一般来说 100G 内的库，可以考虑使用 mysqldump 来做，因为 mysqldump 更加轻巧灵活，备份时间选在业务低峰期，可以每天进行都进行全量备份(mysqldump 备份出来的文件比较小，压缩之后更小)。

100G 以上的库，可以考虑用 xtrabackup 来做，备份速度明显要比 mysqldump 要快。一般是选择一周一个全备，其余每天进行增量备份，备份时间为业务低峰期。

> 艿艿：一般情况下，选择每周备份 + 每天增量备份比较靠谱。

🦅 **备份恢复时间是多长？**

物理备份恢复快，逻辑备份恢复慢。

这里跟机器，尤其是硬盘的速率有关系，以下列举几个仅供参考：

- 20G 的 2 分钟（mysqldump）
- 80G 的 30分钟（mysqldump)
- 111G 的 30分钟（mysqldump)
- 288G 的 3 小时（xtrabackup)
- 3T 的 4 小时（xtrabackup)

逻辑导入时间一般是备份时间的 5 倍以上。

🦅 **备份恢复失败如何处理？**

首先在恢复之前就应该做足准备工作，避免恢复的时候出错。比如说备份之后的有效性检查、权限检查、空间检查等。如果万一报错，再根据报错的提示来进行相应的调整。

🦅 **mysqldump 和 xtrabackup 实现原理？**

1）mysqldump

mysqldump 是最简单的逻辑备份方式。

- 在备份 MyISAM 表的时候，如果要得到一致的数据，就需要锁表，简单而粗暴。
- 在备份 InnoDB 表的时候，加上 `–master-data=1 –single-transaction` 选项，在事务开始时刻，记录下 binlog pos 点，然后利用 MVCC 来获取一致的数据，由于是一个长事务，在写入和更新量很大的数据库上，将产生非常多的 undo ，显著影响性能，所以要慎用。
- 优点：简单，可针对单表备份，在全量导出表结构的时候尤其有用。
- 缺点：简单粗暴，单线程，备份慢而且恢复慢，跨 IDC 有可能遇到时区问题

2）xtrabackup

xtrabackup 实际上是物理备份+逻辑备份的组合。

- 在备份 InnoDB 表的时候，它拷贝 ibd 文件，并一刻不停的监视 redo log 的变化，append 到自己的事务日志文件。在拷贝 ibd 文件过程中，ibd文件本身可能被写”花”，这都不是问题，因为在拷贝完成后的第一个 prepare 阶段，xtrabackup 采用类似于 Innodb 崩溃恢复的方法，把数据文件恢复到与日志文件一致的状态，并把未提交的事务回滚。
- 如果同时需要备份 MyISAM 表以及 InnoDB 表结构等文件，那么就需要用 `flush tables with lock` 来获得全局锁，开始拷贝这些不再变化的文件，同时获得 binlog 位置，拷贝结束后释放锁，也停止对 redo log 的监视。

🦅 **如何从 mysqldump 产生的全库备份中只恢复某一个库、某一张表？**

具体可见 [《MySQL 全库备份中恢复某个库和某张表以及 mysqldump 参数 –ignore-table 介绍》](http://blog.51cto.com/wujianwei/1959473) 文章。





