<!-- MarkdownTOC -->
- [分布式事务基础](#分布式事务基础)
  - [什么是分布式事务？](#什么是分布式事务)
  - [CAP 理论与 BASE 理论是什么？](#cap-理论与-base-理论是什么)
    - [CAP 理论](#cap-理论)
    - [BASE 理论](#base-理论)
    - [BASE 与 CAP 区别](#base-与-cap-区别)
  - [如何理解事务一致性？](#如何理解事务一致性)
  - [分布式事务协议有哪些呢？](#分布式事务协议有哪些呢)
    - [两阶段提交协议 2PC](#两阶段提交协议-2pc)
    - [三阶段提交协议 3PC](#三阶段提交协议-3pc)
  - [什么是柔性事务？](#什么是柔性事务)
- [分布式事务实现](#分布式事务实现)
  - [聊聊 XA 方案？](#聊聊-xa-方案)
    - [什么是XA](#什么是xa)
    - [MySQL XA事务的实现](#mysql-xa事务的实现)
    - [XA事务的缺点](#xa事务的缺点)
  - [聊聊 本地消息表？](#聊聊-本地消息表)
  - [聊聊 事务消息方案？](#聊聊-事务消息方案)
  - [聊聊 最大努力通知方案？](#聊聊-最大努力通知方案)
  - [聊聊 TCC 方案？](#聊聊-tcc-方案)
  - [聊聊 SAGA 方案？](#聊聊-saga-方案)
  - [聊聊 AT 方案？](#聊聊-at-方案)
  - [如何选择事务解决方案？](#如何选择事务解决方案)
- [分布式相关算法](#分布式相关算法)
  - [什么是分布式共识？](#什么是分布式共识)
  - [Paxos 算法是什么？](#paxos-算法是什么)
  - [Raft 算法是什么？](#raft-算法是什么)

<!-- /MarkdownTOC -->

# 分布式事务基础

## 什么是分布式事务？

分布式事务，可以理解为：**分布式条件下，多个节点操作的整体事务一致性**。事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。

本质上来说，分布式事务就是为了保证不同数据库的数据一致性。或者，分布式事务 = n 个本地事务。通过事务管理器，达到 n 个本地事务要么全部成功，要么全部失败。

**为什么要有分布式事务？**

随着互联网的发展，业务系统的复杂度及数据量都在显著提升，集中式环境已经不能满足业务的需要了，只能按照业务为单位进行数据拆分(包含：垂直拆分与水平拆分)；以及按照业务为单位提供服务，从早期的集中式转变为面向服务架构的分布式应用环境。这种场景中采用分布式事务来保持不同资源服务器的数据一致性是很有必要的。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630142611507.png" width="400px"/>
</div>

## CAP 理论与 BASE 理论是什么？

### CAP 理论

CAP 理论对分布式系统的特性做了高度抽象，形成了三个指标： 

* **一致性（Consistency）** ：各节点数据一致，而不是数据完整。
* **可用性（Availability）** ：服务可以，但不保证数据一致。
* **分区容错性（Partition Tolerance）**：强调的是集群对分区故障的容错能力。

CAP 不可能三角说的是对于一个分布式系统而言，一致性、可用性、分区容错性3 个指标不可兼得，最多在3 个指标中选择 2 个。**CAP理论的分区容错性P是一定要满足的，在此基础上，只能再选择可用性A或者一致性C其中一个**。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630170408315.png" width="500px"/>
</div>

因此，**分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。**

> **为啥不能同时保证 CA 呢？**
>
> 举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。
>
> **选择的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。**

**CAP 实际应用案例**

这里简单以 Dubbo 为例说一说。**注册中心 Registry 在其中扮演了什么角色呢？提供了什么服务呢？**

注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630173118823.png" width="600px"/>
</div>


常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos...。

1. **ZooKeeper 保证的是 CP。** 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是， ZooKeeper 不保证每次请求的可用性比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。
2. **Eureka 保证的则是 AP。** Eureka 在设计的时候就是优先保证 A （可用性）。在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。 Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。
3. **Nacos 不仅支持 CP 也支持 AP。**
4. **MySQL 主从异步复制是 AP 系统**。
5. **MySQL 主从半同步复制是 CP 系统**。
6. **Redis 主从同步是 AP 系统**。

### BASE 理论

**BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。**为什么这样说呢？

AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。

**BASE** 是 **Basically Available（基本可用）** 、**Soft-state（软状态）** 和 **Eventually Consistent（最终一致性）** 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630172559554.png" width="500px"/>
</div>

**基本可用**：指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。

- **响应时间上的损失**： 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。
- **系统功能上的损失**：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。

**软状态**：允许系统中的数据存在中间状态（**CAP 理论中的数据不一致**），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。

**最终一致性**：强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

> 分布式一致性的 3 种级别：
>
> 1. **强一致性** ：系统写入了什么，读出来的就是什么。
>
> 2. **弱一致性** ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。
>
> 3. **最终一致性** ：弱一致性的升级版。，系统会保证在一定时间内达到数据一致的状态，
>
> **业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。**

### BASE 与 CAP 区别

应用CAP理论时，**如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA **。

* CA 模型，在分布式系统中不存在。因为舍弃 P，意味着舍弃分布式系统，就比如单机版关系型数据库 MySQL，如果 MySQL 要考虑主备或集群部署时，它必须考虑 P。

* CP 模型，采用 CP 模型的分布式系统，一旦因为消息丢失、延迟过高发生了网络分区，就影响用户的体验和业务的可用性。因为为了防止数据不一致，集群将拒绝新数据的写入，典型的应用是 ZooKeeper，Etcd 和 HBase。

* AP 模型，采用 AP 模型的分布式系统，实现了服务的高可用。用户访问系统的时候，都能得到响应数据，不会出现响应错误，但当出现分区故障时，相同的读操作，访问不同的节点，得到响应数据可能不一样。典型应用就比如 Cassandra 和 DynamoDB。

BASE理论是**对CAP理论中AP 方案的延伸**：

* BASE 理论是对 CAP 中一致性和可用性权衡的结果，它来源于对大规模互联网分布式系统实践的总结，是基于 CAP 定理逐步演化而来的。它的核心思想是，如果不是必须的话，不推荐实现事务或强一致性，鼓励可用性和性能优先，根据业务的场景特点，来实现非常弹性的基本可用，以及实现数据的最终一致性。
* BASE 理论主张通过牺牲部分功能的可用性，实现整体的基本可用，也就是说，通过服务降级的方式，努力保障极端情况下的系统可用性。
* ACID 理论是传统数据库常用的设计理念，追求强一致性模型。BASE 理论支持的是大型分布式系统，通过牺牲强一致性获得高可用性。BASE 理论在很大程度上，解决了事务型系统在性能、容错、可用性等方面痛点。另外我再多说一句，BASE 理论在 NoSQL 中应用广泛，是 NoSQL 系统设计的事实上的理论支撑。

## 如何理解事务一致性？

**强一致性**：任何一次读都能读到某个数据的最近一次写的数据。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。简言之，在任意时刻，所有节点中的数据是一样的。

**弱一致性**：数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。

**最终一致性**：不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。

## 分布式事务协议有哪些呢？

### 两阶段提交协议 2PC

分布式系统的一个难点是如何保证架构下多个节点在进行事务性操作的时候保持一致性。为实现这个目的，二阶段提交算法的成立基于以下假设：

- 该分布式系统中，存在一个节点作为协调者(Coordinator)，其他节点作为参与者(Cohorts)。且节点之间可以进行网络通信。
- 所有节点都采用预写式日志，且日志被写入后即被保持在可靠的存储设备上，即使节点损坏不会导致日志数据的消失。
- 所有节点不会永久性损坏，即使损坏后仍然可以恢复。

**1. 第一阶段（投票阶段）：**

1. 协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。
2. 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）
3. 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个"同意"消息；如果参与者节点的事务操作实际执行失败，则它返回一个"中止"消息。

**2. 第二阶段（提交执行阶段）：**

当协调者节点从所有参与者节点获得的相应消息都为"同意"时：

1. 协调者节点向所有参与者节点发出"正式提交(commit)"的请求。
2. 参与者节点正式完成操作，并释放在整个事务期间内占用的资源。
3. 参与者节点向协调者节点发送"完成"消息。
4. 协调者节点受到所有参与者节点反馈的"完成"消息后，完成事务。

如果任一参与者节点在第一阶段返回的响应消息为"中止"，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：

1. 协调者节点向所有参与者节点发出"回滚操作(rollback)"的请求。
2. 参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。
3. 参与者节点向协调者节点发送"回滚完成"消息。
4. 协调者节点受到所有参与者节点反馈的"回滚完成"消息后，取消事务。

不管最后结果如何，第二阶段都会结束当前事务。

二阶段提交看起来确实能够提供原子性的操作，但是不幸的事，二阶段提交还是有几个缺点的：

1. 执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。
2. 参与者发生故障。协调者需要给每个参与者额外指定超时机制，超时后整个事务失败。（没有多少容错机制）
3. 协调者发生故障。参与者会一直阻塞下去。需要额外的备机进行容错。（这个可以依赖后面要讲的Paxos协议实现HA）
4. 二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

为此，Dale Skeen和Michael Stonebraker在“A Formal Model of Crash Recovery in a Distributed System”中提出了三阶段提交协议（3PC）。

### 三阶段提交协议 3PC

与两阶段提交不同的是，三阶段提交有两个改动点。

- 引入超时机制。同时在协调者和参与者中都引入超时机制。
- 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。

也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。

**1. CanCommit阶段**

3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。

1. 事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。
2. 响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No

**2. PreCommit阶段**

协调者根据参与者的反应情况来决定是否可以记性事务的PreCommit操作。根据响应情况，有以下两种可能。 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。

1. 发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段。
2. 事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。
3. 响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。

假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。

1. 发送中断请求 协调者向所有参与者发送abort请求。
2. 中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。

**3. doCommit阶段** 该阶段进行真正的事务提交，也可以分为以下两种情况。

该阶段进行真正的事务提交，也可以分为以下两种情况。

**3.1 执行提交**

1. 发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。
2. 事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。
3. 响应反馈 事务提交完之后，向协调者发送Ack响应。
4. 完成事务 协调者接收到所有参与者的ack响应之后，完成事务。

**3.2 中断事务** 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。

1. 发送中断请求 协调者向所有参与者发送abort请求
2. 事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。
3. 反馈结果 参与者完成事务回滚之后，向协调者发送ACK消息
4. 中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。

## 什么是柔性事务？

如果将实现了 ACID 的事务要素的事务称为刚性事务的话，那么基于 BASE 事务要素的事务则称为柔 性事务。 

BASE 是**基本可用、柔性状态和最终一致性**这三个要素的缩写。

* 基本可用（Basically Available）保证分布式事务参与方不一定同时在线。
* 柔性状态（Soft state）则允许系统状态更新有一定的延时，这个延时对客户来说不一定能够察觉。
* 而最终一致性（Eventually consistent）通常是通过消息传递的方式保证系统的最终一致性。

在 ACID 事务中对隔离性的要求很高，在事务执行过程中，必须将所有的资源锁定。 柔性事务的理念 则是通过业务逻辑将互斥锁操作从资源层面上移至业务层面。**通过放宽对强一致性要求，来换取系统吞吐量的提升**。

`本地事务 -> XA（2PC）-> BASE`的对比如下：

| 对比     | 本地事务         | 两（三）阶段事务 | 柔性事务      |
| -------- | ---------------- | ---------------- | ------------- |
| 业务改造 | 无               | 无               | 实现相关接口  |
| 一致性   | 不支持           | 支持             | 最终一致      |
| 隔离性   | 不支持           | 支持             | 业务保证方    |
| 并发性能 | 无影响           | 严重衰退         | 略微衰退      |
| 适合场景 | 业务方处理不一致 | 短事务&低并发    | 长事务&高并发 |

BASE 柔性事务常见模式：

* TCC：通过手动补偿处理

* AT：通过自动补偿处理

# 分布式事务实现

如何实现分布式事务呢？通常由两个思路：

* 理想状态：直接像直接像单机数据库事务一样，多个数据库自动通过某种协调机制，实现了跨数据库节点的一致性。

  使用场景：要求严格的一致性，比如金融交易类业务。

* 一般情况：可以容忍一段时间的数据不一致，最终通过超时终止，调度补偿，等等方式，实现数据的最终状态一致性。

  使用场景：准实时或非实时的处理，比如 T+1的各类操作，或者电商类操作。

按照这两种思路，可以把分布式事务方案分为以下7种：

* 强一致性：**XA**
* 弱一致性 + 最终一致性
  * 不用事务，业务侧补偿冲正： **本地消息表，事务消息方案，最大努力通知方案**
  * 柔性事务，使用一套事务框架保证最终一致的事务：**TCC、SAGA、AT**

## 聊聊 XA 方案？

### 什么是XA

基于强一致性的思路，就有了基于数据库本身支持的协议，XA 分布式事务。 XA 整体设计思路可以概括为，如何在现有事务模型上微调扩展，实现分布式事务。

**XA**是X/Open DTP组织（X/Open DTP group）定义的两阶段提交协议，XA被许多数据库（如Oracle、DB2、SQL Server、MySQL）和中间件等工具(如CICS 和 Tuxedo)本地支持 。X/Open DTP模型主要有如下角色：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630144950746.png" width="600px"/>
</div>


其中主要角色有：

* 应用程序（Application Program ，简称 **AP**）： 用于定义事务边界(即定义事务的开始和结束)，并且在事务边界内对资源进行操作；
* 资源管理器（Resource Manager，简称 **RM**）： 如数据库、文件系统等，并提供访问资源的方式；
* 事务管理器 （Transaction Manager ，简称 **TM**）：负责分配事务唯一标识，监控事务的执行进度，并负责事务的提交、回滚等。

XA 主要规定了RM与TM之间的交互，下面来看下XA规范中定义的RM 和 TM交互的接口：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630145449952.png" width="500px"/>
</div>


其中重要的接口有：

* `xa_start` ：负责开启或者恢复一个事务分支；
* `xa_end`： 负责取消当前线程与事务分支的关联；
* `xa_prepare`：询问 RM 是否准备好提交事务分支；
* `xa_commit`：通知 RM 提交事务分支；
* `xa_rollback`： 通知 RM 回滚事务分支；
* `xa_recover` : 需要恢复的 XA 事务。

XA规范的基础是**两阶段提交协议**，其中：

* 第一阶段：事务管理器TM 请求所有的资源管理器RM 预提交（prepare）各自的事务分支，以确认RM是否有能力提交各自事务。
* 第二阶段：事务管理器TM 根据第一阶段资源管理器RM预提交的结果，决定提交还是回滚事务。

### MySQL XA事务的实现

MySQL 从5.0.3开始支持 `InnoDB` 引擎的 XA 分布式事务，MySQL Connector/J 从5.0.0版本开始支持 XA。DTP 模型中，MySQL 属于资源管理器（RM）。分布式事务中存在多个 RM，由事务管理器 TM 来统一进行协调。

MySQL下XA事务语法：

```mysql
XA {START|BEGIN} xid [JOIN|RESUME]  启动一个XA事务 (xid必须是一个唯一值; [JOIN|RESUME]字句不被支持) 
XA END xid [SUSPEND [FOR MIGRATE]]  结束一个XA事务 ( [SUSPEND [FOR MIGRATE]] 字句不被支持)
XA PREPARE xid   				    准备
XA COMMIT xid [ONE PHASE]           提交XA事务
XA ROLLBACK xid                     回滚XA事务
XA RECOVER                          查看处于PREPARE 阶段的所有XA事务
```

MySQL XA 事务状态图如下：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/2021063015140946.png" width="800px"/>
</div>


需要注意的是，**XA 事务和非XA 事务（即本地事务）时互斥的**。例如，已经执行了XA START命令开启了一个XA事务后，则本地事务不会启动，直到XA事务被提交或被回滚为止。相反地，如果已经使用了START TRANSACTION启动本地事务，那么XA事务不能被使用，直到本地事务提交或者回滚为止。

完整的 XA 事务处理过程：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630152019207.png" width="800px"/>
</div>


------

思考问题：XA 过程中，事务失败怎么办？ 

1、业务 SQL 执行过程，某个 RM 崩溃怎么处理？回滚 

2、全部 prepare 后，某个 RM 崩溃怎么处理？ 回滚

3、commit 时，某个 RM 崩溃怎么办？重试commit

------

单个 MySQL 的内部操作：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630152219943.png" width="800px"/>
</div>


**5.7对 MySQL XA 的优化/bug 修复**

`MySQL<5.7`版本会出现的问题 ： 已经 prepare 的事务，在客户端退出或者服务宕机的时候，2PC 的事务会被回滚 ；在服务器故障重启提交后，相应的 `binlog` 被丢失。

> MySQL 5.6版本在客户端退出的时候，自动把已经 prepare 的事务回滚了，那么 MySQL 为什么要这样做？这主要取决于 MySQL 的内部实现， MySQL 5.7以前的版本，对于 prepare 的事务， MySQL 是不会记录 binlog 的（官方说是减少 fsync，起到了优化的作用）。只有当分布式事务提交的时候才会把前面的操作写入 binlog 信息，所以对于 binlog 来说，分布式事务与普通的事务没有区别，而 prepare 以前的操作信息都保存在连接的 IO_CACHE 中，如果这个时候客户退 出了，以前的 binlog 信息都会被丢失，再次重连后允许提交的话，会造成 Binlog 丢失，从而造成主从数据的不一致，所 以官方在客户端退出的时候直接把已经 prepare 的事务都回滚了！

`MySQL>5.7`版本的优化（https://dev.mysql.com/worklog/task/?id=6860） 

* MySQL 对于分布式事务，在 prepare 的时候就完成了写 binlog 的操作，通过新增一种叫 `XA_prepare_log_event`的 event 类型来实现，这是与以前版本的主要区别（以前版本 prepare 时不写binlog）

### XA事务的缺点

XA事务的确能保证强一致性，但是也有如下几个缺点：（注意**XA事务并不会改变隔离级别**）

* **同步阻塞问题**

全局事务内部包含了多个独立的事务分支，这一组事务分支要不都成功，要不都失败，各个事务分支的ACID特性共同构成了全局事务的ACID特性。也就是将单个事务分支的支持的ACID特性提升一个层次（up a level）到分布式事务的范畴。即使在非分布式事务中（即本地事务），如果对操作读很敏感，我们也需要将事务隔离级别设置为SERIALIZABLE。而对于分布式事务来说，更是如此，可重复读隔离级别不足以保证分布式事务一致性。 （一般情况下，不需要调高隔离级别）

也就是说，如果我们使用MySQL来支持XA分布式事务的话，那么最好将事务隔离级别设置为SERIALIZABLE。地球人都知道， SERIALIZABLE（串行化）是四个事务隔离级别中最高的一个级别，也是执行效率最低的一个级别。

* **单点故障** 

由于协调者的重要性，一旦协调者TM发生故障，参与者RM会一直阻塞下去，尤其在第二阶段，协调者发生故障，那么所有的参与者还处于锁定事务资源的状态中，而无法继续完成事务操作。（如果协调者挂掉，可以重新选举一个协调者，但是无法解决因 为协调宕机导致的参与者处于阻塞状态的问题）。（成熟的XA框架需要考虑TM的高可用性）

* **数据不一致** 

在二阶段提交的阶段二中，当协调者向参与者发功commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接收到了commit请求，而在这部分参与者接到commit请求之后就会执行commit操 作。但是其他部分未接到commit请求的机器则无法执行事务提交，于是整个分布式系统便出现了数据不一致的现象。（极端情况下，一定有事务失败问题，需要监控和人工处理）

如何解决呢？

推荐使用使用`ShardingSphere`。`ShardingSphere` 支持基于 XA 的强一致性事务解决方案，可以通过 SPI 注入不同的第三方组件作为事务管理器实现 XA 协议，如 `Atomikos` 和 `Narayana` 。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630153151535.png" width="800px"/>
</div>

## 聊聊 本地消息表？

本地消息表这种实现方式应该是业界使用最多的，其核心思想是将分布式事务拆分成本地事务进行处理，这种思路是来源于ebay。我们可以从下面的流程图中看出其中的一些细节：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/1d1deebb714f44e3af49ee577b5b3658.png" width="1000px"/>
</div>

1. A 系统在自己本地一个事务里操作同时，插入一条数据到消息表；
2. 接着 A 系统将这个消息发送到 MQ 中去；
3. B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样**保证不会重复处理消息**；
4. B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态；
5. 如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理；
6. 这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。

这个方案说实话最大的问题就在于**严重依赖于数据库的消息表来管理事务**，消息表与业务系统耦合度高，如果是高并发场景咋办呢？怎么扩展呢？比较复杂。

本地消息队列是 BASE 理论，是最终一致模型，适用于对一致性要求不高的。实现这个模型时需要注意重试的幂等。

## 聊聊 事务消息方案？

又叫可靠消息最终一致性方案，也就是说利用支持事务消息的消息队列来实现分布式事务。比如阿里的 RocketMQ 就支持消息事务。其思路大致为：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/89f925cd50c24ad28c21510b0145ceeb.png" width="1000px"/>
</div>

1. A 系统先发送一个 prepared 消息到 mq，如果这个 prepared 消息发送失败那么就直接取消操作别执行了；
2. 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息；
3. 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；
4. mq 会自动**定时轮询**所有 prepared 消息回调你的接口，确认这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。
5. 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。

也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了RocketMQ会定时轮询消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。

**这个还是比较合适的，目前国内互联网公司大都是这么玩儿的**。

## 聊聊 最大努力通知方案？

最大努力通知事务的主流实现仍是基于MQ来进行事务控制。最大努力通知事务和事务消息都是通知型事务，主要适用于那些需要异步更新数据，并且对数据的实时性要求较低的场景。

最大努力通知事务主要用于外部系统，因为外部的网络环境更加复杂和不可信，所以只能尽最大努力去通知实现数据最终一致性，比如充值平台与运营商、支付对接、商户通知等等跨平台、跨企业的系统间业务交互场景；而事务消息主要适用于内部系统的数据最终一致性保障，因为内部相对比较可控，比如订单和购物车、收货与清算、支付与结算等等场景。

普通消息是无法解决本地事务执行和消息发送的一致性问题的。因为消息发送是一个网络通信的过程，发送消息的过程就有可能出现发送失败、或者超时的情况。超时有可能发送成功了，有可能发送失败了，消息的发送方是无法确定的，所以此时消息发送方无论是提交事务还是回滚事务，都有可能不一致性出现。所以通知型事务的难度在于投递消息和参与者自身本地事务的一致性保障。

因为核心要点一致，都是为了保证消息的一致性投递，所以最大努力通知事务在投递流程上跟事务消息是一样的，因此也有两个分支：

* 基于MQ自身的事务消息方案

* 基于DB的本地事务消息表方案

> 参考[https://juejin.cn/post/6865688050173902862](https://juejin.cn/post/6865688050173902862)一文。

## 聊聊 TCC 方案？

TCC 模式即将每个服务业务操作分为两个阶段，第一个阶段检查并预留相关资源，第二阶段根据所有 服务业务的 Try 状态来操作，如果都成功，则进行 Confirm 操作，如果任意一个 Try 发生错误，则全 部 Cancel.

TCC 使用要求就是业务接口都必须实现三段逻辑： 

1. **准备操作 Try**：完成所有业务检查，预留必须的业务资源。
2. **确认操作 Confirm**：真正执行的业务逻辑，不做任何业务检查，只使用 Try 阶段预留的业务资源。 因此，只要 Try 操作成功，Confirm 必须能成功。另外，Confirm 操作需满足幂等性，保证一笔分布式事务能且只能成功一次。 
3. **取消操作 Cancel**：释放 Try 阶段预留的业务资源。同样的，Cancel 操作也需要满足幂等性。

TCC 不依赖 RM 对分布式事务的支持，而是通过对业务逻辑的分解来实现分布式事务，不同于 AT 的是**需要自行定义各个阶段的逻辑，对业务有侵入**。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630155411134.png" width="800px"/>
</div>


TCC 需要注意的几个问题： 

* **允许空回滚** ：事务协调器在调用TCC服务的一阶段Try操作时，可能会出现因为丢包而导致的网络超时，此时事务协调器会触发二阶段回滚，调用TCC服务的Cancel操作；
  * TCC服务在未收到Try请求的情况下收到Cancel请求，这种场景被称为空回滚，TCC服务在实现时应当允许空回滚的执行。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630161325327.png" width="600px"/>
</div>


* **防悬挂控制** ：事务协调器在调用TCC服务的一阶段Try操作时，可能会出现因网络拥堵而导致的超时，此时事务协调器会触发二阶段回滚，调用TCC服务的Cancel操作；在此之后，拥堵在网络上的一阶段Try数据包被TCC服务收到，出现了二阶段Cancel请求比一阶段Try请求先执行的情况；
  * 用户在实现TCC服务时，应当允许空回滚，但是要拒绝执行空回滚之后到来的一阶段Try请求。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630161325162.png" width="600px"/>
</div>


* **幂等设计**：无论是网络数据包重传，还是异常事务的补偿执行，都会导致TCC服务的Try、Confirm或者Cancel操作被重复执行。
  * 在实现TCC服务时，需要考虑幂等控制，即Try、Confirm、Cancel 执行一次和执行多次的业务结果是一样的。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630161324823.png" width="400px"/>
</div>

## 聊聊 SAGA 方案？

Saga 核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。

Saga 的组成如下：

- 每个 Saga 由一系列 sub-transaction Ti 组成;
- 每个Ti 都有对应的补偿动作 Ci ，补偿动作用于撤销 Ti 造成的结果。这里的每个 T ，都是一个本地事务;
- 可以看到，和 TCC 相比，**Saga 没有“预留 try”动作 ，它的 Ti 就是直接提交到库**。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630162030512.png" width="400px"/>
</div>


Saga的执行顺序有两种：

- 子事务序列 T1, T2, …, Tn得以完成 (最佳情况)。
- 或者序列 T1, T2, …, Tj, Cj, …, C2, C1, 0 < j < n, 得以完成。

Saga 定义了两种恢复策略：

- 向后恢复：补偿所有已完成的事务，如果任一子事务失败。

- 向前恢复：重试失败的事务，假设每个子事务最终都会成功。

## 聊聊 AT 方案？

AT 模式是一种无侵入的分布式事务解决方案，支持两阶段提交，自动生成反向 SQL。Seata框架，实现了该模式。

在 AT 模式下，用户只需关注自己的“业务 SQL”，用户的 “业务 SQL” 作为一阶段，Seata 框架会自动生成事务的二阶段提交和回滚操作。

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210630161653405.png" width="600px"/>
</div>

## 如何选择事务解决方案？

1、业务上有强一致性要求的场景时，优先考虑 XA 规范的两阶段提交；

2、业务上只需要最终一致性的场景时，可以在根据具体场景在柔性事务方案中进行选择。

* AT 模式是无侵入的分布式事务解决方案，适用于不希望对业务进行改造的场景，几乎零学习成本。
* TCC 模式是高性能分布式事务解决方案，适用于核心系统等对性能有很高要求的场景。
* Saga 模式是长事务解决方案，适用于业务流程长且需要保证事务最终一致性的业务系统，Saga 模式一阶段就会提交本地事务，无锁，长流程情况下可以保证性能，多用于渠道层、集成层业务系统。事务参与者可能是其它公司的服务或者是遗留系统的服务，无法进行改造和提供 TCC 要求的接口，也可以使用 Saga 模式。

# 分布式相关算法

## 什么是分布式共识？

如果只有一个节点，节点作为数据库来存储数据，当客户端提交数据进行修改，单个节点更新数据，数据达成一致，因为只有一个节点，很容易达成共识。

当使用【多个节点】进行数据存储，一份数据可以在多台机器上进行拷贝，如何保证多个节点的【数据一致性】，就是分布式共识的问题；

当前解决这个问题比较流行的算法包括 Paxos 和 Raft算法。

## Paxos 算法是什么？

> TODO

## Raft 算法是什么？

> TODO

[分布式事务理论、算法和协议总结](https://juejin.cn/post/6861568940125437959)
