<!-- MarkdownTOC -->
- [什么是缓存？](#什么是缓存)
- [何时使用缓存？](#何时使用缓存)
- [缓存的加载时机呢？](#缓存的加载时机呢)
- [缓存有哪些特征呢？](#缓存有哪些特征呢)
  - [命中率](#命中率)
  - [最大元素（或最大空间）](#最大元素或最大空间)
  - [清空策略](#清空策略)
- [是否能手写一下 LRU 代码的实现？](#是否能手写一下-lru-代码的实现)
- [缓存常见分类与应用场景？](#缓存常见分类与应用场景)
- [如果避免缓存”穿透”的问题？](#如果避免缓存穿透的问题)
- [如果避免缓存”击穿”的问题？](#如果避免缓存击穿的问题)
- [如何避免缓存”雪崩”的问题？](#如何避免缓存雪崩的问题)
- [缓存和数据库的一致性如何保证？](#缓存和数据库的一致性如何保证)
- [什么是缓存预热？如何实现缓存预热？](#什么是缓存预热如何实现缓存预热)
- [缓存如何存储 POJO 对象？](#缓存如何存储-pojo-对象)

<!-- /MarkdownTOC -->

## 什么是缓存？

“缓存”一词可谓耳熟能详了，那么到底什么是缓存呢？缓存的本质是什么呢？

**缓存（cache）就是一个临时存放数据的地方。广义上来讲，缓存就是为了加速数据处理，让业务更快地访问而临时存放的冗余/副本数据**。

使用缓存后，当用户查询数据时，首先会去缓存中查找，如果找到了就直接使用；如果找不到，就再到数据的原始位置去寻找。所以说，缓存本质上是因为系统各级处理速度不匹配，导致我们需要利用**空间换时间**的技术，把读写速度【慢】的介质的数据保存在读写速度【快】的介质中，从而来来提升数据的访问速度，减少时间消耗。

在实际的应用中，缓存无处不在，例如：

* 内存，就可以看做是 CPU 和 磁盘之间的缓存。
* CPU 与内存的处理速度也不一致，出现 L1&L2&L3 三级缓存。
* 网络处理，数据库引擎的各种 Buffer，都可以看做是缓存。

## 何时使用缓存？

在实际开发中，要根据自己业务的实际数据类型，分析和评估出哪些数据访问对性能的影响比较大。如果按照数据的使用频率和方式分类，大致可以分为其中几类：

* 静态数据：一般不变，类似于字典表。
* 准静态数据：变化频率很低，类似部门结构设置，全国行政区划数据等。
* 中间状态数据：一些计算的可复用中间数据，变量副本，配置中心的本地副本。
* 热数据：使用频率高。
* `读写比`大的数据：读的频率>>写的数据。
* ... ...

按照上面的简介，为了提高数据访问速度，对于**热数据和`读写比`大的数据**，适合使用缓存来进行访问。

问题是，在互联网应用服务中，使用缓存技术的目的就只是为了提升访问速度吗？

* 不尽然。例如**在分布式系统中，缓存机制实际上是系统性能设计的一个重要权衡手段**。比如某个数据库的负载比较高，接近系统瓶颈时，我们就可以使用缓存技术。不过此时缓存的功能就是负载均衡而非提升访问速度了。

**缓存的有效性与数据同步相关问题**

* 为什么一般说变动频率大、一致性要求高的数据，不太适合用缓存？ 
  * 变化大，意味着内存缓存数据与原始数据库数据，一直存在差异；
  * 一致性要求高，意味着只有使用原始数据，甚至加了事务，才是保险的。

* 如何评价缓存的有效性？ 
  * **读写比（ N : 1 ）**：对数据的写操作导致数据变动，意味着维护成本。
  * **命中率（90%+ ）**：命中缓存意味着缓存数据被使用，意味着有价值。 

可见，对于 **数据一致性，性能，成本** 的综合衡量，是引入缓存的必须指标。

------

**使用缓存会带来什么问题？**

* **系统预热导致启动慢** ：试想一下，一个系统启动需要预热半个小时。 导致系统不能做到快速应对故障宕机等问题。
* **系统内存资源耗尽** ：只加入数据，不能清理旧数据。 旧数据处理不及时，或者不能有效识别无用数据。
* **提高了系统复杂度与维护成本**。

## 缓存的加载时机呢？

缓存加载时机主要分为**启动全量加载和懒加载**。

全局加载特点是全局有效，使用简单。而懒加载方式又细分为两类：

* 同步使用加载：先看缓存是否有数据，没有的话从数据库读取；读取的数据，先放到内存，然后返回给调用方 。

* 延迟异步加载：从缓存获取数据，不管是否为空直接返回。
  * （策略1异步）如果为空，则发起一个异步加载的线程，负责加载数据；
  * （策略2解耦）异步线程负责维护缓存的数据，定期或根据条件触发更新。

## 缓存有哪些特征呢？

### 命中率

`命中率=返回正确结果数/请求缓存次数`，命中率问题是缓存中的一个非常重要的问题，它是衡量缓存有效性的重要指标。命中率越高，表明缓存的使用率越高。

### 最大元素（或最大空间）

缓存中可以存放的最大元素的数量，一旦缓存中元素数量超过这个值（或者缓存数据所占空间超过其最大支持空间），那么将会触发缓存启动**清空策略**根据不同的场景合理的设置最大元素值往往可以一定程度上提高缓存的命中率，从而更有效的时候缓存。

### 清空策略

如上所述，缓存的存储空间有限制，当缓存空间被用满时，如何保证在稳定服务的同时有效提升命中率？这就由缓存清空策略来处理，设计适合自身数据特征的清空策略能有效提升命中率。常见的一般策略有：

- **FIFO(first in first out)**

先进先出策略，最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用。

- **LFU(less frequently used)**

最少使用策略，无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的`hitCount`（命中次数）。在保证高频数据有效性场景下，可选择这类策略。

- **LRU(least recently used)**

最近最少使用策略，无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。在热点数据场景下较适用，优先保证热点数据的有效性。

除此之外，还有一些简单策略比如：

- 根据过期时间判断，清理过期时间最长的元素；
- 根据过期时间判断，清理最近要过期的元素；
- 随机清理；
- 根据关键字（或元素内容）长短清理等。

## 是否能手写一下 LRU 代码的实现？

手写 LRU 代码的实现，有多种方式。其中，最简单的是基于 `LinkedHashMap` 来实现，代码如下：

```java
class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int CACHE_SIZE;

    /**
     * 传递进来最多能缓存多少数据
     *
     * @param cacheSize 缓存大小
     */
    public LRUCache(int cacheSize) {
        // true 表示让 LinkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        // 当 map 中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。
        return size() > CACHE_SIZE;
    }

}
```

其它更复杂，更能体现个人编码能力的 LRU 实现方式，可以看看如下两篇文章：

- [《动手实现一个 LRU Cache》](https://crossoverjie.top/2018/04/07/algorithm/LRU-cache/)
- [《缓存、缓存算法和缓存框架简介》](http://blog.jobbole.com/30940/) 文末，并且还提供了 FIFO、LFU 的代码实现。

## 缓存常见分类与应用场景？

在目前的应用服务框架中，缓存可分为local cache（本地缓存）和remote cache（分布式缓存）两大类：

- **本地缓存**：指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；同时，它的缺点也是应为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。常见的本地缓存技术有Guava Cache、Spring Cache、`Ehcache`等。
- **分布式缓存**：指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。我们平时耳熟能详的`Memcached`、`Redis` 就是分布式缓存的典型例子。

目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。

## 如果避免缓存”穿透”的问题？

> 推荐看下 [《Redis架构之防雪崩设计：网站不宕机背后的兵法》](https://mp.weixin.qq.com/s/TBCEwLVAXdsTszRVpXhVug) 文章。

**缓存穿透是指要访问的数据既不在缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据**。这样缓存就成了“空气摆设”一样，当大量请求访问数据时就会直接穿透缓存，给数据库带来巨大压力（注意是数据不存在，而不是数据为NULL）。 

缓存穿透一般发生在业务层误操作（缓存中数据和数据库中数据被误删）和恶意攻击（专门访问数据库中没有的数据）清情况下。一般有三种应对方案：

**1. 缓存空值或缺省值**

缓存一个空值或是和业务层协商确定的缺省值，那么下次访问就不会穿透了，保持了数据库的正常运行。

具体的值可以使用**特殊的标识**，能和真正缓存的数据区分开。另外，需要设置较短的过期时间，一般建议不要超过 5 分钟。

**2. 布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力**

布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成，可以用来快速判断某个数据是否存在。当我们想标记某个数据存在时（例如，数据已被写入数据库），布隆过滤器会通过三个操作完成标记：

* 首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值。
* 然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。
* 最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作。

如果数据不存在（例如，数据库里没有写入数据），我们也就没有用布隆过滤器标记过数据，那么，bit 数组对应 bit 位的值仍然为 0。当需要查询某个数据时，我们就执行刚刚说的计算过程，先得到这个数据在 bit 数组中对应的 N 个位置。紧接着，我们查看 bit 数组中这 N 个位置上的 bit 值。只要这 N 个 bit 值有一个不为 1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存。

<div align="center">  
<img src="../../09-Distributed-System/images/布隆过滤器.png" width="800px"/>
</div>
图中布隆过滤器是一个包含 10 个 bit 位的数组，使用了 3 个哈希函数，当在布隆过滤器中标记数据 X 时，X 会被计算 3 次哈希值，并对 10 取模，取模结果分别是 1、3、7。所以，bit 数组的第 1、3、7 位被设置为 1。当应用想要查询 X 时，只要查看数组的第 1、3、7 位是否为 1，只要有一个为 0，那么，X 就肯定不在数据库中。

正是基于布隆过滤器的快速检测特性，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询缓存和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。

需要注意的是，BloomFilter 不存储 KEY 是不存在的情况（就是我们方案一反过来）？

- BloomFilter 存在误判。简单来说，**存在的不一定存在，不存在的一定不存在**。这样就会导致，一个存在的 KEY 被误判成不存在。
- 同时，BloomFilter 不允许删除。例如说，一个 KEY 一开始是不存在的，后来数据新增了，但是 BloomFilter 不允许删除的特点，就会导致一直会被判断成不存在。

这两个方案，各有其优缺点。

|          | 缓存空对象                                                  | 布隆过滤器                                    |
| :------- | :---------------------------------------------------------- | :-------------------------------------------- |
| 适用场景 | 1. 数据命中不高<br/>2. 保证一致性                           | 1. 数据命中不高<br/>2. 数据相对固定、实时性低 |
| 维护成本 | 1. 代码维护简单<br/>2. 需要过多的缓存空间<br/>3. 数据不一致 | 1. 代码维护复杂<br/>2. 缓存空间占用小         |

实际情况下，使用布隆过滤器比较多。因为，相比方案一来说，更加节省内容，对缓存的负荷更小。

**3. 请求入口的前端进行请求检测**：

缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库。

## 如果避免缓存”击穿”的问题？

**缓存击穿是指，缓存中的某些热点数据忽然因为某种原因失效了，比如典型地由于超期而失效，恰巧此时有大量访问数据的请求，会直接发送到真实数据库，导致数据库压力剧增**。

- 和缓存“雪崩“”的区别在于，前者针对某一 KEY 缓存，后者则是很多 KEY 。
- 和缓存“穿透“”的区别在于，这个 KEY 是真实存在对应的值的。

我们通常可以采取这样两种办法：

**1. 加锁同步**

以请求该数据的 key 值为锁，这样就只有第一个请求可以流入到真实的数据源中，其他线程采取阻塞或重试策略。如果是进程内缓存出现了问题，施加普通**互斥锁**就可以了；如果是分布式缓存中出现的问题，就施加**分布式锁**，这样数据源就不会同时收到大量针对同一个数据的请求了。

**2. 热点数据由代码来手动管理**

缓存击穿是只针对热点数据被自动失效才引发的问题，所以对于这类数据，我们可以直接通过代码来有计划地完成更新、失效，避免由缓存的策略自动管理。比如**对于访问特别频繁的热点数据，我们就不设置过期时间**了。

这两个方案，各有其优缺点。

|      | 枷锁同步                       | 手动过期               |
| :--- | :----------------------------- | :--------------------- |
| 优点 | 思路简单，保证一致性           | 性价最佳，用户无需等待 |
| 缺点 | 代码复杂度增大，存在死锁的风险 | 无法保证缓存一致性     |

具体使用哪一种方案，胖友可以根据自己的业务场景去做选择。

- 有一点要注意，上述的两个方案，都是建立在**极度“热点”**数据存在的情况，所以实际场景下，需要结合 「如果避免缓存”穿透”的问题？的方案，一起使用。

## 如何避免缓存”雪崩”的问题？

**缓存雪崩是指，缓存中有大量数据同时失效，导致大量的应用请求无法在缓存中进行处理而直接发送到数据库，导致数据库层的压力激增**。

可以看出，缓存雪崩与缓存击穿的区别在于，缓存击穿是针对单个热点数据失效，由大量请求击穿缓存而给真实数据源带来了压力。

一般来说，由于**更新策略、或者数据热点、缓存服务宕机等原因**，可能会导致缓存数据同一 个时间点大规模不可用，或者都更新。所以，需要我们的更新策略要在时间上合适，数据要均匀分散，缓存服务器要多台高可用。 

**缓存雪崩最好的预防方法就是事前预防**。比如：

* 使用的热数据尽量分散到不同的机器上。 
* 多台机器做主从复制或者多副本，实现高可用。
* 在数据原本的失效时间上加上一个随机值（”错峰失效“）。

当然我们也得有“事后诸葛亮”的兜底方案，即**在业务系统中实现服务熔断或请求限流机制**。

* 服务熔断，是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，暂停业务应用对缓存系统的接口访问。再具体点说，就是业务应用调用缓存接口时，缓存客户端并不把请求发给缓存实例，而是直接返回，等到缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。

* 请求限流，就是指，我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。

## 缓存和数据库的一致性如何保证？

> 左耳朵耗子[《缓存更新的套路》](https://coolshell.cn/articles/17416.html)
>
> 沈剑[《缓存架构设计细节二三事》](https://www.w3cschool.cn/architectroad/architectroad-cache-architecture-design.html)

主要有两种情况，会导致缓存和 DB 的一致性问题：

* 并发的场景下，导致读取老的 DB 数据，更新到缓存中。

> 这里，主要指的是，更新 DB 数据之前，先删除 Cache 的数据。在低并发量下没什么问题，但是在高并发下，就会存在问题。在(删除 Cache 的数据, 和更新 DB 数据)时间之间，恰好有一个请求，我们如果使用**被动读**，因为此时 DB 数据还是老的，又会将老的数据写入到 Cache 中。

* 缓存和 DB 的操作，不在一个事务中，可能只有一个 DB 操作成功，而另一个 Cache 操作失败，导致不一致。

当然，有一点我们要注意，缓存和 DB 的一致性，我们指的更多的是最终一致性。我们使用缓存只要是提高读操作的性能，真正在写操作的业务逻辑，还是以数据库为准。例如说，我们可能缓存用户钱包的余额在缓存中，在前端查询钱包余额时，读取缓存，在使用钱包余额时，读取数据库。

因此无论哪种方案，要解决一致性问题则需要解决：

- 将缓存可能存在的并行写，实现串行写。

  > 注意，这里指的是缓存的并行写。在被动读中，如果缓存不存在，也存在写。

- 实现数据的最终一致性。

下面，我们就来看看几种方案。

**1. 先淘汰缓存，再写数据库**

因为先淘汰缓存，所以数据的最终一致性是可以得到有效的保证的。为什么呢？先淘汰缓存，即使写数据库发生异常，也就是下次缓存读取时，多读取一次数据库。

但是，这种方案会存在缓存和 DB 的数据会不一致的情况，[《缓存与数据库一致性优化》](https://www.w3cschool.cn/architectroad/architectroad-consistency-of-cache-with-database.html) 已经说了。

那么，我们需要解决缓存并行写，实现串行写。比较简单的方式，引入分布式锁。

- 在写请求时，先淘汰缓存之前，先获取该分布式锁。
- 在读请求时，发现缓存不存在时，先获取分布式锁。

这样，缓存的并行写就成功的变成串行写落。实际上，就是 「如果避免缓存”击穿”的问题？」的【方案一】互斥锁的加强版。

- 写请求时，是否主动更新缓存，根据自己业务的需要，是否有，都没问题。

**2. 先写数据库，再更新缓存**

按照“先写数据库，再更新缓存”，我们要保证 DB 和缓存的操作，能够在“同一个事务”中，从而实现最终一致性。

* **基于定时任务来实现**
  * 首先，写入数据库。
  * 然后，在写入数据库所在的事务中，插入一条记录到任务表。该记录会存储需要更新的缓存 KEY 和 VALUE 。
  * 【异步】最后，定时任务每秒扫描任务表，更新到缓存中，之后删除该记录。

* **基于消息队列来实现**
  * 首先，写入数据库。
  * 然后，发送带有缓存 KEY 和 VALUE 的事务消息。此时，需要有支持事务消息特性的消息队列，或者我们自己封装消息队列，支持事务消息。
  * 【异步】最后，消费者消费该消息，更新到缓存中。

这两种方式，可以进一步优化，可以先尝试更新缓存，如果失败，则插入任务表，或者事务消息。

另外，极端情况下，如果并发写执行时，先更新成功 DB 的，结果后更新缓存。

- 理论来说，希望的更新缓存顺序是，线程 1 快于线程 2 ，但是实际线程1 晚于线程 2 ，导致数据不一致。
- 可能胖友会说，图中不是基于定时任务或消息队列来实现异步更新缓存啊？答案是一直的，如果网络抖动，导致【插入任务表，或者事务消息】的顺序不一致。
- 那么怎么解决呢？需要做如下三件事情：
  - 1、在缓存值中，拼接上数据版本号或者时间戳。例如说：`value = {value: 原值, version: xxx}` 。
  - 2、在任务表的记录，或者事务消息中，增加上数据版本号或者时间戳的字段。
  - 3、在定时任务或消息队列执行更新缓存时，先读取缓存，对比版本号或时间戳，大于才进行更新。😈 当然，此处也会有并发问题，所以还是得引入分布式锁或 CAS 操作。
    - 关于 Redis 分布式锁，可以看看 [《精尽 Redis 面试题》](http://svip.iocoder.cn/Redis/Interview) 的 [「如何使用 Redis 实现分布式锁？」](http://svip.iocoder.cn/Cache/Interview/#) 问题。
    - 关于 Redis CAS 操作，可以看看 [《精尽 Redis 面试题》](http://svip.iocoder.cn/Redis/Interview) 的 [「什么是 Redis 事务？」](http://svip.iocoder.cn/Cache/Interview/#) 问题。

**3. 基于数据库的 binlog 日志**

> 引用自 [《技术专题讨论第五期：论系统架构设计中缓存的重要性》](http://www.spring4all.com/question/177) 文章

![binlog 方案](http://static.iocoder.cn/f434927790ae53b4fa955ecd9952f787)

- 应用直接写数据到数据库中。
- 数据库更新binlog日志。
- 利用Canal中间件读取binlog日志。
- Canal借助于限流组件按频率将数据发到MQ中。
- 应用监控MQ通道，将MQ的数据更新到Redis缓存中。

可以看到这种方案对研发人员来说比较轻量，不用关心缓存层面，而且这个方案虽然比较重，但是却容易形成统一的解决方案。

------

当然，以上种种方案，各有其复杂性：

- “**先淘汰缓存，再写数据库**”的方案，并且无需引入分布式锁。
- “**先写数据库，再更新缓存**”的方案，并且无需引入定时任务或者消息队列

> FROM 基友老梁的总结
>
> 使用缓存过程中，经常会遇到缓存数据的不一致性和脏读现象。一般情况下，采取缓存双淘汰机制，在更新数据库的**前**淘汰缓存。此外，设定超时时间，例如三十分钟。
>
> **极端场景下，即使有脏数据进入缓存，这个脏数据也最存在一段时间后自动销毁。**

- 重点，是最后一句话哟。
- 真的出现不一致的情况，靠缓存过期后，重新从 DB 中读取即可。

另外，在 DB 主从架构下，方案会更加复杂。详细可以看看 [《主从 DB 与 cache 一致性优化》](https://www.w3cschool.cn/architectroad/architectroad-consistency-of-cache-with-master-and-slave-database.html) 。

## 什么是缓存预热？如何实现缓存预热？

 **缓存预热**

在刚启动的缓存系统中，如果缓存中没有任何数据，如果依靠用户请求的方式重建缓存数据，那么对数据库的压力非常大，而且系统的性能开销也是巨大的。

此时，最好的策略是启动时就把热点数据加载好。这样，用户请求时，直接读取的就是缓存的数据，而无需去读取 DB 重建缓存数据。

举个例子，热门的或者推荐的商品，需要提前预热到缓存中。

 **如何实现**

一般来说，有如下几种方式来实现：

1. 数据量不大时，项目启动时，自动进行初始化。
2. 写个修复数据脚本，手动执行该脚本。
3. 写个管理界面，可以手动点击，预热对应的数据到缓存中。

## 缓存如何存储 POJO 对象？

实际场景下，缓存值可能是一个 POJO 对象，就需要考虑如何 POJO 对象存储的问题。目前有两种方式：

- 方案一，将 POJO 对象序列化进行存储，适合 Redis 和 Memcached 。

  - 可参考 [《Redis 序列化方式StringRedisSerializer、FastJsonRedisSerializer 和 KryoRedisSerializer》](https://blog.csdn.net/xiaolyuh123/article/details/78682200) 文章。
  - 对于 POJO 对象比较大，可以考虑使用压缩算法，例如说 Snappy、zlib、GZip 等等。
  
- 方案二，使用 Hash 数据结构，适合 Redis 。

  - 可参考 [《Redis 之序列化 POJO》](https://my.oschina.net/yuyidi/blog/499951) 文章。

不过对于 Redis 来说，大多数情况下，会考虑使用 JSON 序列化的方案。可以看看如下两篇文章，很有趣：

- [《Redis 内存压缩实战》](http://www.iocoder.cn/Fight/Redis-memory-compression-combat/?self) ，Redis HASH 数据结构，可以通过 ziplist 的编码方式，压缩数据。
- [《redis-strings-vs-redis-hashes-to-represent-json-efficiency》](https://stackoverflow.com/questions/16375188/redis-strings-vs-redis-hashes-to-represent-json-efficiency) ，重点看 BMiner 的回答，提供了四种方案，非常有趣。
