<!-- MarkdownTOC -->
- [TCP 粘包/拆包](#tcp-粘包拆包)
  - [什么是 TCP 粘包/拆包?有什么解决办法呢？](#什么是-tcp-粘包拆包有什么解决办法呢)
  - [为什么会出现粘包/拆包？](#为什么会出现粘包拆包)
    - [粘包](#粘包)
    - [拆包](#拆包)
    - [本质原因](#本质原因)
  - [如何解决粘包/拆包？](#如何解决粘包拆包)
- [Netty一次编码](#netty一次编码)
- [Netty二次编码](#netty二次编码)
  - [为什么需要一次编解码和二次编解码呢？](#为什么需要一次编解码和二次编解码呢)
  - [一次编解码和二次编解码可以合并吗？](#一次编解码和二次编解码可以合并吗)
  - [Netty 中如何快速区分一次编解码和二次编解码呢？](#netty-中如何快速区分一次编解码和二次编解码呢)
  - [常见的二次编解码方式](#常见的二次编解码方式)
- [Netty 长连接、心跳机制了解么？](#netty-长连接心跳机制了解么)
- [Netty 的零拷贝了解么？](#netty-的零拷贝了解么)
  - [什么是零拷贝？](#什么是零拷贝)
  - [讲讲 Netty中 的零拷贝？](#讲讲-netty中-的零拷贝)
- [参考](#参考)

<!-- /MarkdownTOC -->

# TCP 粘包/拆包

## 什么是 TCP 粘包/拆包?有什么解决办法呢？

TCP 粘包/拆包 就是你基于 TCP 发送数据的时候，出现了多个字符串“粘”在了一起或者一个字符串被“拆”开的问题。我们发送两条消息：ABC 和 DEF，可能一次就把两条消息接收完了，即 ABCDEF；也可能分成了好多次，比如 AB、CD 和 EF。

对方一次性接收了多条消息这种现象，我们就称之为**粘包现象**。

对方多次接收了不完整消息这种现象，我们就称之为**拆包（半包）现象**。

## 为什么会出现粘包/拆包？

### 粘包

TCP 发送消息的时候是有缓冲区的，当**消息的内容远小于缓冲区**的时候，这条消息不会立马发送出去，而是跟其它的消息合并之后再发送出去，这样合并发送是明显能够提高效率的。但是，**对方接收到的消息就是一个粘包**，无法有效区分出来到底是几条消息。当然，接收消息也是会通过 TCP 的缓冲区的，**如果接收方读取得不及时，也有可能出现粘包现象**。

可见，出现粘包的原因无非两种：

- 发送方每次写入数据 < 套接字缓冲区大小
- 接收方读取套接字缓冲区数据不够及时

### 拆包

类比粘包，如果发送的消息太大，已经**超过了缓冲区的大小**，这时候就**必须拆分发送**，也就**形成了拆包现象**。还有一种情况，网络协议各层是有最大负载的，所以，对应到各种协议它们是有最大发送数据的限制的，这种可以发送的最大数据称作 MTU（Maximum Transmission Unit，最大传输单元）。

可见，出现拆包的原因有两种：

- 发送方写入数据 > 套接字缓冲区大小
- 发送的数据大于协议的 MTU（Maximum Transmission Unit，最大传输单元），必须拆包

### 本质原因

**TCP 是流式协议，消息无边界**。（UDP 协议不会出现粘包 / 拆包现象，它的消息是有明确边界的。UDP 像邮寄的包裹，虽然一次运输多个，但每个包裹都有“界限”，一个一个签收， 所以无粘包、半包问题）。

## 如何解决粘包/拆包？

解决问题的根本手段就是：找出消息的边界。可以通过封装成帧（Framing）的三种方法：

| 方法          | 如何确定消息边界                   | 优点               | 缺点                                     | 推荐度     |
| :------------ | :--------------------------------- | :----------------- | :--------------------------------------- | :--------- |
| 定长法        | 使用固定长度分割消息               | 简单               | 空间浪费                                 | 不推荐     |
| 分割符法      | 使用固定分割符分割消息             | 简单               | 分割符本身需要转义，且需要扫描消息的内容 | 不特别推荐 |
| 长度 + 内容法 | 先获取消息的长度，再按长度读取内容 | 精确获取消息的内容 | 需要预先知道消息的最大长度               | 推荐+      |

> 其他方法：
>
> 1. TCP 连接改成短连接，一个请求一个短连接，那么建立连接到释放连接之 间的信息即为传输信息。效率低下，不推荐。
> 2. 例如 JSON 可以看{}是否应已经成对，所以说衡量实际场景，很多是对现有协议的支持。

**Netty 是如何支持的？**

Netty 是通过三组类来处理粘包 / 半包问题的，主要对应于上面提到的三种方式。

| 方法          | 编码                   | 解码                           |
| :------------ | :--------------------- | :----------------------------- |
| 定长法        | 简单                   | `FixedLengthFrameDecoder`      |
| 分割符法      | 简单                   | `DelimiterBasedFrameDecoder`   |
| 长度 + 内容法 | `LengthFieldPrepender` | `LengthFieldBasedFrameDecoder` |

* **`FixedLengthFrameDecoder`**: 定长协议解码 器，我们可以指定固定的字节数算一个完整的 报文

- **`DelimiterBasedFrameDecoder`** : 分隔符解码 器，分隔符可以自己指定。
- **`LineBasedFrameDecoder`** : 行分隔符解码器， 遇到`\n` 或者`\r\n`，则认为是一个完整的报文。
- **`LengthFieldBasedFrameDecoder`**：长度编码解码器，将报文划分为报文头/报文体。
- `JsonObjectDecoder`：json 格式解码器，当检 测到匹配数量的“{” 、”}”或”[””]”时，则认为是 一个完整的 json 对象或者 json 数组

> 之所以以`*FrameDecoder`结尾，那是因为被解码之后的消息又叫作一帧一帧的消息，所以称为 “帧解码器”。 

# Netty一次编码

> 待编写... ...

# Netty二次编码

粘包 / 半包的处理在 Netty 中是一次编解码，那么，二次编解码是什么呢？

## 为什么需要一次编解码和二次编解码呢？

一次解码主要用于解决粘包 / 半包的问题，将缓冲区中的字节数组按照协议本身的格式进行分割，其实，分割后的数据还是字节数组。

那么，分割后的字节数组如何转换成 Java 里面我们可以直接使用的对象呢？

这就需要二次解码了，通过二次解码，可以将字节数组转换成 Java 对象，然后传入我们自定义的 Handler 里面进行业务逻辑的处理。

比如，上一节中，固定长度为 3 的一次编解码器的那个例子，如果我们需要在控制台打印出来输入的内容，那么就要经历以下几个过程：

1. 运用一次解码将 “12345\r\n” 的字节数组拆分成 “123” 和 “45\r” 的字节数组；
2. 运用二次解码将 “123” 和 “45\r” 转换成 Java 的 String 类型的对象；
3. 打印上面的 String 对象；

<div align="center">  
<img src="https://img1.sycdn.imooc.com/5f179e66000118ca10340264.png" width="800px"/>
</div>

既然一次解码的时候都已经解出了对应的字节数组，何不顺势而为将其序列化成 Java 对象呢？

## 一次编解码和二次编解码可以合并吗？

可以，但是不建议，这里主要运用了分层的思想，举个简单的例子，比如一次编解码我们采用的是 “长度 + 内容法”，二次编解码一开始使用的是 XML，后面换成了 JSON，其实一次编解码我们不需要修改，只需要修改二次编解码就可以了。但是，如果二者合为一体了，那我们在后面实现 JSON 编解码的时候又要重新实现一下 “长度 + 内容” 的一次编解码的过程。

分层的思想很重要，在 Java 中随处可见，比如，著名的 MVC 分层思想。

> 凡事都有特例，Netty 中也有一些编解码没有严格地按照分层的思想来实现，比如 MarshallingEncoder，但是，还是那句话，不建议合并，分层很重要。

## Netty 中如何快速区分一次编解码和二次编解码呢？

其实，贴心的 Netty 也想到了这个问题，所以她定义了下面两组类来分别表示一次编解码和二次编解码：

- 一次编解码：`MessageToByteEncoder/ByteToMessageDecoder`
- 二次编解码：`MessageToMessageEncoder/MessageToMessageDecoder`

正常来说，继承自 `MessageToByteEncoder` 或者 `ByteToMessageDecoder` 类的就是一次编解码，继承自 `MessageToMessageEncoder` 或者 `MessageToMessageDecoder` 类的就是二次编解码，其实，也很好理解，服务端接收请求的过程也是先拿到字节数组（在 Netty 中可以理解为 ByteBuf），然后通过 ByteToMessageDecoder 转换成协议格式的字节数组，再把协议格式的字节数组通过 MessageToMessageDecoder 转换成 Java 对象。

<div align="center">  
<img src="https://img1.sycdn.imooc.com/5f179e780001aa4710310142.png" width="800px"/>
</div>

> 正如前文所说，凡事都有特例，比如 MarshallingEncoder，它继承自 MessageToByteEncoder，但是它把二次编码的工作也给干了。从 ByteToMessageDecoder 的名称也可以知道，字节数组直接转成 Java 对象也没有毛病，而且，MessageToMessageDecoder 也可以表示 Java 对象 A 转换成 Java 对象 B。不过，对于我们自己来写编解码，最好还是遵循分层的思想来实现。

## 常见的二次编解码方式

常见的二次编解码方式有很多，比如 XML、JSON、Java 序列化等，这些大家都比较熟悉，也比较常用，特别是 JSON，现在随着 RESTful 的流行，基本上基于 Web 开发都使用 JSON 来传输数据。还有一种序列化方式比较流行 ——Google 的 Protobuf，它主要运用在客户端与服务端需要长连接的场景，比如游戏行业。另外，Go 语言中也喜欢用 Protobuf，非常方便，而且高效。

> 二次编解码略等同于序列化方式，如果非要说区别，二次编解码的范围略大于序列化，序列化仅指把 Java 对象转换成字节数组的过程，而二次编解码实际上还包括 Java 对象之间的互相转换，也就是 Message to Message，比如 String 转 Integer，当然，一般不会为这么小的需求还写一个编解码器。

那么，Netty 中支持哪些二次编解码方式呢？

让我们打开 Netty 工程，找到 `netty-codec` 这个工程，展开目录：

<div align="center">  
<img src="https://img1.sycdn.imooc.com/5f179e8f0001c77704640379.png" width="500px"/>
</div>

可以看到，这个目录下有 base64、bytes、json、protobuf 等等，让我们一个一个来看一下：

- base64，大家都比较熟，BASE64 的支持，常用来把一个字符串转换成另一个字符串，简单加密
- bytes，ByteBuf 与 Java 本身的字节数组 `byte[]` 之间的互相转换
- compression，各种压缩协议的支持，比如 BZip、Snappy、Zlib 等
- json，通过 JSON 的形式来分割协议，不过，这里只有一个 JSON 一次解码器，因为 JSON 比较简单，只需要 toString () 就能拿到 JSON 文本了，所以，没有相应的二次编解码器，JSON 的优点很多，跨语言，结构清晰，易读
- marshalling，JBoss 的 Marshalling 的支持，也是比较有名的，不过这里的实现没有很好地分层，通过源码可以看到 MarshallingEncoder 继承自 MessageToByteEncoder，而 MarshallingDecoder 继承自 LengthFieldBasedFrameDecoder，缺少一种对称美
- protobuf，Google 的 Protobuf，因体积小，多语言支持而出名，而且不用写多少代码，只需要简单地定义好协议，使用工具一键生成 Java 对象，而且非常方便客户端与服务端不同语言的开发场景
- serialization，基于 Java 序列化做了一些优化，减小了序列化之后字节数组的大小，缺点很明显，只能 Java 中使用
- string，将 ByteBuf 转换成 Java 中的 String 对象，查看源码，其实很简单，只是调用 msg.toString (charset) 就完事了
- xml，XML 的支持，现在很少系统使用 XML 来传输数据了，缺点很明显，报文太大了

好了，我们这里拿三个比较常用的做下简单地对比：

| 序列化方式                            | 优点                                 | 缺点                                 |
| :------------------------------------ | :----------------------------------- | :----------------------------------- |
| serialization（优化过的 Java 序列化） | Java 原生，使用方便                  | 报文太大，不便于阅读，只能 Java 使用 |
| json                                  | 结构清晰，便于阅读，效率较高，跨语言 | 报文较大                             |
| protobuf                              | 使用方便，效率很高，报文很小，跨语言 | 不便于阅读                           |

其实，对于性能要求不是特别高的系统，我是非常推荐使用 JSON 这种方式的，毕竟写起来简单，看起来也简单。如果对于性能要求比较高，强烈推荐使用 Protobuf，性能非常高，而且也不用写多少代码，还能很好地定义客户端与服务端之间的协议，比如客户端使用 Javascript，服务端使用 Java，只要双方定好协议，各自使用工具生成对应的代码就可以直接使用了，再也不会为了协议的事儿扯皮了。

# Netty 长连接、心跳机制了解么？

**TCP 长连接和短连接了解么？**

我们知道 TCP 在进行读写之前，server 与 client 之间必须提前建立一个连接。建立连接的过程，需要我们常说的三次握手，释放/关闭连接的话需要四次挥手。这个过程是比较消耗网络资源并且有时间延迟的。

所谓，短连接说的就是 server 端 与 client 端建立连接之后，读写完成之后就关闭掉连接，如果下一次再要互相发送消息，就要重新连接。短连接的有点很明显，就是管理和实现都比较简单，缺点也很明显，每一次的读写都要建立连接必然会带来大量网络资源的消耗，并且连接的建立也需要耗费时间。

长连接说的就是 client 向 server 双方建立连接之后，即使 client 与 server 完成一次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。长连接的可以省去较多的 TCP 建立和关闭的操作，降低对网络资源的依赖，节约时间。对于频繁请求资源的客户来说，非常适用长连接。

**为什么需要心跳机制？Netty 中心跳机制了解么？**

在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server 之间如果没有交互的话，它们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入 **心跳机制** 。

心跳机制的工作原理是: 在 client 与 server 之间在一定时间内没有数据交互时, 即处于 idle 状态时, 客户端或服务器就会发送一个特殊的数据包给对方, 当接收方收到这个数据报文后, 也立即发送一个特殊的数据报文, 回应发送方, 此即一个 PING-PONG 交互。所以, 当某一端收到心跳消息后, 就知道了对方仍然在线, 这就确保 TCP 连接的有效性.

TCP 实际上自带的就有长连接选项，本身是也有心跳包机制，也就是 TCP 的选项：`SO_KEEPALIVE`。 但是，TCP 协议层面的长连接灵活性不够。所以，一般情况下我们都是在应用层协议上实现自定义心跳机制的，也就是在 Netty 层面通过编码实现。通过 Netty 实现心跳机制的话，核心类是 `IdleStateHandler` 。

# Netty 的零拷贝了解么？

## 什么是零拷贝？

系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数 据。等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中；而拷贝数据， 就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。以下是具体流程：

<div align="center">  
<img src="https://img-blog.csdnimg.cn/20210615144859758.png" width="800px"/>
</div>

应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到 系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。 这里我们可以看到，一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操 作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据。 

应用进程的一次完整的读写操作，都需要在用户空间与内核空间中来回拷贝，并且每一次拷 贝，都需要 CPU 进行一次上下文切换（由用户进程切换到系统内核，或由系统内核切换到 用户进程），这样是不是很浪费 CPU 和性能呢？那有没有什么方式，可以减少进程间的数 据拷贝，提高数据传输的效率呢？ 

这时我们就需要**零拷贝（Zero-copy）技术**。 所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，可以通过一种方式，直接将数据写入内核或从内核中读取数据，再通过 DMA 将内 核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。 那怎么做到零拷贝？你想一下是不是用户空间与内核空间都将数据写到一个地方，就不需要拷贝了？此时你有没有想到虚拟内存？

<div align="center">  
<img src="https://img-blog.csdnimg.cn/2021061514511858.png" width="800px"/>
</div>

零拷贝有两种解决方式，分别是 `mmap+write` 方式和 `sendfile` 方式，其核心原理都是 通过虚拟内存来解决的

## 讲讲 Netty中 的零拷贝？

在 OS 层面上的 `Zero-copy` 通常指避免在 `用户态(User-space)` 与 `内核态(Kernel-space)` 之间来回拷贝数据，可以提升 CPU 的利用率。

而在 Netty 层面 ，零拷贝主要体现在对于数据操作的优化。

Netty 中的零拷贝体现在以下几个方面

1. 使用 Netty 提供的 `CompositeByteBuf` 类，可以将多个`ByteBuf` 合并为一个逻辑上的 `ByteBuf`，避免了各个 `ByteBuf` 之间的拷贝。
2. `ByteBuf` 支持 `slice` 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 `ByteBuf`，避免了内存的拷贝。
3. 通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、ByteBuffer 等包装成一个 Netty ByteBuf 对象, 进而避免拷贝操作。
4. 通过 `FileRegion` 包装的`FileChannel.tranferTo` 实现文件传输，可以直接将文件缓冲区的数据发送到目标 `Channel`，避免了传统通过循环 write 方式导致的内存拷贝问题。

# 参考

- netty 学习系列二：NIO Reactor 模型 & Netty 线程模型：https://www.jianshu.com/p/38b56531565d
- 《Netty 实战》
- Netty 面试题整理(2):https://metatronxl.github.io/2019/10/22/Netty-
- Netty（3）源码 NioEventLoopGroup:https://www.cnblogs.com/qdhxhz/p/10075568.html
- 对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解: https://www.cnblogs.com/xys1228/p/6088805.html