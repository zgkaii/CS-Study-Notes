- [概览](#概览)
- [理解代码：前端](#理解代码前端)
  - [词法分析](#词法分析)
  - [语法分析](#语法分析)
  - [语义分析](#语义分析)
- [高效运行：后端](#高效运行后端)
  - [程序的运行机制](#程序的运行机制)
  - [生成中间代码](#生成中间代码)
  - [代码分析和优化](#代码分析和优化)
- [总结](#总结)

## 概览	

编译器整个编译过程大致如下：

<img src="https://img-blog.csdnimg.cn/20210421145657724.png" style="zoom:80%;" />

> 这里的“前端”是指编译器对程序代码的分析和理解过程，只与语言的语法相关，与目标机器无关；与之对应的“后端”则是生成目标代码的过程，跟目标机器相关。

编译器的工作流程简要描述如下：

> 1. 对源文件进行扫描，将源文件的字符流拆分分一个个的词（记号），此为词法分析。
> 2. 根据语法规则将这些记号构造出语法树，此为语法分析。
> 3. 对语法树的各个节点之间的关系进行检查，检查语义规则是否被违背，同时对语法树进行必要的优化，此为语义分析。
> 4. 遍历语法树的节点，将各节点转化为中间代码，并按特定的顺序拼装起来，此为中间代码生成。
> 5. 对中间代码进行优化。
> 6. 将中间代码转化为目标代码。
> 7. 对目标代码进行优化，生成最终的目标程序。

## 理解代码：前端

可以看到，编译器的“前端”技术分为**词法分析、语法分析**和**语义分析**三个部分，它主要涉及自动机和形式语言方面的基础的计算理论。

### 词法分析

词法分析（lexical analysis）是计算机科学中将字符序列转换为标记（token）序列的过程。 进行词法分析的程序或者函数叫作词法分析器（lexical analyzer，简称lexer），也叫扫描器（scanner）。 词法分析器一般以函数的形式存在，供语法分析器调用。

词法分析器是基于“正则文法”的规则工作的，其读入正则表达式，生成一种“有限自动机”的算法来完成具体的词法分析工作。

> **正则文法**是一种最普通、最常见的规则，写正则表达式的时候用的就是正则文法。
>
> **有限自动机**是有限个状态的自动机器。我们可以拿抽水马桶举例，它分为两个状态：“注水”和“水满”。摁下冲马桶的按钮，它转到“注水”的状态，而浮球上升到一定高度，就会把注水阀门关闭，它转到“水满”状态。

词法分析器分析整个程序的字符串，当遇到不同的字符时，会驱使它迁移到不同的状态。例如`age >= 45`这行代码，词法分析程序在扫描 age 的时候，处于“标识符”状态，等它遇到一个 > 符号，就切换到“比较操作符”的状态。词法分析过程，就是这样一个个状态迁移的过程。

<img src="https://img-blog.csdnimg.cn/20210421151325644.png" style="zoom: 67%;" />

### 语法分析

词法分析只是分析出一个个单词，而语法分析（syntactic analysis，也叫parsing）则是在词法分析的基础上识别出程序的语法结构。这个结构是一个树状结构，是计算器容易理解和执行的。而这颗树叫做**抽象语法树**（Abstract Syntax Tree，AST），树的每个节点（子树）是一个语法单元，这个单元的构成规则就叫“语法”。每个节点还可以有下级节点。

例如，在网址中输入一个可计算的表达式`2+3*5` ，那么会得到类似这样的AST：

```html
										+
									  /   \
									 2     *
										 /	 \
									 	3 	  5	 
```

那么这样形成AST有什么好处呢？**方便计算机处理**。针对表达式形成的这棵树，从根节点遍历整棵树就可以获得表达式的值。

**那么如何构造AST?**

一种非常直观的构造思路是自上而下进行分析，算法就是非常常用的递归下降算法。

<img src="https://img-blog.csdnimg.cn/20210421152435471.png" style="zoom:67%;" />

首先构造根节点，代表整个程序，之后向下扫描 Token 串，构建它的子节点。当它看到一个 int 类型的 Token 时，知道这儿遇到了一个变量声明语句，于是建立一个“变量声明”节点；接着遇到 age，建立一个子节点，这是第一个变量；之后遇到 =，意味着这个变量有初始化值，那么建立一个初始化的子节点；最后，遇到“字面量”，其值是 45。这样，一棵子树就扫描完毕了。程序退回到根节点，开始构建根节点的第二个子节点。这样递归地扫描，直到构建起一棵完整的树。

递归下降算法是一种自顶向下的算法，与之对应的，还有自底向上的算法。这个算法会先将最下面的叶子节点识别出来，然后再组装上一级节点。有点儿像搭积木，我们总是先构造出小的单元，然后再组装成更大的单元。

### 语义分析

直白地讲，语义分析（semantic analysis）是消除语义模糊，生成一些属性信息，让计算机能够依据这些信息生成目标代码。

以“You can never drink too much water.” 这句话为例。它的确切含义是什么？是“你不能喝太多水”，还是“你喝多少水都不嫌多”？实际上，这两种解释都是可以的，我们只有联系上下文才能知道它的准确含义。

语义分析工作的某些成果，会作为属性标注在抽象语法树上，比如在 age 这个标识符节点和 45 这个字面量节点上，都会标识它的数据类型是 int 型的。

在这个树上还可以标记很多属性，有些属性是在之前的两个阶段就被标注上了，比如所处的源代码行号，这一行的第几个字符。这样，在编译程序报错的时候，就可以比较清楚地了解出错的位置。

做了这些属性标注以后，编译器在后面就可以依据这些信息生成目标代码了

在语言学中，语义分析是将句法结构（从短语，从句，句子和段落的级别到整个写作级别，到其与语言无关的含义）相关联的过程。它还涉及删除功能针对特定语言和文化背景，对这样的项目是可能的范围内。在语义分析中，习惯用语和修辞格的文化元素通常也转换为相对不变的含义。

## 高效运行：后端

编译器后端工作主要是把程序编译成机器能读懂的代码，并高效运行。**这时，我们就面临了三个问题：**

1. 我们必须了解计算机运行一个程序的原理（也就是运行期机制），只有这样，才知道如何生成这样的程序。
2. 要能利用前端生成的 AST 和属性信息，将其正确翻译成目标代码。
3.  需要对程序做尽可能多的优化，比如让程序执行效率更高，占空间更少等等。

### 程序的运行机制

说到底，要让一个程序在计算机正确和高效运行，我们主要关注的是下面两个硬件：

* **一个是 CPU，它能接受机器指令和数据，并进行计算。**它里面有寄存器、高速缓存和运算单元，充分利用寄存器和高速缓存会让系统的性能大大提升。
* **另一个是内存。**我们要在内存里保存编译好的代码和数据，还要设计一套机制，让程序最高效地利用这些内存。

<img src="https://img-blog.csdnimg.cn/20210421160338968.png" style="zoom:67%;" />

通常情况下，我们的程序要受某个操作系统的管理，所以也要符合操作系统的一些约定。但有时候我们的程序也可能直接跑在硬件上，单片机和很多物联网设备采用这样的结构，甚至一些服务端系统，也可以不跑在操作系统上。

你可以看出，编译器后端技术跟计算机体系结构的关系很密切。要想编译生成程序，我们需要清楚明白这个机制才行，而运行期的机制涉及知识相对复杂，比如内存空间如何划分和组织；程序是如何启动、跳转和退出的；执行过程中指令和数据如何传递到 CPU；整个过程中需要如何跟操作系统配合，等等。

也的时候，我们的面对的机器是虚拟机，Java 的运行环境就是一个虚拟机（JVM），那我们就需要了解这个虚拟机的特点，以便生成可以在这个虚拟机上运行的代码，比如 Java 的字节码。同时，字节码有时仍然需要编译成机器码。

> 这些问题之后再做探讨... ...

### 生成中间代码

编译器后端的最终结果，就是生成目标代码。如果目标是在计算机上直接运行，就像 C 语言程序那样，那这个目标代码指的是汇编代码。而如果运行目标是 Java 虚拟机，那这个目标代码就是指 JVM 的字节码。

当然，写汇编跟使用高级语言有很多不同，**其中一点就是要关心 CPU 和内存这样具体的硬件。**比如，你需要了解不同的 CPU 指令集的差别，你还需要知道 CPU 是 64 位的还是 32 位的，有几个寄存器，每个寄存器可以用于什么指令，等等。但这样导致的问题是，每种语言，针对每种不同的硬件，都要生成不同的汇编代码。一般我们设计一门语言要支持尽可能多的硬件平台，这样的工作量太过庞大。

所以，为了降低后端工作量，提高软件复用度，就需要引入**中间代码（Intermediate Representation，IR）的机制**，它是独立于具体硬件的一种代码格式。各个语言的前端可以先翻译成 IR，然后再从 IR 翻译成不同硬件架构的汇编代码。如果有 n 个前端语言，m 个后端架构，本来需要做 `m*n` 个翻译程序，现在只需要 `m+n` 个了。这就大大降低了总体的工作量。

<img src="https://img-blog.csdnimg.cn/20210421160223412.png" style="zoom: 67%;" />

甚至，很多语言主要做好前端就行了，后端可以尽量重用已有的库和工具，这也是现在推出新语言越来越快的原因之一。像 Rust 就充分利用了 LLVM，GCC 的各种语言，如 C、C++、Object C 等，也是充分共享了后端技术。

IR 可以有多种格式，例如有三地址代码、静态单赋值码等不同的 IR。比如，`“x + y * z”`翻译成三地址代码是下面的样子，每行代码最多涉及三个地址，其中 t1 和 t2 是临时变量：

```html
t1 := y * z
t2 := x + t1
```

其实，IR 这个词直译成中文，是“中间表示方式”的意思，不一定非是像汇编代码那样的一条条的指令。所以，AST 其实也可以看做一种 IR。每种 IR 的目的和用途是不一样的：

- AST 主要用于前端的工作。
- Java 的字节码，是设计用来在虚拟机上运行的。
- LLVM 的中间代码，主要是用于做代码翻译和编译优化的。
- ……

总的来说，我们可以把各种语言翻译成中间代码，再针对每一种目标架构，通过一个程序将中间代码翻译成相应的汇编代码就可以了。然而事情真的这么简单吗？答案是否定的，因为我们还必须对代码进行优化。

### 代码分析和优化

生成正确的、能够执行的代码比较简单，可这样的代码执行效率很低，因为直接翻译生成的代码往往不够简洁，比如会生成大量的临时变量，指令数量也较多。因为翻译程序首先照顾的是正确性，很难同时兼顾是否足够优化，这是一方面。另一方面，由于高级语言本身的限制和程序员的编程习惯，也会导致代码不够优化，不能充分发挥计算机的性能。所以我们一定要对代码做优化。程序员在比较各种语言的时候，一定会比较它们的性能差异。一个语言的性能太差，就会影响它的使用和普及。

实际上，就算是现在常见的脚本语言，如 Python 和 JavaScript，也做了很多后端优化的工作，包括编译成字节码、支持即时编译等，这些都是为了进一步提高性能。从谷歌支持的开源项目 V8 开始，JavaScript 的性能获得了巨大的提高，这才导致了 JavaScript 再一次的繁荣，包括支持体验更好的前端应用和基于 Node.js 的后端应用。

优化工作又分为**“独立于机器的优化”和“依赖于机器的优化”**两种。

独立于机器的优化，是基于 IR 进行的。它可以通过对代码的分析，用更加高效的代码代替原来的代码。比如下面这段代码中的 foo() 函数，里面有多个地方可以优化。甚至，我们连整个对 foo() 函数的调用，也可以省略，因为 foo() 的值一定是 101。这些优化工作在编译期都可以去做。

```c
int foo() {
    int a = 10*10;  // 这里在编译时可以直接计算出 100 这个值
    int b = 20;     // 这个变量没有用到，可以在代码中删除
 
    if (a>0) {      // 因为 a 一定大于 0，所以判断条件和 else 语句都可以去掉
        return a+1; // 这里可以在编译器就计算出是 101
    } else {
        return a-1;
    }
}
int a = foo();      // 这里可以直接地换成 a=101;
```

上面的代码，通过优化，可以消除很多冗余的逻辑。这就好比你正在旅行，先从北京飞到了上海，然后又飞到厦门，最后飞回北京。然后你朋友问你现在在哪时，你告诉他在北京。那么他虽然知道你在北京，但并没有意识到你已经在几个城市折腾了一圈，因为他只关心你现在在哪儿，并不关心你的中间过程。 我们在给 a 赋值的时候，只需要知道这个值是 101 就行了。完全不需要在运行时去兜一大圈来计算。

计算机代码里有很多这种需要优化的情形，也有多种优化技术，比如局部优化和全局优化，常数折叠、拷贝传播、删除公共子表达式等，其中数据流分析方法比较重要。

**依赖于机器的优化，则是依赖于硬件的特征。**现代的计算机硬件设计了很多特性，以便提供更高的处理能力，比如并行计算能力，多层次内存结构（使用多个级别的高速缓存）等等。编译器要能够充分利用硬件提供的性能，比如 ：

- **寄存器优化。**对于频繁访问的变量，最好放在寄存器中，并且尽量最大限度地利用寄存器，不让其中一些空着，有不少算法是解决这个问题的，教材上一般提到的是染色算法；
- **充分利用高速缓存。**高速缓存的访问速度可以比内存快几十倍上百倍，所以我们要尽量利用高速缓存。比如，某段代码操作的数据，在内存里尽量放在一起，这样 CPU 读入数据时，会一起都放到高速缓存中，不用一遍一遍地重新到内存取。
- **并行性。**现代计算机都有多个内核，可以并行计算。我们的编译器要尽可能把充分利用多个内核的计算能力。 这在编译技术中是一个专门的领域。
- **流水线。**CPU 在处理不同的指令的时候，需要等待的时间周期是不一样的，在等待某些指令做完的过程中其实还可以执行其他指令。就比如在星巴克买咖啡，交了钱就可以去等了，收银员可以先去处理下一个顾客，而不是要等到前一个顾客拿到咖啡才开始处理下一个顾客。
- **指令选择。**有的时候，CPU 完成一个功能，有多个指令可供选择。而针对某个特定的需求，采用 A 指令可能比 B 指令效率高百倍。比如 X86 架构的 CPU 提供 SIMD 功能，也就是一条指令可以处理多条数据，而不是像传统指令那样一条指令只能处理一条数据。在内存计算领域，SIMD 也可以大大提升性能，我们在第 30 讲的应用篇，会针对 SIMD 做一个实验。
- **其他优化。**比如可以针对专用的 AI 芯片和 GPU 做优化，提供 AI 计算能力，等等。

可以看出来，做好依赖于机器的优化要对目标机器的体系结构有清晰的理解，如果能做好这些工作，那么开发一些系统级的软件也会更加得心应手。实际上，数据库系统、大数据系统等等，都是要融合编译技术的。

总结起来，在编译器中需要对代码进行的优化非常多。因此，这部分工作也是编译过程中耗时最长、最体现某个编译器的功力的一类工作，所以更值得引起你的重视。

## 总结

本篇文章主要**简述**了编译器基本工作流程。可以看出，前端技术着重于“理解代码”，它主要分三个部分：

- 词法分析是把程序分割成一个个 token 的过程，可以通过构造有限自动机来实现；
- 语法分析是把程序的结构识别出来，并形成一棵便于由计算机处理的抽象语法树。可以用递归下降的算法来实现；
- 语义分析是消除语义模糊，生成一些属性信息，让计算机能够依据这些信息生成目标代码。

其实，这些编译过程我们的实际工作息息相关。例如，词法分析就是工作中使用正则表达式的过程；而语法分析则是在解析文本文件、配置文件、模型定义文件，或者做自定义公式功能的时会用到的。

当然，熟悉了前端技术，能做 Lexer、Parser并不意味着就理解了编译原理。实际上，词法分析和语法分析比较成熟，有成熟的工具来支撑。**相对来说，后端的工作量更大，挑战更多，研究的热点也更多**。比如，人工智能领域又出现了一些专用的 AI 芯片和指令集，就需要去适配。

要做好后端工作，我们就必须：

* 熟悉计算机体系结构和程序的运行时机制；
* 还要从前端生成中间代码，然后基于中间代码生成针对不同平台的目标代码；
* 最后，需要对代码做各种优化工作，包括独立于机器的优化和依赖于机器的优化。

编译器的后端，也就是把高级语言翻译成计算机能够理解的目标语言。它跟前端相比，关注点是不同的。**前端关注的是正确反映了代码含义的静态结构，而后端关注的是让代码良好运行的动态结构**。
